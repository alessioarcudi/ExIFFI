{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ExIFFI and EIF+ Documentation","text":"<p>This is the official documentation of the implementation used in the \"ExIFFI and EIF+: Interpretability and Enhanced Generalizability to Extend the Extended Isolation Forest\" paper. The paper introduces Extended Isolation Forest Feature Importance (ExIFFI), a novel interpretation algorithm designed for the Extended Isolation Forest (EIF) anomaly detection model but it also works for all the Isolation Forest based AD models. ExIFFI aims to provide explanations for predictions made by EIF by computing global and local feature importance scores. Additionally, an enhanced variant of EIF, named EIF+, is proposed to improve generalization performance. The evaluation involves comprehensive experiments on synthetic and real-world datasets to assess anomaly detection performance and the effectiveness of ExIFFI for interpretation. The code used to perform the experiments is also included in this documentation to provide reproducibility. </p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Datasets</li> <li>Models</li> <li>Plots</li> <li>Experiments</li> <li>Tutorial Noteboook</li> </ul>"},{"location":"datasets/","title":"Datasets","text":"<p>The <code>Dataset</code> class enables loading and manipulating the datasets. The datasets are contained in the folder <code>data</code> and divided into two subfolders: </p> <ul> <li><code>real</code> \u2192 Real World Datasets</li> <li><code>syn</code> \u2192 Synthetic Datasets</li> </ul>"},{"location":"datasets/#utils_reboot.datasets.Dataset","title":"<code>Dataset</code>  <code>dataclass</code>","text":"<p>A class to represent a dataset.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the dataset.</p> <code>path</code> <code>str</code> <p>The path to the dataset file.</p> <code>feature_names_filepath</code> <code>Optional[str]</code> <p>The path to the json file containing the feature names of the dataset.</p> <code>X</code> <code>Optional[NDArray]</code> <p>Data matrix of the dataset.</p> <code>y</code> <code>Optional[NDArray]</code> <p>The labels of the dataset.</p> <code>X_train</code> <code>Optional[NDArray]</code> <p>Training set, initialized to None</p> <code>y_train</code> <code>Optional[NDArray]</code> <p>The labels of the training set</p> <code>X_test</code> <code>Optional[NDArray]</code> <p>Test set, initialized to None</p> <code>y_test</code> <code>Optional[NDArray]</code> <p>The labels of the test set</p> <code>feature_names</code> <code>Optional[List[str]]</code> <p>The names of the features of the dataset.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>@dataclass\nclass Dataset:\n    \"\"\"\n    A class to represent a dataset.\n\n    Attributes:\n        name: The name of the dataset.\n        path: The path to the dataset file.\n        feature_names_filepath: The path to the json file containing the feature names of the dataset.\n        X: Data matrix of the dataset.\n        y: The labels of the dataset.\n        X_train: Training set, initialized to None\n        y_train: The labels of the training set\n        X_test: Test set, initialized to None\n        y_test: The labels of the test set\n        feature_names: The names of the features of the dataset.\n    \"\"\"\n    name: str\n    path: str = \"../data/\"\n    feature_names_filepath: Optional[str] = None\n    X: Optional[npt.NDArray] = field(default=None, init=False)\n    y: Optional[npt.NDArray] = field(default=None, init=False)\n    X_train: Optional[npt.NDArray] = field(default=None, init=False)\n    y_train: Optional[npt.NDArray] = field(default=None, init=False)\n    X_test: Optional[npt.NDArray] = field(default=None, init=False)\n    y_test: Optional[npt.NDArray] = field(default=None, init=False)\n    feature_names: Optional[List[str]] = field(default=None, init=False)\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Initialize the dataset.\n\n        Load the dataset from the file and set the feature names.\n\n        \"\"\"\n        self.load()\n\n        if self.feature_names_filepath is not None:\n            self.dataset_feature_names()\n\n        if self.feature_names is None:\n            self.feature_names=np.arange(self.shape[1])\n\n    @property\n    def shape(self) -&gt; tuple:\n        \"\"\"\n        Return the shape of the dataset.\n\n        Returns:\n            The shape of the dataset.\n        \"\"\"\n        return self.X.shape if self.X is not None else ()\n\n    @property\n    def n_outliers(self) -&gt; int:\n        \"\"\"\n        Return the number of outliers in the dataset.\n\n        Returns:\n            The number of outliers in the dataset.\n        \"\"\"\n        return int(sum(self.y)) if self.y is not None else 0\n\n    @property\n    def perc_outliers(self) -&gt; float:\n        \"\"\"\n        Return the percentage of outliers in the dataset (i.e. the contamination factor)\n\n        Returns:\n            The percentage of outliers in the dataset.\n        \"\"\"\n        return sum(self.y) / len(self.y) if self.y is not None else 0.0\n\n    def load(self) -&gt; None:\n        \"\"\"\n        Load the dataset from the file.\n\n        Raises:\n            FileNotFoundError: If the dataset file is not found.\n            Exception: If the dataset name is not valid.\n\n        Returns:\n            The dataset is loaded in place.\n        \"\"\"\n        try:\n            datapath = self.path + self.name + \".mat\"\n            try:\n                mat = loadmat(datapath)\n            except NotImplementedError:\n                mat = mat73.loadmat(datapath)\n\n            self.X = mat['X'].astype(float)\n            self.y = mat['y'].reshape(-1, 1).astype(float)\n        except FileNotFoundError:\n            try:\n                datapath = self.path + self.name + \".csv\"\n                T = pd.read_csv(datapath)\n                if 'Unnamed: 0' in T.columns:\n                    T = T.drop(columns=['Unnamed: 0'])\n                self.X = T['X'].to_numpy(dtype=float)\n                self.y = T['y'].to_numpy(dtype=float).reshape(-1, 1)\n            except Exception as e:\n                try:\n                    datapath = self.path + self.name + \".csv\"\n                    if self.name == \"glass\":\n                        T = pd.read_csv(datapath)\n                    else:\n                        T = pd.read_csv(datapath,index_col=0)\n                    if 'Unnamed: 0' in T.columns:\n                        T = T.drop(columns=['Unnamed: 0'])\n                    self.X = T.loc[:,T.columns != \"Target\"].to_numpy(float)\n                    self.y = T.loc[:,\"Target\"].to_numpy(float)\n                except:\n                    raise Exception(\"The dataset name is not valid\") from e\n\n\n    def __repr__(self) -&gt; str:\n        return f\"[{self.name}][{self.shape}][{self.n_outliers}]\"\n\n    def drop_duplicates(self) -&gt; None:\n        \"\"\"\n        Drop duplicate samples from the dataset.\n\n        Returns:\n            The dataset is modified in place.\n        \"\"\"\n        S = np.c_[self.X, self.y]\n        S = pd.DataFrame(S).drop_duplicates().to_numpy()\n        self.X, self.y = S[:, :-1], S[:, -1]\n\n    def downsample(self, max_samples: int = 2500) -&gt; None:\n        \"\"\"\n        Downsample the dataset to a maximum number of samples.\n\n        Args:\n            max_samples: The maximum number of samples to keep in the dataset.\n\n        Returns:\n            The dataset is modified in place.\n        \"\"\"\n        if len(self.X) &gt; max_samples:\n            print(\"downsampled to \", max_samples)\n            sss = SSS(n_splits=1, test_size=1 - max_samples / len(self.X))\n            index = list(sss.split(self.X, self.y))[0][0]\n            self.X, self.y = self.X[index, :], self.y[index]\n\n    def partition_data(self,X:np.array,y:np.array) -&gt; tuple:\n\n        # Ensure that X and y are not None\n        if self.X is None or self.y is None:\n            print(\"Dataset not loaded.\")\n            return\n        try:\n            inliers = X[y == 0, :]\n            outliers = X[y == 1, :]\n            y_inliers= y[y == 0]\n            y_outliers= y[y == 1]\n        except TypeError:\n            print('X_train and y_train not loaded yet. Run split_dataset() first')\n            return \n        return inliers, outliers,y_inliers,y_outliers\n\n    def print_dataset_resume(self) -&gt; None:\n        \"\"\"\n        Print a summary of the dataset.\n\n        The summary includes the number of samples, the number of features, the number of inliers and outliers and some\n        summary statistics of the features.\n\n        Returns:\n            The dataset summary is printed.\n\n        \"\"\"\n        # Ensure that X and y are not None\n        if self.X is None or self.y is None:\n            print(\"Dataset not loaded.\")\n            return\n\n        # Basic statistics\n        num_samples = len(self.X)\n        num_features = self.X.shape[1] if self.X is not None else 0\n        num_inliers = np.sum(self.y == 0)\n        num_outliers = np.sum(self.y == 1)\n        balance_ratio = num_outliers / num_samples\n\n        # Aggregate statistics for features in X\n        mean_values = np.mean(self.X, axis=0)\n        std_dev_values = np.std(self.X, axis=0)\n        min_values = np.min(self.X, axis=0)\n        max_values = np.max(self.X, axis=0)\n\n        # Compact representation of statistics\n        mean_val = np.mean(mean_values)\n        std_dev_val = np.mean(std_dev_values)\n        min_val = np.min(min_values)\n        max_val = np.max(max_values)\n\n        # Print the summary\n        print(f\"Dataset Summary for '{self.name}':\")\n        print(f\" Total Samples: {num_samples}, Features: {num_features}\")\n        print(f\" Inliers: {num_inliers}, Outliers: {num_outliers}, Balance Ratio: {balance_ratio:.2f}\")\n        print(f\" Feature Stats - Mean: {mean_val:.2f}, Std Dev: {std_dev_val:.2f}, Min: {min_val}, Max: {max_val}\")\n\n\n    def split_dataset(self, \n                      train_size:float = 0.8, \n                      contamination:float = 0.1) -&gt; None:\n\n        \"\"\"\n        Split the dataset into training and test sets with a given train size and contamination factor.\n\n        Args:\n            train_size: The proportion of the dataset to include in the training set.\n            contamination: The proportion of outliers in the dataset.\n\n        Returns:\n            The dataset is split into training and test sets in place\n\n        \"\"\"\n        # Ensure that X and y are not None\n        if self.X is None or self.y is None:\n            print(\"Dataset not loaded.\")\n            return\n\n        # Check if train_size is correct\n        if train_size &gt; 1 - self.perc_outliers:\n            print(\"Train size is too large. Setting it at 1-dataset.perc_outliers.\")\n            train_size = 1 - self.perc_outliers\n\n        indexes_outliers = np.where(self.y==1)[0].tolist()\n        indexes_inliers = np.where(self.y==0)[0].tolist()\n        random.shuffle(indexes_outliers)\n        random.shuffle(indexes_inliers)\n        dim_train = int(len(self.X)*train_size)\n        self.X_train = np.zeros((dim_train,self.X.shape[1]))\n        self.y_train = np.zeros(dim_train)\n        for i in range(dim_train):\n            if i &lt; dim_train*contamination and len(indexes_outliers) &gt; 0:\n                index = indexes_outliers.pop()\n            else:\n                index = indexes_inliers.pop()\n            self.X_train[i] = self.X[index]\n            self.y_train[i] = self.y[index]\n\n    def pre_process(self) -&gt; None:\n\n        \"\"\"\n        Normalize the data using `StansardScaler()` from `sklearn.preprocessing`.\n\n        Returns:\n           The dataset is normalized in place.\n        \"\"\"\n\n        # Ensure that X and y are not None\n        if self.X is None or self.y is None:\n            print(\"Dataset not loaded.\")\n            return\n        if self.X_train is None:\n            self.initialize_train_test()\n        if self.X_test is None:\n            self.initialize_test()\n\n        scaler = StandardScaler()\n\n        self.X_train=scaler.fit_transform(self.X_train)\n        self.X_test=scaler.transform(self.X_test)\n\n    def initialize_train_test(self) -&gt; None:\n\n        \"\"\"\n        Initialize the training and test sets with the original dataset. \n\n        This method is used when `split_dataset()` has not been called before `pre_process()`.\n\n        Returns:\n            The training and test sets are initialized in place.\n        \"\"\"\n        # Ensure that X and y are not None\n        if self.X is None or self.y is None:\n            print(\"Dataset not loaded.\")\n            return\n        if self.X_train is None:\n            self.initialize_train()\n        if self.X_test is None:\n            self.initialize_test()\n\n    def initialize_test(self) -&gt;None:\n\n        \"\"\"\n        Initialize the test set with the original dataset. \n\n        This method is used when `split_dataset()` has not been called before `pre_process()`.\n\n        Returns:\n            The test set is initialized in place.\n        \"\"\"\n\n        self.X_test=copy.deepcopy(self.X)\n        self.y_test=copy.deepcopy(self.y)\n\n\n    def initialize_train(self) -&gt;None:\n\n        \"\"\"\n        Initialize the train set with the original dataset. \n\n        This method is used when `split_dataset()` has not been called before `pre_process()`.\n\n        Returns:\n            The training set is initalized in place.\n        \"\"\"\n\n        self.X_train=copy.deepcopy(self.X)\n        self.y_train=copy.deepcopy(self.y)\n\n    def dataset_feature_names(self) -&gt; List[str]:\n\n            \"\"\" \n            Set the feture names for the datasets for which the feature names are available \n\n            Returns:\n                Set the feature_names attributes to a list of string containing the feature names of the dataset.\n            \"\"\"\n            with open(self.feature_names_filepath+'data_feature_names.json','r') as f:\n                data_feature_names=json.load(f)\n\n            if self.name in data_feature_names:    \n                self.feature_names=data_feature_names[self.name]\n            else:\n                self.feature_names=None \n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.n_outliers","title":"<code>n_outliers: int</code>  <code>property</code>","text":"<p>Return the number of outliers in the dataset.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of outliers in the dataset.</p>"},{"location":"datasets/#utils_reboot.datasets.Dataset.perc_outliers","title":"<code>perc_outliers: float</code>  <code>property</code>","text":"<p>Return the percentage of outliers in the dataset (i.e. the contamination factor)</p> <p>Returns:</p> Type Description <code>float</code> <p>The percentage of outliers in the dataset.</p>"},{"location":"datasets/#utils_reboot.datasets.Dataset.shape","title":"<code>shape: tuple</code>  <code>property</code>","text":"<p>Return the shape of the dataset.</p> <p>Returns:</p> Type Description <code>tuple</code> <p>The shape of the dataset.</p>"},{"location":"datasets/#utils_reboot.datasets.Dataset.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Initialize the dataset.</p> <p>Load the dataset from the file and set the feature names.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Initialize the dataset.\n\n    Load the dataset from the file and set the feature names.\n\n    \"\"\"\n    self.load()\n\n    if self.feature_names_filepath is not None:\n        self.dataset_feature_names()\n\n    if self.feature_names is None:\n        self.feature_names=np.arange(self.shape[1])\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.dataset_feature_names","title":"<code>dataset_feature_names()</code>","text":"<p>Set the feture names for the datasets for which the feature names are available </p> <p>Returns:</p> Type Description <code>List[str]</code> <p>Set the feature_names attributes to a list of string containing the feature names of the dataset.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def dataset_feature_names(self) -&gt; List[str]:\n\n        \"\"\" \n        Set the feture names for the datasets for which the feature names are available \n\n        Returns:\n            Set the feature_names attributes to a list of string containing the feature names of the dataset.\n        \"\"\"\n        with open(self.feature_names_filepath+'data_feature_names.json','r') as f:\n            data_feature_names=json.load(f)\n\n        if self.name in data_feature_names:    \n            self.feature_names=data_feature_names[self.name]\n        else:\n            self.feature_names=None \n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.downsample","title":"<code>downsample(max_samples=2500)</code>","text":"<p>Downsample the dataset to a maximum number of samples.</p> <p>Parameters:</p> Name Type Description Default <code>max_samples</code> <code>int</code> <p>The maximum number of samples to keep in the dataset.</p> <code>2500</code> <p>Returns:</p> Type Description <code>None</code> <p>The dataset is modified in place.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def downsample(self, max_samples: int = 2500) -&gt; None:\n    \"\"\"\n    Downsample the dataset to a maximum number of samples.\n\n    Args:\n        max_samples: The maximum number of samples to keep in the dataset.\n\n    Returns:\n        The dataset is modified in place.\n    \"\"\"\n    if len(self.X) &gt; max_samples:\n        print(\"downsampled to \", max_samples)\n        sss = SSS(n_splits=1, test_size=1 - max_samples / len(self.X))\n        index = list(sss.split(self.X, self.y))[0][0]\n        self.X, self.y = self.X[index, :], self.y[index]\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.drop_duplicates","title":"<code>drop_duplicates()</code>","text":"<p>Drop duplicate samples from the dataset.</p> <p>Returns:</p> Type Description <code>None</code> <p>The dataset is modified in place.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def drop_duplicates(self) -&gt; None:\n    \"\"\"\n    Drop duplicate samples from the dataset.\n\n    Returns:\n        The dataset is modified in place.\n    \"\"\"\n    S = np.c_[self.X, self.y]\n    S = pd.DataFrame(S).drop_duplicates().to_numpy()\n    self.X, self.y = S[:, :-1], S[:, -1]\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.initialize_test","title":"<code>initialize_test()</code>","text":"<p>Initialize the test set with the original dataset. </p> <p>This method is used when <code>split_dataset()</code> has not been called before <code>pre_process()</code>.</p> <p>Returns:</p> Type Description <code>None</code> <p>The test set is initialized in place.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def initialize_test(self) -&gt;None:\n\n    \"\"\"\n    Initialize the test set with the original dataset. \n\n    This method is used when `split_dataset()` has not been called before `pre_process()`.\n\n    Returns:\n        The test set is initialized in place.\n    \"\"\"\n\n    self.X_test=copy.deepcopy(self.X)\n    self.y_test=copy.deepcopy(self.y)\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.initialize_train","title":"<code>initialize_train()</code>","text":"<p>Initialize the train set with the original dataset. </p> <p>This method is used when <code>split_dataset()</code> has not been called before <code>pre_process()</code>.</p> <p>Returns:</p> Type Description <code>None</code> <p>The training set is initalized in place.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def initialize_train(self) -&gt;None:\n\n    \"\"\"\n    Initialize the train set with the original dataset. \n\n    This method is used when `split_dataset()` has not been called before `pre_process()`.\n\n    Returns:\n        The training set is initalized in place.\n    \"\"\"\n\n    self.X_train=copy.deepcopy(self.X)\n    self.y_train=copy.deepcopy(self.y)\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.initialize_train_test","title":"<code>initialize_train_test()</code>","text":"<p>Initialize the training and test sets with the original dataset. </p> <p>This method is used when <code>split_dataset()</code> has not been called before <code>pre_process()</code>.</p> <p>Returns:</p> Type Description <code>None</code> <p>The training and test sets are initialized in place.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def initialize_train_test(self) -&gt; None:\n\n    \"\"\"\n    Initialize the training and test sets with the original dataset. \n\n    This method is used when `split_dataset()` has not been called before `pre_process()`.\n\n    Returns:\n        The training and test sets are initialized in place.\n    \"\"\"\n    # Ensure that X and y are not None\n    if self.X is None or self.y is None:\n        print(\"Dataset not loaded.\")\n        return\n    if self.X_train is None:\n        self.initialize_train()\n    if self.X_test is None:\n        self.initialize_test()\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.load","title":"<code>load()</code>","text":"<p>Load the dataset from the file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the dataset file is not found.</p> <code>Exception</code> <p>If the dataset name is not valid.</p> <p>Returns:</p> Type Description <code>None</code> <p>The dataset is loaded in place.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def load(self) -&gt; None:\n    \"\"\"\n    Load the dataset from the file.\n\n    Raises:\n        FileNotFoundError: If the dataset file is not found.\n        Exception: If the dataset name is not valid.\n\n    Returns:\n        The dataset is loaded in place.\n    \"\"\"\n    try:\n        datapath = self.path + self.name + \".mat\"\n        try:\n            mat = loadmat(datapath)\n        except NotImplementedError:\n            mat = mat73.loadmat(datapath)\n\n        self.X = mat['X'].astype(float)\n        self.y = mat['y'].reshape(-1, 1).astype(float)\n    except FileNotFoundError:\n        try:\n            datapath = self.path + self.name + \".csv\"\n            T = pd.read_csv(datapath)\n            if 'Unnamed: 0' in T.columns:\n                T = T.drop(columns=['Unnamed: 0'])\n            self.X = T['X'].to_numpy(dtype=float)\n            self.y = T['y'].to_numpy(dtype=float).reshape(-1, 1)\n        except Exception as e:\n            try:\n                datapath = self.path + self.name + \".csv\"\n                if self.name == \"glass\":\n                    T = pd.read_csv(datapath)\n                else:\n                    T = pd.read_csv(datapath,index_col=0)\n                if 'Unnamed: 0' in T.columns:\n                    T = T.drop(columns=['Unnamed: 0'])\n                self.X = T.loc[:,T.columns != \"Target\"].to_numpy(float)\n                self.y = T.loc[:,\"Target\"].to_numpy(float)\n            except:\n                raise Exception(\"The dataset name is not valid\") from e\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.pre_process","title":"<code>pre_process()</code>","text":"<p>Normalize the data using <code>StansardScaler()</code> from <code>sklearn.preprocessing</code>.</p> <p>Returns:</p> Type Description <code>None</code> <p>The dataset is normalized in place.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def pre_process(self) -&gt; None:\n\n    \"\"\"\n    Normalize the data using `StansardScaler()` from `sklearn.preprocessing`.\n\n    Returns:\n       The dataset is normalized in place.\n    \"\"\"\n\n    # Ensure that X and y are not None\n    if self.X is None or self.y is None:\n        print(\"Dataset not loaded.\")\n        return\n    if self.X_train is None:\n        self.initialize_train_test()\n    if self.X_test is None:\n        self.initialize_test()\n\n    scaler = StandardScaler()\n\n    self.X_train=scaler.fit_transform(self.X_train)\n    self.X_test=scaler.transform(self.X_test)\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.print_dataset_resume","title":"<code>print_dataset_resume()</code>","text":"<p>Print a summary of the dataset.</p> <p>The summary includes the number of samples, the number of features, the number of inliers and outliers and some summary statistics of the features.</p> <p>Returns:</p> Type Description <code>None</code> <p>The dataset summary is printed.</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def print_dataset_resume(self) -&gt; None:\n    \"\"\"\n    Print a summary of the dataset.\n\n    The summary includes the number of samples, the number of features, the number of inliers and outliers and some\n    summary statistics of the features.\n\n    Returns:\n        The dataset summary is printed.\n\n    \"\"\"\n    # Ensure that X and y are not None\n    if self.X is None or self.y is None:\n        print(\"Dataset not loaded.\")\n        return\n\n    # Basic statistics\n    num_samples = len(self.X)\n    num_features = self.X.shape[1] if self.X is not None else 0\n    num_inliers = np.sum(self.y == 0)\n    num_outliers = np.sum(self.y == 1)\n    balance_ratio = num_outliers / num_samples\n\n    # Aggregate statistics for features in X\n    mean_values = np.mean(self.X, axis=0)\n    std_dev_values = np.std(self.X, axis=0)\n    min_values = np.min(self.X, axis=0)\n    max_values = np.max(self.X, axis=0)\n\n    # Compact representation of statistics\n    mean_val = np.mean(mean_values)\n    std_dev_val = np.mean(std_dev_values)\n    min_val = np.min(min_values)\n    max_val = np.max(max_values)\n\n    # Print the summary\n    print(f\"Dataset Summary for '{self.name}':\")\n    print(f\" Total Samples: {num_samples}, Features: {num_features}\")\n    print(f\" Inliers: {num_inliers}, Outliers: {num_outliers}, Balance Ratio: {balance_ratio:.2f}\")\n    print(f\" Feature Stats - Mean: {mean_val:.2f}, Std Dev: {std_dev_val:.2f}, Min: {min_val}, Max: {max_val}\")\n</code></pre>"},{"location":"datasets/#utils_reboot.datasets.Dataset.split_dataset","title":"<code>split_dataset(train_size=0.8, contamination=0.1)</code>","text":"<p>Split the dataset into training and test sets with a given train size and contamination factor.</p> <p>Parameters:</p> Name Type Description Default <code>train_size</code> <code>float</code> <p>The proportion of the dataset to include in the training set.</p> <code>0.8</code> <code>contamination</code> <code>float</code> <p>The proportion of outliers in the dataset.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>None</code> <p>The dataset is split into training and test sets in place</p> Source code in <code>utils_reboot/datasets.py</code> <pre><code>def split_dataset(self, \n                  train_size:float = 0.8, \n                  contamination:float = 0.1) -&gt; None:\n\n    \"\"\"\n    Split the dataset into training and test sets with a given train size and contamination factor.\n\n    Args:\n        train_size: The proportion of the dataset to include in the training set.\n        contamination: The proportion of outliers in the dataset.\n\n    Returns:\n        The dataset is split into training and test sets in place\n\n    \"\"\"\n    # Ensure that X and y are not None\n    if self.X is None or self.y is None:\n        print(\"Dataset not loaded.\")\n        return\n\n    # Check if train_size is correct\n    if train_size &gt; 1 - self.perc_outliers:\n        print(\"Train size is too large. Setting it at 1-dataset.perc_outliers.\")\n        train_size = 1 - self.perc_outliers\n\n    indexes_outliers = np.where(self.y==1)[0].tolist()\n    indexes_inliers = np.where(self.y==0)[0].tolist()\n    random.shuffle(indexes_outliers)\n    random.shuffle(indexes_inliers)\n    dim_train = int(len(self.X)*train_size)\n    self.X_train = np.zeros((dim_train,self.X.shape[1]))\n    self.y_train = np.zeros(dim_train)\n    for i in range(dim_train):\n        if i &lt; dim_train*contamination and len(indexes_outliers) &gt; 0:\n            index = indexes_outliers.pop()\n        else:\n            index = indexes_inliers.pop()\n        self.X_train[i] = self.X[index]\n        self.y_train[i] = self.y[index]\n</code></pre>"},{"location":"experiments/","title":"Experiments","text":"<p>The <code>experiments</code> module contains the methods used to perform all the experiments outlined in the paper. </p>"},{"location":"experiments/#utils_reboot.experiments.ablation_EIF_plus","title":"<code>ablation_EIF_plus(I, dataset, eta_list, nruns=10)</code>","text":"<p>Compute the average precision scores for different values of the eta parameter in the EIF+ model.</p> <p>Parameters:</p> Name Type Description Default <code>I</code> <code>Type[ExtendedIsolationForest]</code> <p>The AD model.</p> required <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset.</p> required <code>eta_list</code> <code>list[float]</code> <p>The list of eta values.</p> required <code>nruns</code> <code>int</code> <p>The number of runs. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[array]</code> <p>The average precision scores.</p> Source code in <code>utils_reboot/experiments.py</code> <pre><code>def ablation_EIF_plus(I:Type[ExtendedIsolationForest], \n                      dataset:Type[Dataset], \n                      eta_list:list[float], \n                      nruns:int=10) -&gt; list[np.array]:\n\n    \"\"\"\n    Compute the average precision scores for different values of the eta parameter in the EIF+ model.\n\n    Args:\n        I: The AD model.\n        dataset: Input dataset.\n        eta_list: The list of eta values.\n        nruns: The number of runs. Defaults to 10.\n\n    Returns:\n        The average precision scores.\n    \"\"\"\n\n    precisions = []\n    for eta in tqdm(eta_list):\n        precision = []\n        for run in range(nruns):\n            I.eta = eta\n            I.fit(dataset.X_train)\n            score = I.predict(dataset.X_test)\n            precision.append(average_precision_score(dataset.y_test, score))\n        precisions.append(precision)\n    return precisions\n</code></pre>"},{"location":"experiments/#utils_reboot.experiments.compute_global_importances","title":"<code>compute_global_importances(I, dataset, p=0.1, interpretation='EXIFFI+', fit_model=True)</code>","text":"<p>Compute the global feature importances for an interpration model on a specific dataset.</p> <p>Parameters:</p> Name Type Description Default <code>I</code> <code>Type[ExtendedIsolationForest]</code> <p>The AD model.</p> required <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset.</p> required <code>p</code> <p>The percentage of outliers in the dataset (i.e. contamination factor). Defaults to 0.1.</p> <code>0.1</code> <code>interpretation</code> <p>Name of the interpretation method to be used. Defaults to \"EXIFFI+\".</p> <code>'EXIFFI+'</code> <code>fit_model</code> <p>Whether to fit the model on the dataset. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>array</code> <p>The global feature importance vector.</p> Source code in <code>utils_reboot/experiments.py</code> <pre><code>def compute_global_importances(I: Type[ExtendedIsolationForest],\n                        dataset: Type[Dataset],\n                        p = 0.1,\n                        interpretation=\"EXIFFI+\",\n                        fit_model = True) -&gt; np.array: \n\n    \"\"\"\n    Compute the global feature importances for an interpration model on a specific dataset.\n\n    Args:\n        I: The AD model.\n        dataset: Input dataset.\n        p: The percentage of outliers in the dataset (i.e. contamination factor). Defaults to 0.1.\n        interpretation: Name of the interpretation method to be used. Defaults to \"EXIFFI+\".\n        fit_model: Whether to fit the model on the dataset. Defaults to True.\n\n    Returns:\n        The global feature importance vector.\n\n    \"\"\"\n\n    if fit_model:\n        I.fit(dataset.X_train)        \n    if interpretation==\"DIFFI\":\n        fi,_=diffi_ib(I,dataset.X_test)\n    elif interpretation==\"EXIFFI\" or interpretation=='EXIFFI+':\n        fi=I.global_importances(dataset.X_test,p)\n    elif interpretation==\"RandomForest\":\n        rf = RandomForestRegressor()\n        rf.fit(dataset.X_test, I.predict(dataset.X_test))\n        fi = rf.feature_importances_\n    return fi\n</code></pre>"},{"location":"experiments/#utils_reboot.experiments.compute_plt_data","title":"<code>compute_plt_data(imp_path)</code>","text":"<p>Compute statistics on the global feature importances obtained from experiment_global_importances. These will then be used in the score_plot method. </p> <p>Parameters:</p> Name Type Description Default <code>imp_path</code> <code>str</code> <p>The path to the importances file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The dictionary containing the mean importances, the feature order, and the standard deviation of the importances.</p> Source code in <code>utils_reboot/experiments.py</code> <pre><code>def compute_plt_data(imp_path:str) -&gt; dict:\n\n    \"\"\"\n    Compute statistics on the global feature importances obtained from experiment_global_importances. These will then be used in the score_plot method. \n\n    Args:\n        imp_path: The path to the importances file.\n\n    Returns:\n        The dictionary containing the mean importances, the feature order, and the standard deviation of the importances.\n    \"\"\"\n\n    try:\n        fi = np.load(imp_path)['element']\n    except:\n        print(\"Error: importances file should be npz\")\n    # Handle the case in which there are some np.nan in the fi array\n    if np.isnan(fi).any():\n        #Substitute the np.nan values with 0  \n        #fi=np.nan_to_num(fi,nan=0)\n        mean_imp = np.nanmean(fi,axis=0)\n        std_imp = np.nanstd(fi,axis=0)\n    else:\n        mean_imp = np.mean(fi,axis=0)\n        std_imp = np.std(fi,axis=0)\n\n    feat_ordered = mean_imp.argsort()\n    mean_ordered = mean_imp[feat_ordered]\n    std_ordered = std_imp[feat_ordered]\n\n    plt_data={'Importances': mean_ordered,\n                'feat_order': feat_ordered,\n                'std': std_ordered}\n    return plt_data\n</code></pre>"},{"location":"experiments/#utils_reboot.experiments.contamination_in_training_precision_evaluation","title":"<code>contamination_in_training_precision_evaluation(I, dataset, n_runs=10, train_size=0.8, contamination_values=np.linspace(0.0, 0.1, 10), compute_GFI=False, interpretation='EXIFFI+', pre_process=True)</code>","text":"<p>Evaluate the average precision of the model on the dataset for different contamination values in the training set.  The precision values will then be used in the <code>plot_precision_over_contamination</code> method</p> <p>Parameters:</p> Name Type Description Default <code>I</code> <code>Type[ExtendedIsolationForest]</code> <p>The AD model.</p> required <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset.</p> required <code>n_runs</code> <code>int</code> <p>The number of runs. Defaults to 10.</p> <code>10</code> <code>train_size</code> <p>The size of the training set. Defaults to 0.8.</p> <code>0.8</code> <code>contamination_values</code> <code>NDArray</code> <p>The contamination values. Defaults to <code>np.linspace(0.0,0.1,10)</code>.</p> <code>linspace(0.0, 0.1, 10)</code> <code>compute_GFI</code> <code>bool</code> <p>Whether to compute the global feature importances. Defaults to False.</p> <code>False</code> <code>interpretation</code> <code>str</code> <p>Name of the interpretation method to be used. Defaults to \"EXIFFI+\".</p> <code>'EXIFFI+'</code> <code>pre_process</code> <code>bool</code> <p>Whether to pre process the dataset. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[tuple[ndarray, ndarray], ndarray]</code> <p>The average precision scores and the global feature importances if <code>compute_GFI</code> is True, </p> <code>Union[tuple[ndarray, ndarray], ndarray]</code> <p>otherwise just the average precision scores are returned.</p> Source code in <code>utils_reboot/experiments.py</code> <pre><code>def contamination_in_training_precision_evaluation(I: Type[ExtendedIsolationForest],\n                                                   dataset: Type[Dataset],\n                                                   n_runs: int = 10,\n                                                   train_size = 0.8,\n                                                   contamination_values: npt.NDArray = np.linspace(0.0,0.1,10),\n                                                   compute_GFI:bool=False,\n                                                   interpretation:str=\"EXIFFI+\",\n                                                   pre_process:bool=True,\n                                                   ) -&gt; Union[tuple[np.ndarray, np.ndarray], np.ndarray]:\n\n    \"\"\"\n    Evaluate the average precision of the model on the dataset for different contamination values in the training set. \n    The precision values will then be used in the `plot_precision_over_contamination` method\n\n    Args:\n        I: The AD model.\n        dataset: Input dataset.\n        n_runs: The number of runs. Defaults to 10.\n        train_size: The size of the training set. Defaults to 0.8.\n        contamination_values: The contamination values. Defaults to `np.linspace(0.0,0.1,10)`.\n        compute_GFI: Whether to compute the global feature importances. Defaults to False.\n        interpretation: Name of the interpretation method to be used. Defaults to \"EXIFFI+\".\n        pre_process: Whether to pre process the dataset. Defaults to True.\n\n    Returns:\n        The average precision scores and the global feature importances if `compute_GFI` is True, \n        otherwise just the average precision scores are returned. \n    \"\"\"\n\n    precisions = np.zeros(shape=(len(contamination_values),n_runs))\n    if compute_GFI:\n        importances = np.zeros(shape=(len(contamination_values),n_runs,len(contamination_values),dataset.X.shape[1]))\n    for i,contamination in tqdm(enumerate(contamination_values)):\n        for j in range(n_runs):\n            dataset.split_dataset(train_size,contamination)\n            dataset.initialize_test()\n\n            if pre_process:\n                dataset.pre_process()\n\n            start_time = time.time()\n            I.fit(dataset.X_train)\n            fit_time = time.time() - start_time\n\n            if j&gt;3:\n                try:\n                    dict_time[\"fit\"][I.name].setdefault(dataset.name, []).append(fit_time)\n                except:\n                    print('Model not recognized: creating a new key in the dict_time for the new model')\n                    dict_time[\"fit\"].setdefault(I.name, {}).setdefault(dataset.name, []).append(fit_time)\n\n            if compute_GFI:\n                for k,c in enumerate(contamination_values):\n                    start_time = time.time()\n                    importances[i,j,k,:] = compute_global_importances(I,\n                                                                    dataset,\n                                                                    p=c,\n                                                                    interpretation=interpretation,\n                                                                    fit_model=False)\n                    gfi_time = time.time() - start_time\n                    if k&gt;3: \n                        dict_time[\"importances\"][interpretation].setdefault(dataset.name, []).append(gfi_time)\n\n            start_time = time.time()\n            score = I.predict(dataset.X_test)\n            predict_time = time.time() - start_time\n            if j&gt;3:\n                try:\n                    dict_time[\"predict\"][I.name].setdefault(dataset.name, []).append(predict_time)\n                except:\n                    print('Model not recognized: creating a new key in the dict_time for the new model')\n                    dict_time[\"predict\"].setdefault(I.name, {}).setdefault(dataset.name, []).append(predict_time)\n\n            avg_prec = sklearn.metrics.average_precision_score(dataset.y_test,score)\n            precisions[i,j] = avg_prec\n\n    with open(filename, \"wb\") as file:\n        pickle.dump(dict_time, file)\n    if compute_GFI:\n        return precisions,importances\n    return precisions\n</code></pre>"},{"location":"experiments/#utils_reboot.experiments.experiment_global_importances","title":"<code>experiment_global_importances(I, dataset, n_runs=10, p=0.1, model='EIF+', interpretation='EXIFFI+')</code>","text":"<p>Compute the global feature importances for an interpration model on a specific dataset for a number of runs.</p> <p>Parameters:</p> Name Type Description Default <code>I</code> <code>Type[ExtendedIsolationForest]</code> <p>The AD model.</p> required <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset.</p> required <code>n_runs</code> <code>int</code> <p>The number of runs. Defaults to 10.</p> <code>10</code> <code>p</code> <code>float</code> <p>The percentage of outliers in the dataset (i.e. contamination factor). Defaults to 0.1.</p> <code>0.1</code> <code>model</code> <code>str</code> <p>The name of the model. Defaults to 'EIF+'.</p> <code>'EIF+'</code> <code>interpretation</code> <code>str</code> <p>Name of the interpretation method to be used. Defaults to \"EXIFFI+\".</p> <code>'EXIFFI+'</code> <p>Returns:</p> Type Description <code>tuple[array, dict, str, str]</code> <p>The global feature importances vectors for the different runs and the average importances times.</p> Source code in <code>utils_reboot/experiments.py</code> <pre><code>def experiment_global_importances(I:Type[ExtendedIsolationForest],\n                               dataset:Type[Dataset],\n                               n_runs:int=10, \n                               p:float=0.1,\n                               model:str=\"EIF+\",\n                               interpretation:str=\"EXIFFI+\"\n                               ) -&gt; tuple[np.array,dict,str,str]:\n\n    \"\"\"\n    Compute the global feature importances for an interpration model on a specific dataset for a number of runs.\n\n    Args:\n        I: The AD model.\n        dataset: Input dataset.\n        n_runs: The number of runs. Defaults to 10.\n        p: The percentage of outliers in the dataset (i.e. contamination factor). Defaults to 0.1.\n        model: The name of the model. Defaults to 'EIF+'.\n        interpretation: Name of the interpretation method to be used. Defaults to \"EXIFFI+\".\n\n    Returns:\n        The global feature importances vectors for the different runs and the average importances times.\n    \"\"\"\n    fi=np.zeros(shape=(n_runs,dataset.X.shape[1]))\n    imp_times=[]\n    for i in tqdm(range(n_runs)):\n        start_time = time.time()\n        fi[i,:]=compute_global_importances(I,\n                        dataset,\n                        p = p,\n                        interpretation=interpretation)\n        gfi_time = time.time() - start_time\n        if i&gt;3:\n            imp_times.append(gfi_time)\n            if (model==\"IF\") and (interpretation==\"EXIFFI\"):\n                dict_time[\"importances\"][\"IF_EXIFFI\"].setdefault(dataset.name, []).append(gfi_time)\n            else:\n                dict_time[\"importances\"][interpretation].setdefault(dataset.name, []).append(gfi_time)\n            #print(f'Added time {str(gfi_time)} to time dict')\n\n    with open(filename, \"wb\") as file:\n        pickle.dump(dict_time, file)\n    return fi,np.mean(imp_times)\n</code></pre>"},{"location":"experiments/#utils_reboot.experiments.feature_selection","title":"<code>feature_selection(I, dataset, importances_indexes, n_runs=10, inverse=True, random=False, scenario=2)</code>","text":"<p>Perform feature selection on the dataset by dropping features in order of importance.</p> <p>Parameters:</p> Name Type Description Default <code>I</code> <code>Type[ExtendedIsolationForest]</code> <p>The AD model.</p> required <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset.</p> required <code>importances_indexes</code> <code>NDArray</code> <p>The indexes of the features in the dataset.</p> required <code>n_runs</code> <code>int</code> <p>The number of runs. Defaults to 10.</p> <code>10</code> <code>inverse</code> <code>bool</code> <p>Whether to drop the features in decreasing order of importance. Defaults to True.</p> <code>True</code> <code>random</code> <code>bool</code> <p>Whether to drop the features in random order. Defaults to False.</p> <code>False</code> <code>scenario</code> <code>int</code> <p>The scenario of the experiment. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Type Description <code>array</code> <p>The average precision scores for the different runs.</p> Source code in <code>utils_reboot/experiments.py</code> <pre><code>def feature_selection(I: Type[ExtendedIsolationForest],\n                      dataset: Type[Dataset],\n                      importances_indexes: npt.NDArray,\n                      n_runs: int = 10, \n                      inverse: bool = True,\n                      random: bool = False,\n                      scenario:int=2\n                      ) -&gt; np.array:\n\n        \"\"\"\n        Perform feature selection on the dataset by dropping features in order of importance.\n\n        Args:\n            I: The AD model.\n            dataset: Input dataset.\n            importances_indexes: The indexes of the features in the dataset.\n            n_runs: The number of runs. Defaults to 10.\n            inverse: Whether to drop the features in decreasing order of importance. Defaults to True.\n            random: Whether to drop the features in random order. Defaults to False.\n            scenario: The scenario of the experiment. Defaults to 2.\n\n        Returns:\n            The average precision scores for the different runs.\n        \"\"\"\n\n        dataset_shrinking = copy.deepcopy(dataset)\n        d = dataset.X.shape[1]\n        precisions = np.zeros(shape=(len(importances_indexes),n_runs))\n        for number_of_features_dropped in tqdm(range(len(importances_indexes))):\n            runs = np.zeros(n_runs)\n            for run in range(n_runs):\n                if random:\n                    importances_indexes = np.random.choice(importances_indexes, len(importances_indexes), replace=False)\n                dataset_shrinking.X = dataset.X_test[:,importances_indexes[:d-number_of_features_dropped]] if not inverse else dataset.X_test[:,importances_indexes[number_of_features_dropped:]]\n                dataset_shrinking.y = dataset.y\n                dataset_shrinking.drop_duplicates()\n\n                if scenario==2:\n                    dataset_shrinking.split_dataset(1-dataset_shrinking.perc_outliers,0)\n                    dataset_shrinking.initialize_test()\n                else:\n                    dataset_shrinking.initialize_train()\n                    dataset_shrinking.initialize_test()\n\n                try:\n                    if dataset.X.shape[1] == dataset_shrinking.X.shape[1]:\n\n                        start_time = time.time()\n                        I.fit(dataset_shrinking.X_train)\n                        fit_time = time.time() - start_time\n\n                        if run &gt;3:\n                            dict_time[\"fit\"][I.name].setdefault(dataset.name, []).append(fit_time)\n                        start_time = time.time()\n                        score = I.predict(dataset_shrinking.X_test)\n                        predict_time = time.time() - start_time\n\n                        if run &gt;3:                        \n                            dict_time[\"predict\"][I.name].setdefault(dataset.name, []).append(predict_time)\n                    else:\n                        I.fit(dataset_shrinking.X_train)\n                        score = I.predict(dataset_shrinking.X_test)\n                    avg_prec = sklearn.metrics.average_precision_score(dataset_shrinking.y,score)\n                    runs[run] = avg_prec\n                except:\n                    runs[run] = np.nan\n\n            precisions[number_of_features_dropped] = runs\n\n        with open(filename, \"wb\") as file:\n            pickle.dump(dict_time, file)\n        return precisions\n</code></pre>"},{"location":"experiments/#utils_reboot.experiments.fit_predict_experiment","title":"<code>fit_predict_experiment(I, dataset, n_runs=40, model='EIF+')</code>","text":"<p>Fit and predict the model on the dataset for a number of runs and keep track of the fit and predict times.</p> <p>Parameters:</p> Name Type Description Default <code>I</code> <code>Type[ExtendedIsolationForest]</code> <p>The AD model.</p> required <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset.</p> required <code>n_runs</code> <code>int</code> <p>The number of runs. Defaults to 40.</p> <code>40</code> <code>model</code> <p>The name of the model. Defaults to 'EIF+'.</p> <code>'EIF+'</code> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>The average fit and predict time.</p> Source code in <code>utils_reboot/experiments.py</code> <pre><code>def fit_predict_experiment(I: Type[ExtendedIsolationForest],\n                            dataset: Type[Dataset],\n                            n_runs:int = 40,\n                            model='EIF+') -&gt; tuple[float,float]:\n\n    \"\"\"\n    Fit and predict the model on the dataset for a number of runs and keep track of the fit and predict times.\n\n    Args:\n        I: The AD model.\n        dataset: Input dataset.\n        n_runs: The number of runs. Defaults to 40.\n        model: The name of the model. Defaults to 'EIF+'.\n\n    Returns:\n        The average fit and predict time.\n    \"\"\"\n\n    fit_times = []\n    predict_times = []\n\n    for i in trange(n_runs):\n        start_time = time.time()\n        I.fit(dataset.X_train)\n        fit_time = time.time() - start_time\n        if i&gt;3:  \n            fit_times.append(fit_time)\n            dict_time[\"fit\"][I.name].setdefault(dataset.name, []).append(fit_time) \n\n        start_time = time.time()\n        if model in ['EIF','EIF+']:\n            _=I._predict(dataset.X_test,p=dataset.perc_outliers)\n            predict_time = time.time() - start_time\n        elif model in ['sklearn_IF','DIF','AnomalyAutoencoder']:\n            _=I.predict(dataset.X_test)\n            predict_time = time.time() - start_time\n\n        if i&gt;3:\n            predict_times.append(predict_time)\n            dict_time[\"predict\"][I.name].setdefault(dataset.name, []).append(predict_time)\n\n    with open(filename, \"wb\") as file:\n        pickle.dump(dict_time, file)\n\n    return np.mean(fit_times), np.mean(predict_times)\n</code></pre>"},{"location":"experiments/#utils_reboot.experiments.performance","title":"<code>performance(y_pred, y_true, score, I, model_name, dataset, contamination=0.1, train_size=0.8, scenario=2, n_runs=10, filename='', path=os.getcwd(), save=True)</code>","text":"<p>Compute the performance metrics of the model on the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>array</code> <p>The predicted labels.</p> required <code>y_true</code> <code>array</code> <p>The true labels.</p> required <code>score</code> <code>array</code> <p>The Anomaly Scores.</p> required <code>I</code> <code>Type[ExtendedIsolationForest]</code> <p>The AD model.</p> required <code>model_name</code> <code>str</code> <p>The name of the model.</p> required <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset.</p> required <code>contamination</code> <code>float</code> <p>The contamination factor. Defaults to 0.1.</p> <code>0.1</code> <code>train_size</code> <code>float</code> <p>The size of the training set. Defaults to 0.8.</p> <code>0.8</code> <code>scenario</code> <code>int</code> <p>The scenario of the experiment. Defaults to 2.</p> <code>2</code> <code>n_runs</code> <code>int</code> <p>The number of runs. Defaults to 10.</p> <code>10</code> <code>filename</code> <code>str</code> <p>The filename. Defaults to \"\".</p> <code>''</code> <code>path</code> <code>str</code> <p>The path to the experiments folder. Defaults to os.getcwd().</p> <code>getcwd()</code> <code>save</code> <code>bool</code> <p>Whether to save the results. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, str]</code> <p>The performance metrics and the path to the results.</p> Source code in <code>utils_reboot/experiments.py</code> <pre><code>def performance(y_pred:np.array,\n                y_true:np.array,\n                score:np.array,\n                I:Type[ExtendedIsolationForest],\n                model_name:str,\n                dataset:Type[Dataset],\n                contamination:float=0.1,\n                train_size:float=0.8,\n                scenario:int=2,\n                n_runs:int=10,\n                filename:str=\"\",\n                path:str=os.getcwd(),\n                save:bool=True\n                ) -&gt; tuple[pd.DataFrame,str]: \n\n    \"\"\"\n    Compute the performance metrics of the model on the dataset.\n\n    Args:\n        y_pred: The predicted labels.\n        y_true: The true labels.\n        score: The Anomaly Scores.\n        I: The AD model.\n        model_name: The name of the model.\n        dataset: Input dataset.\n        contamination: The contamination factor. Defaults to 0.1.\n        train_size: The size of the training set. Defaults to 0.8.\n        scenario: The scenario of the experiment. Defaults to 2.\n        n_runs: The number of runs. Defaults to 10.\n        filename: The filename. Defaults to \"\".\n        path: The path to the experiments folder. Defaults to os.getcwd().\n        save: Whether to save the results. Defaults to True.\n\n    Returns:\n        The performance metrics and the path to the results.\n    \"\"\"\n\n    y_pred=y_pred.astype(int)\n    y_true=y_true.astype(int)\n\n    if dataset.X.shape[0]&gt;7500:\n        dataset.downsample(max_samples=7500)\n\n    precisions=[]\n    for i in trange(n_runs):\n        I.fit(dataset.X_train)\n        if model_name in ['DIF','AnomalyAutoencoder']:\n            score = I.decision_function(dataset.X_test)\n        else:\n            score = I.predict(dataset.X_test)\n        precisions.append(average_precision_score(y_true, score))\n\n    df=pd.DataFrame({\n        \"Model\": model_name,\n        \"Dataset\": dataset.name,\n        \"Contamination\": contamination,\n        \"Train Size\": train_size,\n        \"Precision\": precision_score(y_true, y_pred),\n        \"Recall\": recall_score(y_true, y_pred),\n        \"f1 score\": f1_score(y_true, y_pred),\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n        \"Average Precision\": np.mean(precisions),\n        \"ROC AUC Score\": roc_auc_score(y_true, y_pred)\n    }, index=[pd.Timestamp.now()])\n\n    path=path + f\"/experiments/results/{dataset.name}/experiments/metrics/{model_name}/\" + f\"scenario_{str(scenario)}/\"\n\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n    filename=f\"perf_{dataset.name}_{model_name}_{scenario}\"\n\n    if save:\n        save_element(df, path, filename)\n\n    return df,path\n</code></pre>"},{"location":"models/","title":"Models","text":"<p>This section provides an overview of the implementation of IF (class <code>IsolationForest</code>), EIF,EIF+ and EXIFFI (all implemebted in class <code>ExtendedIsolationForest</code>). In order to achieve a speed up in the computations the <code>numba</code> Pyhton compiler is used.</p>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedIsolationForest","title":"<code>ExtendedIsolationForest</code>","text":"<p>Class that represents the Extended Isolation Forest model.</p> <p>Attributes:</p> Name Type Description <code>n_estimators</code> <code>int</code> <p>Number of trees in the model. Defaults to 400</p> <code>max_samples</code> <code>int</code> <p>Maximum number of samples in a node. Defaults to 256</p> <code>max_depth</code> <code>int</code> <p>Maximum depth of the trees. Defaults to \"auto\"</p> <code>plus</code> <code>bool</code> <p>Boolean flag to indicate if the model is a <code>EIF</code> or <code>EIF+</code>.</p> <code>name</code> <code>str</code> <p>Name of the model</p> <code>ids</code> <code>array</code> <p>Leaf node ids for each data point in the dataset. Defaults to None</p> <code>X</code> <code>array</code> <p>Input dataset. Defaults to None</p> <code>eta</code> <code>float</code> <p>Eta value for the model. Defaults to 1.5</p> <code>avg_number_of_nodes</code> <code>int</code> <p>Average number of nodes in the trees</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>class ExtendedIsolationForest():\n\n    \"\"\"\n    Class that represents the Extended Isolation Forest model.\n\n    Attributes:\n        n_estimators (int): Number of trees in the model. Defaults to 400\n        max_samples (int): Maximum number of samples in a node. Defaults to 256\n        max_depth (int): Maximum depth of the trees. Defaults to \"auto\"\n        plus (bool): Boolean flag to indicate if the model is a `EIF` or `EIF+`.\n        name (str): Name of the model\n        ids (np.array): Leaf node ids for each data point in the dataset. Defaults to None\n        X (np.array): Input dataset. Defaults to None\n        eta (float): Eta value for the model. Defaults to 1.5\n        avg_number_of_nodes (int): Average number of nodes in the trees\n\n    \"\"\"\n\n    def __init__(self,\n                 plus:bool,\n                 n_estimators:int=400,\n                 max_depth:Union[str,int]=\"auto\",\n                 max_samples:Union[str,int]=\"auto\",\n                 eta:float = 1.5):\n        self.n_estimators = n_estimators\n        self.max_samples = 256 if max_samples == \"auto\" else max_samples\n        self.max_depth = max_depth\n        self.plus=plus\n        self.name=\"EIF\"+\"+\"*int(plus)\n        self.ids=None\n        self.X=None\n        self.eta=eta\n\n    @property\n    def avg_number_of_nodes(self) -&gt; float:\n        \"\"\"\n        Compute the average number of nodes in the trees.\n\n        Returns:\n            The average number of nodes in the trees.\n\n        \"\"\"\n        return np.mean([T.node_count for T in self.trees])\n\n    def fit(self, X:np.array, locked_dims:int=None) -&gt; None:\n\n        \"\"\"\n        Fit the model to the dataset.\n\n        Args:\n            X: Input dataset\n            locked_dims: Number of dimensions to be locked in the model. Defaults to None\n\n        Returns:\n            The method fits the model and does not return any value.\n        \"\"\"\n\n        self.ids = None\n        if not locked_dims:\n            locked_dims = 0\n\n        if self.max_depth == \"auto\":\n            self.max_depth = int(np.ceil(np.log2(self.max_samples)))\n        subsample_size = np.min((self.max_samples, len(X)))\n        self.trees = [ExtendedTree(subsample_size, X.shape[1], self.max_depth, locked_dims=locked_dims, plus=self.plus, eta=self.eta)\n                      for _ in range(self.n_estimators)]\n        for T in self.trees:\n            T.fit(X[np.random.randint(len(X), size=subsample_size)])\n\n    def compute_ids(self, X:np.array) -&gt; None:\n\n        \"\"\"\n        Compute the leaf node ids for each data point in the dataset.\n\n        Args:\n            X: Input dataset\n\n        Returns:\n            The method computes the leaf node ids and does not return any value.\n        \"\"\"\n        if self.ids is None or self.X.shape != X.shape:\n            self.X = X\n            self.ids = np.array([tree.leaf_ids(X) for tree in self.trees])\n\n    def predict(self, X:np.array) -&gt; np.array:\n\n        \"\"\"\n        Predict the anomaly score for each data point in the dataset.\n\n        Args:\n            X: Input dataset\n\n        Returns:\n            Anomaly score for each data point in the dataset.\n        \"\"\"\n        self.compute_ids(X)\n        #predictions=[tree.predict(X,self.ids[i]) for i,tree in enumerate(self.trees)]\n        predictions=[tree.predict(self.ids[i]) for i,tree in enumerate(self.trees)]\n        values = np.array([p[0] for p in predictions])\n        return np.power(2,-np.mean([value for value in values], axis=0))\n\n    def _predict(self,\n                 X:np.array,\n                 p:float) -&gt; np.array:\n        \"\"\"\n        Predict the class of each data point (i.e. inlier or outlier) based on the anomaly score.\n\n        Args:\n            X: Input dataset\n            p: Proportion of outliers (i.e. threshold for the anomaly score)\n\n        Returns:\n           Class labels (i.e. 0 for inliers and 1 for outliers)\n        \"\"\"\n        An_score = self.predict(X)\n        y_hat = An_score &gt; sorted(An_score,reverse=True)[int(p*len(An_score))]\n        return y_hat\n\n    def _importances(self,\n                     X:np.array,\n                     ids:np.array) -&gt; tuple[np.array,np.array]:\n\n        \"\"\"\n        Compute the importances of the features for the given leaf node ids.\n\n        Args:\n            X: Input dataset\n            ids: Leaf node ids for each data point in the dataset.\n\n        Returns:\n            Importances of the features for the given leaf node ids and the normal vectors.\n\n        \"\"\"\n        importances = np.zeros(X.shape)\n        normals = np.zeros(X.shape)\n        for i,T in enumerate(self.trees):\n            importance, normal = T.importances(ids[i])\n            importances += importance\n            normals += normal\n        return importances/self.n_estimators, normals/self.n_estimators\n\n    def global_importances(self,\n                           X:np.array,\n                           p:float=0.1) -&gt; np.array:\n\n        \"\"\"\n        Compute the global importances of the features for the dataset.\n\n        Args:\n            X: Input dataset\n            p: Proportion of outliers (i.e. threshold for the anomaly score). Defaults to 0.1\n\n        Returns:\n            Global importances of the features for the dataset.\n        \"\"\"\n\n        self.compute_ids(X)\n        y_hat = self._predict(X,p)\n        importances, normals = self._importances(X, self.ids)\n        outliers_importances,outliers_normals = np.sum(importances[y_hat],axis=0),np.sum(normals[y_hat],axis=0) \n        inliers_importances,inliers_normals = np.sum(importances[~y_hat],axis=0),np.sum(normals[~y_hat],axis=0)\n        return (outliers_importances/outliers_normals)/(inliers_importances/inliers_normals)\n\n    def local_importances(self,\n                          X:np.array) -&gt; np.array:\n\n        \"\"\"\n        Compute the local importances of the features for the dataset.\n\n        Args:\n            X: Input dataset\n\n        Returns:\n           Local importances of the features for the dataset.\n        \"\"\"\n\n        self.compute_ids(X)\n        importances, normals = self._importances(X, self.ids)\n        return importances/normals\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedIsolationForest.avg_number_of_nodes","title":"<code>avg_number_of_nodes: float</code>  <code>property</code>","text":"<p>Compute the average number of nodes in the trees.</p> <p>Returns:</p> Type Description <code>float</code> <p>The average number of nodes in the trees.</p>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedIsolationForest.compute_ids","title":"<code>compute_ids(X)</code>","text":"<p>Compute the leaf node ids for each data point in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>None</code> <p>The method computes the leaf node ids and does not return any value.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def compute_ids(self, X:np.array) -&gt; None:\n\n    \"\"\"\n    Compute the leaf node ids for each data point in the dataset.\n\n    Args:\n        X: Input dataset\n\n    Returns:\n        The method computes the leaf node ids and does not return any value.\n    \"\"\"\n    if self.ids is None or self.X.shape != X.shape:\n        self.X = X\n        self.ids = np.array([tree.leaf_ids(X) for tree in self.trees])\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedIsolationForest.fit","title":"<code>fit(X, locked_dims=None)</code>","text":"<p>Fit the model to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <code>locked_dims</code> <code>int</code> <p>Number of dimensions to be locked in the model. Defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>The method fits the model and does not return any value.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def fit(self, X:np.array, locked_dims:int=None) -&gt; None:\n\n    \"\"\"\n    Fit the model to the dataset.\n\n    Args:\n        X: Input dataset\n        locked_dims: Number of dimensions to be locked in the model. Defaults to None\n\n    Returns:\n        The method fits the model and does not return any value.\n    \"\"\"\n\n    self.ids = None\n    if not locked_dims:\n        locked_dims = 0\n\n    if self.max_depth == \"auto\":\n        self.max_depth = int(np.ceil(np.log2(self.max_samples)))\n    subsample_size = np.min((self.max_samples, len(X)))\n    self.trees = [ExtendedTree(subsample_size, X.shape[1], self.max_depth, locked_dims=locked_dims, plus=self.plus, eta=self.eta)\n                  for _ in range(self.n_estimators)]\n    for T in self.trees:\n        T.fit(X[np.random.randint(len(X), size=subsample_size)])\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedIsolationForest.global_importances","title":"<code>global_importances(X, p=0.1)</code>","text":"<p>Compute the global importances of the features for the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <code>p</code> <code>float</code> <p>Proportion of outliers (i.e. threshold for the anomaly score). Defaults to 0.1</p> <code>0.1</code> <p>Returns:</p> Type Description <code>array</code> <p>Global importances of the features for the dataset.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def global_importances(self,\n                       X:np.array,\n                       p:float=0.1) -&gt; np.array:\n\n    \"\"\"\n    Compute the global importances of the features for the dataset.\n\n    Args:\n        X: Input dataset\n        p: Proportion of outliers (i.e. threshold for the anomaly score). Defaults to 0.1\n\n    Returns:\n        Global importances of the features for the dataset.\n    \"\"\"\n\n    self.compute_ids(X)\n    y_hat = self._predict(X,p)\n    importances, normals = self._importances(X, self.ids)\n    outliers_importances,outliers_normals = np.sum(importances[y_hat],axis=0),np.sum(normals[y_hat],axis=0) \n    inliers_importances,inliers_normals = np.sum(importances[~y_hat],axis=0),np.sum(normals[~y_hat],axis=0)\n    return (outliers_importances/outliers_normals)/(inliers_importances/inliers_normals)\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedIsolationForest.local_importances","title":"<code>local_importances(X)</code>","text":"<p>Compute the local importances of the features for the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>array</code> <p>Local importances of the features for the dataset.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def local_importances(self,\n                      X:np.array) -&gt; np.array:\n\n    \"\"\"\n    Compute the local importances of the features for the dataset.\n\n    Args:\n        X: Input dataset\n\n    Returns:\n       Local importances of the features for the dataset.\n    \"\"\"\n\n    self.compute_ids(X)\n    importances, normals = self._importances(X, self.ids)\n    return importances/normals\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedIsolationForest.predict","title":"<code>predict(X)</code>","text":"<p>Predict the anomaly score for each data point in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>array</code> <p>Anomaly score for each data point in the dataset.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def predict(self, X:np.array) -&gt; np.array:\n\n    \"\"\"\n    Predict the anomaly score for each data point in the dataset.\n\n    Args:\n        X: Input dataset\n\n    Returns:\n        Anomaly score for each data point in the dataset.\n    \"\"\"\n    self.compute_ids(X)\n    #predictions=[tree.predict(X,self.ids[i]) for i,tree in enumerate(self.trees)]\n    predictions=[tree.predict(self.ids[i]) for i,tree in enumerate(self.trees)]\n    values = np.array([p[0] for p in predictions])\n    return np.power(2,-np.mean([value for value in values], axis=0))\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedTree","title":"<code>ExtendedTree</code>","text":"<p>Class that represents an Isolation Tree in the Extended Isolation Forest model.</p> <p>Attributes:</p> Name Type Description <code>plus</code> <code>bool</code> <p>Boolean flag to indicate if the model is a <code>EIF</code> or <code>EIF+</code>. Defaults to True (i.e. <code>EIF+</code>)</p> <code>locked_dims</code> <code>int</code> <p>Number of dimensions to be locked in the model. Defaults to 0</p> <code>max_depth</code> <code>int</code> <p>Maximum depth of the tree</p> <code>min_sample</code> <code>int</code> <p>Minimum number of samples in a node. Defaults to 1</p> <code>n</code> <code>int</code> <p>Number of samples in the dataset</p> <code>d</code> <code>int</code> <p>Number of dimensions in the dataset</p> <code>node_count</code> <code>int</code> <p>Counter for the number of nodes in the tree</p> <code>max_nodes</code> <code>int</code> <p>Maximum number of nodes in the tree. Defaults to 10000</p> <code>path_to</code> <code>array</code> <p>Array to store the path to the leaf nodes</p> <code>path_to_Right_Left</code> <code>array</code> <p>Array to store the path to the leaf nodes with directions</p> <code>child_left</code> <code>array</code> <p>Array to store the left child nodes</p> <code>child_right</code> <code>array</code> <p>Array to store the right child nodes</p> <code>normals</code> <code>array</code> <p>Array to store the normal vectors of the splitting hyperplanes</p> <code>intercepts</code> <code>array</code> <p>Array to store the intercept values of the splitting hyperplanes</p> <code>node_size</code> <code>array</code> <p>Array to store the size of the nodes</p> <code>depth</code> <code>array</code> <p>Array to store the depth of the nodes</p> <code>corrected_depth</code> <code>array</code> <p>Array to store the corrected depth of the nodes</p> <code>importances_right</code> <code>array</code> <p>Array to store the importances of the right child nodes</p> <code>importances_left</code> <code>array</code> <p>Array to store the importances of the left child nodes</p> <code>eta</code> <code>float</code> <p>Eta value for the model. Defaults to 1.5</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>@jitclass(tree_spec)\nclass ExtendedTree:\n\n    \"\"\"\n    Class that represents an Isolation Tree in the Extended Isolation Forest model.\n\n\n    Attributes:\n        plus (bool): Boolean flag to indicate if the model is a `EIF` or `EIF+`. Defaults to True (i.e. `EIF+`)\n        locked_dims (int): Number of dimensions to be locked in the model. Defaults to 0\n        max_depth (int): Maximum depth of the tree\n        min_sample (int): Minimum number of samples in a node. Defaults to 1\n        n (int): Number of samples in the dataset\n        d (int): Number of dimensions in the dataset\n        node_count (int): Counter for the number of nodes in the tree\n        max_nodes (int): Maximum number of nodes in the tree. Defaults to 10000\n        path_to (np.array): Array to store the path to the leaf nodes\n        path_to_Right_Left (np.array): Array to store the path to the leaf nodes with directions\n        child_left (np.array): Array to store the left child nodes\n        child_right (np.array): Array to store the right child nodes\n        normals (np.array): Array to store the normal vectors of the splitting hyperplanes\n        intercepts (np.array): Array to store the intercept values of the splitting hyperplanes\n        node_size (np.array): Array to store the size of the nodes\n        depth (np.array): Array to store the depth of the nodes\n        corrected_depth (np.array): Array to store the corrected depth of the nodes\n        importances_right (np.array): Array to store the importances of the right child nodes\n        importances_left (np.array): Array to store the importances of the left child nodes\n        eta (float): Eta value for the model. Defaults to 1.5\n\n    \"\"\"\n\n    def __init__(self,\n                 n:int,\n                 d:int,\n                 max_depth:int,\n                 locked_dims:int=0,\n                 min_sample:int=1,\n                 plus:bool=True,\n                 max_nodes:int=10000,\n                 eta:float=1.5):\n\n        self.plus = plus\n        self.locked_dims = locked_dims \n        self.max_depth = max_depth\n        self.min_sample = min_sample\n        self.n = n\n        self.d = d\n        self.node_count = 1\n        self.max_nodes = max_nodes\n        self.eta = eta\n\n        self.path_to = -np.ones((max_nodes, max_depth+1), dtype=np.int64)\n        self.path_to_Right_Left = np.zeros((max_nodes, max_depth+1), dtype=np.int64)\n        self.child_left = np.zeros(max_nodes, dtype=np.int64)\n        self.child_right = np.zeros(max_nodes, dtype=np.int64)\n        self.normals = np.zeros((max_nodes, d), dtype=np.float64)\n        self.intercepts = np.zeros(max_nodes, dtype=np.float64)\n        self.node_size = np.zeros(max_nodes, dtype=np.int64)\n        self.depth = np.zeros(max_nodes, dtype=np.int64)\n        self.corrected_depth = np.zeros(max_nodes, dtype=np.float64)\n        self.importances_right = np.zeros((max_nodes, d), dtype=np.float64)\n        self.importances_left = np.zeros((max_nodes, d), dtype=np.float64)\n\n    def fit(self, X:np.array) -&gt; None:\n\n        \"\"\"\n        Fit the model to the dataset.\n\n        Args:\n            X: Input dataset\n\n        Returns:\n            The method fits the model and does not return any value.\n        \"\"\"\n\n        self.path_to[0,0] = 0\n        self.extend_tree(node_id=0, X=X, depth=0)\n        self.corrected_depth = np.array([\n            (c_factor(k)+sum(path&gt;-1))/c_factor(self.n)\n            for i,(k,path) in enumerate(zip(self.node_size,self.path_to))\n            if i&lt;self.node_count\n        ])\n\n    def create_new_node(self,\n                        parent_id:int,\n                        direction:int) -&gt; int:\n\n        \"\"\"\n        Create a new node in the tree.\n\n        Args:\n            parent_id: Parent node id\n            direction: Direction to the new node\n\n        Returns:\n            New node id\n\n        \"\"\"\n\n        new_node_id = self.node_count\n        self.node_count+=1\n        self.path_to[new_node_id] = self.path_to[parent_id]\n        self.path_to_Right_Left[new_node_id] = self.path_to_Right_Left[parent_id]\n        self.path_to[new_node_id, self.depth[parent_id]+1] = new_node_id\n        self.path_to_Right_Left[new_node_id, self.depth[parent_id]] = direction\n        self.depth[new_node_id] = self.depth[parent_id]+1     \n        return new_node_id\n\n    def extend_tree(self,\n                    node_id:int,\n                    X:npt.NDArray,\n                    depth: int) -&gt; None:\n\n        \"\"\"\n        Extend the tree to the given node.\n\n        Args:\n            node_id: Node id\n            X: Input dataset\n            depth: Depth of the node\n\n        Returns:\n            The method extends the tree and does not return any value.\n        \"\"\"\n\n        stack = [(0, X, 0)] \n\n        while stack:\n            node_id, data, depth = stack.pop()\n\n            self.node_size[node_id] = len(data)\n            if self.node_size[node_id] &lt;= self.min_sample or depth &gt;= self.max_depth:\n                continue\n\n            self.normals[node_id] = make_rand_vector(self.d - self.locked_dims, self.d)         \n\n            dist = np.dot(np.ascontiguousarray(data), np.ascontiguousarray(self.normals[node_id]))\n\n            if self.plus:\n                #self.intercepts[node_id] = np.random.normal(np.mean(dist),np.std(dist)*self.eta)\n                self.intercepts[node_id] = np.random.normal(np.mean(dist),np.std(dist)*self.eta)\n            else:\n                self.intercepts[node_id] = np.random.uniform(np.min(dist),np.max(dist))\n            mask = dist &lt;= self.intercepts[node_id]  \n\n            X_left = data[mask]\n            X_right = data[~mask,:]\n\n            self.importances_left[node_id] = np.abs(self.normals[node_id])*(self.node_size[node_id]/(len(X_left)+1))\n            self.importances_right[node_id] = np.abs(self.normals[node_id])*self.node_size[node_id]/(len(X_right)+1)\n\n            left_child = self.create_new_node(node_id,-1)\n            right_child = self.create_new_node(node_id,1)\n\n            self.child_left[node_id] = left_child\n            self.child_right[node_id] = right_child\n\n            stack.append((left_child, X_left, depth + 1))\n            stack.append((right_child, X_right, depth + 1))\n\n            if self.node_count &gt;= self.max_nodes:\n                raise ValueError(\"Max number of nodes reached\")\n\n    def leaf_ids(self, X:np.array) -&gt; np.array:\n        \"\"\"\n        Get the leaf node ids for each data point in the dataset.\n\n        This is a stub method of `get_leaf_ids`.\n\n        Args:\n            X: Input dataset\n\n        Returns:\n           Leaf node ids for each data point in the dataset.\n        \"\"\"\n        return get_leaf_ids(X, self.child_left, self.child_right, self.normals, self.intercepts) \n\n\n    def apply(self, X:np.array) -&gt; None:\n        \"\"\"\n        Update the `path_to` attribute with the path to the leaf nodes for each data point in the dataset.\n\n        Args:\n            X: Input dataset\n\n        Returns:\n            The method updates `path_to` and does not return any value.\n        \"\"\"\n        return self.path_to[self.leaf_ids(X)] \n\n    def predict(self,\n                ids:np.array) -&gt; np.array:\n\n        \"\"\"\n        Predict the anomaly score for each data point in the dataset.\n\n        Args:\n            ids: Leaf node ids for each data point in the dataset.\n\n        Returns:\n            Anomaly score for each data point in the dataset.\n        \"\"\"\n        return self.corrected_depth[ids],\n\n    def importances(self,ids:np.array) -&gt; tuple[np.array,np.array]:\n\n        \"\"\"\n        Compute the importances of the features for the given leaf node ids.\n\n        Args:\n            ids: Leaf node ids for each data point in the dataset.\n\n        Returns:\n            Importances of the features for the given leaf node ids and the normal vectors.\n        \"\"\"\n        importances,normals = calculate_importances(\n            self.path_to[ids], \n            self.path_to_Right_Left[ids], \n            self.importances_left, \n            self.importances_right, \n            self.normals, \n            self.d\n        )\n\n        return importances, normals\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedTree.apply","title":"<code>apply(X)</code>","text":"<p>Update the <code>path_to</code> attribute with the path to the leaf nodes for each data point in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>None</code> <p>The method updates <code>path_to</code> and does not return any value.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def apply(self, X:np.array) -&gt; None:\n    \"\"\"\n    Update the `path_to` attribute with the path to the leaf nodes for each data point in the dataset.\n\n    Args:\n        X: Input dataset\n\n    Returns:\n        The method updates `path_to` and does not return any value.\n    \"\"\"\n    return self.path_to[self.leaf_ids(X)] \n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedTree.create_new_node","title":"<code>create_new_node(parent_id, direction)</code>","text":"<p>Create a new node in the tree.</p> <p>Parameters:</p> Name Type Description Default <code>parent_id</code> <code>int</code> <p>Parent node id</p> required <code>direction</code> <code>int</code> <p>Direction to the new node</p> required <p>Returns:</p> Type Description <code>int</code> <p>New node id</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def create_new_node(self,\n                    parent_id:int,\n                    direction:int) -&gt; int:\n\n    \"\"\"\n    Create a new node in the tree.\n\n    Args:\n        parent_id: Parent node id\n        direction: Direction to the new node\n\n    Returns:\n        New node id\n\n    \"\"\"\n\n    new_node_id = self.node_count\n    self.node_count+=1\n    self.path_to[new_node_id] = self.path_to[parent_id]\n    self.path_to_Right_Left[new_node_id] = self.path_to_Right_Left[parent_id]\n    self.path_to[new_node_id, self.depth[parent_id]+1] = new_node_id\n    self.path_to_Right_Left[new_node_id, self.depth[parent_id]] = direction\n    self.depth[new_node_id] = self.depth[parent_id]+1     \n    return new_node_id\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedTree.extend_tree","title":"<code>extend_tree(node_id, X, depth)</code>","text":"<p>Extend the tree to the given node.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>int</code> <p>Node id</p> required <code>X</code> <code>NDArray</code> <p>Input dataset</p> required <code>depth</code> <code>int</code> <p>Depth of the node</p> required <p>Returns:</p> Type Description <code>None</code> <p>The method extends the tree and does not return any value.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def extend_tree(self,\n                node_id:int,\n                X:npt.NDArray,\n                depth: int) -&gt; None:\n\n    \"\"\"\n    Extend the tree to the given node.\n\n    Args:\n        node_id: Node id\n        X: Input dataset\n        depth: Depth of the node\n\n    Returns:\n        The method extends the tree and does not return any value.\n    \"\"\"\n\n    stack = [(0, X, 0)] \n\n    while stack:\n        node_id, data, depth = stack.pop()\n\n        self.node_size[node_id] = len(data)\n        if self.node_size[node_id] &lt;= self.min_sample or depth &gt;= self.max_depth:\n            continue\n\n        self.normals[node_id] = make_rand_vector(self.d - self.locked_dims, self.d)         \n\n        dist = np.dot(np.ascontiguousarray(data), np.ascontiguousarray(self.normals[node_id]))\n\n        if self.plus:\n            #self.intercepts[node_id] = np.random.normal(np.mean(dist),np.std(dist)*self.eta)\n            self.intercepts[node_id] = np.random.normal(np.mean(dist),np.std(dist)*self.eta)\n        else:\n            self.intercepts[node_id] = np.random.uniform(np.min(dist),np.max(dist))\n        mask = dist &lt;= self.intercepts[node_id]  \n\n        X_left = data[mask]\n        X_right = data[~mask,:]\n\n        self.importances_left[node_id] = np.abs(self.normals[node_id])*(self.node_size[node_id]/(len(X_left)+1))\n        self.importances_right[node_id] = np.abs(self.normals[node_id])*self.node_size[node_id]/(len(X_right)+1)\n\n        left_child = self.create_new_node(node_id,-1)\n        right_child = self.create_new_node(node_id,1)\n\n        self.child_left[node_id] = left_child\n        self.child_right[node_id] = right_child\n\n        stack.append((left_child, X_left, depth + 1))\n        stack.append((right_child, X_right, depth + 1))\n\n        if self.node_count &gt;= self.max_nodes:\n            raise ValueError(\"Max number of nodes reached\")\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedTree.fit","title":"<code>fit(X)</code>","text":"<p>Fit the model to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>None</code> <p>The method fits the model and does not return any value.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def fit(self, X:np.array) -&gt; None:\n\n    \"\"\"\n    Fit the model to the dataset.\n\n    Args:\n        X: Input dataset\n\n    Returns:\n        The method fits the model and does not return any value.\n    \"\"\"\n\n    self.path_to[0,0] = 0\n    self.extend_tree(node_id=0, X=X, depth=0)\n    self.corrected_depth = np.array([\n        (c_factor(k)+sum(path&gt;-1))/c_factor(self.n)\n        for i,(k,path) in enumerate(zip(self.node_size,self.path_to))\n        if i&lt;self.node_count\n    ])\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedTree.importances","title":"<code>importances(ids)</code>","text":"<p>Compute the importances of the features for the given leaf node ids.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>array</code> <p>Leaf node ids for each data point in the dataset.</p> required <p>Returns:</p> Type Description <code>tuple[array, array]</code> <p>Importances of the features for the given leaf node ids and the normal vectors.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def importances(self,ids:np.array) -&gt; tuple[np.array,np.array]:\n\n    \"\"\"\n    Compute the importances of the features for the given leaf node ids.\n\n    Args:\n        ids: Leaf node ids for each data point in the dataset.\n\n    Returns:\n        Importances of the features for the given leaf node ids and the normal vectors.\n    \"\"\"\n    importances,normals = calculate_importances(\n        self.path_to[ids], \n        self.path_to_Right_Left[ids], \n        self.importances_left, \n        self.importances_right, \n        self.normals, \n        self.d\n    )\n\n    return importances, normals\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedTree.leaf_ids","title":"<code>leaf_ids(X)</code>","text":"<p>Get the leaf node ids for each data point in the dataset.</p> <p>This is a stub method of <code>get_leaf_ids</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>array</code> <p>Leaf node ids for each data point in the dataset.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def leaf_ids(self, X:np.array) -&gt; np.array:\n    \"\"\"\n    Get the leaf node ids for each data point in the dataset.\n\n    This is a stub method of `get_leaf_ids`.\n\n    Args:\n        X: Input dataset\n\n    Returns:\n       Leaf node ids for each data point in the dataset.\n    \"\"\"\n    return get_leaf_ids(X, self.child_left, self.child_right, self.normals, self.intercepts) \n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.ExtendedTree.predict","title":"<code>predict(ids)</code>","text":"<p>Predict the anomaly score for each data point in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>array</code> <p>Leaf node ids for each data point in the dataset.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Anomaly score for each data point in the dataset.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def predict(self,\n            ids:np.array) -&gt; np.array:\n\n    \"\"\"\n    Predict the anomaly score for each data point in the dataset.\n\n    Args:\n        ids: Leaf node ids for each data point in the dataset.\n\n    Returns:\n        Anomaly score for each data point in the dataset.\n    \"\"\"\n    return self.corrected_depth[ids],\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.IsolationForest","title":"<code>IsolationForest</code>","text":"<p>             Bases: <code>ExtendedIsolationForest</code></p> <p>Class that represents the Isolation Forest model. </p> <p>This is a subclass of <code>ExtendedIsolationForest</code> with the <code>plus</code> attribute set to False and the  <code>locked_dims</code> attribute set to the number of dimensions minus one.</p> <p>Attributes:</p> Name Type Description <code>n_estimators</code> <code>int</code> <p>Number of trees in the model. Defaults to 400</p> <code>max_depth</code> <code>Union[str, int]</code> <p>Maximum depth of the trees. Defaults to \"auto\"</p> <code>max_samples</code> <code>Union[str, int]</code> <p>Maximum number of samples in a node. Defaults to \"auto\"</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>class IsolationForest(ExtendedIsolationForest):\n\n    \"\"\"\n    Class that represents the Isolation Forest model. \n\n    This is a subclass of `ExtendedIsolationForest` with the `plus` attribute set to False and the \n    `locked_dims` attribute set to the number of dimensions minus one.\n\n    Attributes:\n        n_estimators (int): Number of trees in the model. Defaults to 400\n        max_depth (Union[str,int]): Maximum depth of the trees. Defaults to \"auto\"\n        max_samples (Union[str,int]): Maximum number of samples in a node. Defaults to \"auto\"\n\n    \"\"\"\n    def __init__(self,\n                 n_estimators:int=400,\n                 max_depth:Union[str,int]=\"auto\",\n                 max_samples:Union[str,int]=\"auto\") -&gt; None:\n        super().__init__(plus=False,n_estimators=n_estimators,max_depth=max_depth,max_samples=max_samples)\n        self.name=\"IF\"\n\n    def fit(self,\n            X:np.array) -&gt; None:\n\n        \"\"\"\n        Fit the model to the dataset.\n\n        Args:\n            X: Input dataset\n\n        Returns:\n            The method fits the model and does not return any value.\n        \"\"\"\n\n        return super().fit(X, locked_dims=X.shape[1]-1)\n\n    def decision_function_single_tree(self,\n                                      tree_idx:int,\n                                      X:np.array,\n                                      p:float=0.1) -&gt; tuple[np.array,np.array]:\n\n        \"\"\"\n        Predict the anomaly score for each data point in the dataset using a single tree.\n\n        Args:\n            tree_idx: Index of the tree\n            X: Input dataset\n            p: Proportion of outliers (i.e. threshold for the anomaly score). Defaults to 0.1\n\n        Returns:\n            Anomaly score for each data point in the dataset and the predicted class for each data point in the dataset.\n        \"\"\"\n\n        self.compute_ids(X)\n        pred=self.trees[tree_idx].predict(X,self.ids[tree_idx])[0]\n        score=np.power(2,-pred)\n        y_hat = np.array(score &gt; sorted(score,reverse=True)[int(p*len(score))],dtype=int)\n        return score,y_hat\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.IsolationForest.decision_function_single_tree","title":"<code>decision_function_single_tree(tree_idx, X, p=0.1)</code>","text":"<p>Predict the anomaly score for each data point in the dataset using a single tree.</p> <p>Parameters:</p> Name Type Description Default <code>tree_idx</code> <code>int</code> <p>Index of the tree</p> required <code>X</code> <code>array</code> <p>Input dataset</p> required <code>p</code> <code>float</code> <p>Proportion of outliers (i.e. threshold for the anomaly score). Defaults to 0.1</p> <code>0.1</code> <p>Returns:</p> Type Description <code>tuple[array, array]</code> <p>Anomaly score for each data point in the dataset and the predicted class for each data point in the dataset.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def decision_function_single_tree(self,\n                                  tree_idx:int,\n                                  X:np.array,\n                                  p:float=0.1) -&gt; tuple[np.array,np.array]:\n\n    \"\"\"\n    Predict the anomaly score for each data point in the dataset using a single tree.\n\n    Args:\n        tree_idx: Index of the tree\n        X: Input dataset\n        p: Proportion of outliers (i.e. threshold for the anomaly score). Defaults to 0.1\n\n    Returns:\n        Anomaly score for each data point in the dataset and the predicted class for each data point in the dataset.\n    \"\"\"\n\n    self.compute_ids(X)\n    pred=self.trees[tree_idx].predict(X,self.ids[tree_idx])[0]\n    score=np.power(2,-pred)\n    y_hat = np.array(score &gt; sorted(score,reverse=True)[int(p*len(score))],dtype=int)\n    return score,y_hat\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.IsolationForest.fit","title":"<code>fit(X)</code>","text":"<p>Fit the model to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>None</code> <p>The method fits the model and does not return any value.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>def fit(self,\n        X:np.array) -&gt; None:\n\n    \"\"\"\n    Fit the model to the dataset.\n\n    Args:\n        X: Input dataset\n\n    Returns:\n        The method fits the model and does not return any value.\n    \"\"\"\n\n    return super().fit(X, locked_dims=X.shape[1]-1)\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.c_factor","title":"<code>c_factor(n)</code>","text":"<p>Average path length of unsuccesful search in a binary search tree given n points. This is a constant factor that will be used as a normalization factor in the Anomaly Score computation.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of data points for the BST.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Average path length of unsuccesful search in a BST</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>@njit(cache=True)\ndef c_factor(n: int) -&gt; float:\n    \"\"\"\n    Average path length of unsuccesful search in a binary search tree given n points.\n    This is a constant factor that will be used as a normalization factor in the Anomaly Score computation.\n\n    Args:\n        n: Number of data points for the BST.\n\n    Returns:\n        Average path length of unsuccesful search in a BST\n\n    \"\"\"\n    if n &lt;=1: return 0\n    return 2.0*(np.log(n-1)+0.5772156649) - (2.0*(n-1.)/(n*1.0))\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.calculate_importances","title":"<code>calculate_importances(paths, directions, importances_left, importances_right, normals, d)</code>","text":"<p>Calculate the importances of the features for the given paths and directions.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>ndarray</code> <p>Paths to the leaf nodes</p> required <code>directions</code> <code>ndarray</code> <p>Directions to the leaf nodes</p> required <code>importances_left</code> <code>ndarray</code> <p>Importances of the left child nodes</p> required <code>importances_right</code> <code>ndarray</code> <p>Importances of the right child nodes</p> required <code>normals</code> <code>ndarray</code> <p>Normal vectors of the splitting hyperplanes</p> required <code>d</code> <code>int</code> <p>Number of dimensions in the dataset</p> required <p>Returns:</p> Type Description <code>tuple[array, array]</code> <p>Importances of the features for the given paths and directions and the normal vectors.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>@njit(cache=True)\ndef calculate_importances(paths:np.ndarray,\n                          directions:np.ndarray, \n                          importances_left:np.ndarray, \n                          importances_right:np.ndarray, \n                          normals:np.ndarray,\n                          d:int) -&gt; tuple[np.array,np.array]:\n\n    \"\"\"\n    Calculate the importances of the features for the given paths and directions.\n\n    Args:\n        paths: Paths to the leaf nodes\n        directions: Directions to the leaf nodes\n        importances_left: Importances of the left child nodes\n        importances_right: Importances of the right child nodes\n        normals: Normal vectors of the splitting hyperplanes\n        d: Number of dimensions in the dataset\n\n    Returns:\n        Importances of the features for the given paths and directions and the normal vectors.\n    \"\"\"\n\n    # Flatten the paths and directions for 1D boolean indexing\n    paths_flat = paths.flatten()\n    directions_flat = directions.flatten()\n\n    # Create masks for left and right directions\n    left_mask_flat = directions_flat == -1\n    right_mask_flat = directions_flat == 1\n\n    # Use masks to filter flattened paths; initialize with -1 (or suitable default)\n    left_paths_flat = np.full_like(paths_flat, -1)\n    right_paths_flat = np.full_like(paths_flat, -1)\n\n    # Apply the masks\n    left_paths_flat[left_mask_flat] = paths_flat[left_mask_flat]\n    right_paths_flat[right_mask_flat] = paths_flat[right_mask_flat]\n\n    # Since importances are mentioned to be arrays of arrays, let's assume we can index them directly with the flattened paths\n    # Note: This step might need adjustment based on the actual structure and intended calculations\n    importances_sum_left = np.zeros((paths.shape[0],d), dtype=np.float64)  # Initialize to match number of rows in paths\n    importances_sum_right = np.zeros((paths.shape[0],d), dtype=np.float64)\n\n    normals_sum = np.zeros((paths.shape[0],d), dtype=np.float64)  # Initialize to match number of rows in paths\n\n    importances_sum_left = importances_left[left_paths_flat].reshape(paths.shape[0],paths.shape[1],d).sum(axis=1)\n    importances_sum_right = importances_right[right_paths_flat].reshape(paths.shape[0],paths.shape[1],d).sum(axis=1)\n    normals_sum = np.abs(normals[paths_flat]).reshape(paths.shape[0],paths.shape[1],d).sum(axis=1)\n\n    importances_sum = importances_sum_left + importances_sum_right\n\n    return importances_sum, normals_sum\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.get_leaf_ids","title":"<code>get_leaf_ids(X, child_left, child_right, normals, intercepts)</code>","text":"<p>Get the leaf node ids for each data point in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Data points</p> required <code>child_left</code> <code>array</code> <p>Left child node ids</p> required <code>child_right</code> <code>array</code> <p>Right child node ids</p> required <code>normals</code> <code>array</code> <p>Normal vectors of the splitting hyperplanes</p> required <code>intercepts</code> <code>array</code> <p>Intercept values of the splitting hyperplanes</p> required <p>Returns:</p> Type Description <code>array</code> <p>Leaf node ids for each data point in the dataset.</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>@njit(cache=True)\ndef get_leaf_ids(X:np.array,\n                 child_left:np.array,\n                 child_right:np.array,\n                 normals:np.array,\n                 intercepts:np.array) -&gt; np.array:\n\n        \"\"\"\n        Get the leaf node ids for each data point in the dataset.\n\n        Args:\n            X: Data points\n            child_left: Left child node ids\n            child_right: Right child node ids\n            normals: Normal vectors of the splitting hyperplanes\n            intercepts: Intercept values of the splitting hyperplanes\n\n        Returns:\n           Leaf node ids for each data point in the dataset.\n        \"\"\"\n        res = []\n        for x in X:\n            node_id = 0\n            while child_left[node_id] or child_right[node_id]:\n                d = np.dot(np.ascontiguousarray(x),np.ascontiguousarray(normals[node_id]))\n                node_id = child_left[node_id] if d &lt;= intercepts[node_id] else child_right[node_id]        \n            res.append(int(node_id))\n        return np.array(res)\n</code></pre>"},{"location":"models/#model_reboot.EIF_reboot.make_rand_vector","title":"<code>make_rand_vector(df, dimensions)</code>","text":"<p>Generate a random unitary vector in the unit ball with a maximum number of dimensions.  This vector will be successively used in the generation of the splitting hyperplanes.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>int</code> <p>Degrees of freedom</p> required <code>dimensions</code> <code>int</code> <p>number of dimensions of the feature space</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the degree of freedom does not match with the dataset dimensions</p> <p>Returns:</p> Name Type Description <code>vec</code> <code>NDArray[float64]</code> <p>Random unitary vector in the unit ball</p> Source code in <code>model_reboot/EIF_reboot.py</code> <pre><code>@njit(cache=True)\ndef make_rand_vector(df:int,\n                     dimensions:int) -&gt; npt.NDArray[np.float64]:\n    \"\"\"\n    Generate a random unitary vector in the unit ball with a maximum number of dimensions. \n    This vector will be successively used in the generation of the splitting hyperplanes.\n\n    Args:\n        df: Degrees of freedom\n        dimensions: number of dimensions of the feature space\n\n    Raises:\n        ValueError: If the degree of freedom does not match with the dataset dimensions\n\n    Returns:\n        vec: Random unitary vector in the unit ball\n\n    \"\"\"\n    if dimensions&lt;df:\n        raise ValueError(\"degree of freedom does not match with dataset dimensions\")\n    else:\n        vec_ = np.random.normal(loc=0.0, scale=1.0, size=df)\n        indexes = np.random.choice(np.arange(dimensions),df,replace=False)\n        vec = np.zeros(dimensions)\n        vec[indexes] = vec_\n        vec=vec/np.linalg.norm(vec)\n    return vec\n</code></pre>"},{"location":"plots/","title":"Plots","text":"<p>The <code>plots</code> module contains the methods used to generate the plots showed in the paper.</p>"},{"location":"plots/#utils_reboot.plots.bar_plot","title":"<code>bar_plot(dataset, global_importances_file, filetype='npz', plot_path=os.getcwd(), f=6, save_image=True, show_plot=True, model='EIF+', interpretation='EXIFFI+', scenario=1)</code>","text":"<p>Compute the Global Importance Bar Plot starting from the Global Feature Importance vector.  </p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset</p> required <code>global_importances_file</code> <code>str</code> <p>The path to the file containing the global importances.</p> required <code>filetype</code> <code>str</code> <p>The file type of the global importances file. Defaults to \"npz\".</p> <code>'npz'</code> <code>plot_path</code> <code>str</code> <p>The path where the plot will be saved. Defaults to os.getcwd().</p> <code>getcwd()</code> <code>f</code> <code>int</code> <p>The number of ranks to be displayed in the plot. Defaults to 6. </p> <code>6</code> <code>save_image</code> <p>A boolean indicating whether the plot should be saved. Defaults to True.</p> <code>True</code> <code>show_plot</code> <p>A boolean indicating whether the plot should be displayed. Defaults to True.</p> <code>True</code> <code>model</code> <code>str</code> <p>The AD model on which the importances should be computed. Defaults to 'EIF+'.</p> <code>'EIF+'</code> <code>interpretation</code> <code>str</code> <p>The interpretation model used. Defaults to 'EXIFFI+'.</p> <code>'EXIFFI+'</code> <code>scenario</code> <code>int</code> <p>The scenario number. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>tuple[figure, axes, DataFrame]</code> <p>The figure, the axes and the bars dataframe.</p> Source code in <code>utils_reboot/plots.py</code> <pre><code>def bar_plot(dataset: Type[Dataset], \n            global_importances_file: str,\n            filetype: str = \"npz\", \n            plot_path: str = os.getcwd(), \n            f: int = 6, \n            save_image = True, \n            show_plot = True,\n            model:str='EIF+',\n            interpretation:str=\"EXIFFI+\",\n            scenario:int=1) -&gt; tuple[plt.figure, plt.axes, pd.DataFrame]:\n    \"\"\"\n    Compute the Global Importance Bar Plot starting from the Global Feature Importance vector.  \n\n    Args:\n        dataset: Input dataset\n        global_importances_file: The path to the file containing the global importances.\n        filetype: The file type of the global importances file. Defaults to \"npz\".\n        plot_path: The path where the plot will be saved. Defaults to os.getcwd().\n        f: The number of ranks to be displayed in the plot. Defaults to 6. \n        save_image: A boolean indicating whether the plot should be saved. Defaults to True.\n        show_plot: A boolean indicating whether the plot should be displayed. Defaults to True.\n        model: The AD model on which the importances should be computed. Defaults to 'EIF+'.\n        interpretation: The interpretation model used. Defaults to 'EXIFFI+'.\n        scenario: The scenario number. Defaults to 1.\n\n    Returns:\n       The figure, the axes and the bars dataframe.   \n    \"\"\"\n\n    if  isinstance(dataset.feature_names, np.ndarray):\n        col_names = dataset.feature_names.astype(str)\n    elif isinstance(dataset.feature_names, list):\n        col_names = dataset.feature_names\n\n    t = time.localtime()\n    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n\n    if (model=='EIF+' and interpretation=='EXIFFI+') or (model=='EIF' and interpretation=='EXIFFI'):\n        name_file = f\"{current_time}_GFI_Bar_plot_{dataset.name}_{interpretation}_{scenario}\"\n    else:\n        name_file = f\"{current_time}_GFI_Bar_plot_{dataset.name}_{model}_{interpretation}_{scenario}\"\n\n    #Load the imps array from the pkl file contained in imps_path -&gt; the imps_path is returned from the \n    #compute_local_importances or compute_global_importances functions so we have it for free \n    try:\n        importances = open_element(global_importances_file, filetype=filetype)\n    except:\n        raise Exception(\"The file path is not valid\")\n\n    number_colours = 20\n    color = plt.cm.get_cmap('tab20',number_colours).colors\n    patterns=[None,'!','@','#','$','^','&amp;','*','\u00b0','(',')','-','_','+','=','[',']','{','}',\n    '|',';',':',',','.','&lt;','&gt;','/','?','`','~','\\\\','!!','@@','##','$$','^^','&amp;&amp;','**','\u00b0\u00b0','((']\n    importances_matrix = np.array([np.array(pd.Series(x).sort_values(ascending = False).index).T for x in importances])\n    dim=int(importances.shape[1])\n\n    bars = [[(list(importances_matrix[:,j]).count(i)/len(importances_matrix))*100 for i in range(dim)] for j in range(dim)]\n    bars = pd.DataFrame(bars)\n\n    tick_names=[]\n    for i in range(1,f+1):\n        if int(str(i)[-1])==1 and (len(str(i))==1 or int(str(i)[-2])!=1):\n            tick_names.append(r'${}'.format(i) + r'^{st}$')\n        elif int(str(i)[-1])==2 and (len(str(i))==1 or int(str(i)[-2])!=1):\n            tick_names.append(r'${}'.format(i) + r'^{nd}$')\n        elif int(str(i)[-1])==3 and (len(str(i))==1 or int(str(i)[-2])!=1):\n            tick_names.append(r'${}'.format(i) + r'^{rd}$')\n        else:\n            tick_names.append(r'${}'.format(i) + r'^{th}$')\n\n    barWidth = 0.85\n    r = range(dim)\n    ncols=1\n    if importances.shape[1]&gt;15:\n        ncols=2\n    elif importances.shape[1]&gt;30:\n        ncols=3\n    elif importances.shape[1]&gt;45:\n        ncols=4\n    elif importances.shape[1]&gt;60:\n        ncols=5\n    elif importances.shape[1]&gt;75:\n        ncols=6\n\n    fig, ax = plt.subplots()\n\n    for i in range(dim):\n        if col_names is not None: \n            ax.bar(r[:f], bars.T.iloc[i, :f].values, bottom=bars.T.iloc[:i, :f].sum().values, color=color[i % number_colours], edgecolor='white', width=barWidth, label=col_names[i], hatch=patterns[i // number_colours])\n        else:\n            ax.bar(r[:f], bars.T.iloc[i, :f].values, bottom=bars.T.iloc[:i, :f].sum().values, color=color[i % number_colours], edgecolor='white', width=barWidth, label=str(i), hatch=patterns[i // number_colours])\n\n    ax.set_xlabel(\"Rank\", fontsize=20)\n    ax.set_xticks(range(f), tick_names[:f])\n    ax.set_ylabel(\"Percentage count\", fontsize=20)\n    ax.set_yticks(range(10, 101, 10), [str(x) + \"%\" for x in range(10, 101, 10)])\n    ax.legend(bbox_to_anchor=(1.05, 0.95), loc=\"upper left\",ncol=ncols)\n\n    if save_image:\n        plt.savefig(plot_path + f'/{name_file}.pdf', bbox_inches='tight')\n\n    if show_plot:\n        plt.show()\n\n    return fig, ax, bars\n</code></pre>"},{"location":"plots/#utils_reboot.plots.get_contamination_comparison","title":"<code>get_contamination_comparison(model1, model2, dataset_name, path=os.getcwd())</code>","text":"<p>Obtain the difference in precision between two models for different contamination values.</p> <p>Parameters:</p> Name Type Description Default <code>model1</code> <code>str</code> <p>The first model name.</p> required <code>model2</code> <code>str</code> <p>The second model name.</p> required <code>dataset_name</code> <code>str</code> <p>The dataset name.</p> required <code>path</code> <code>str</code> <p>Starting path to retrieve the path where the precisions of the two models are stored. Defaults to os.getcwd().</p> <code>getcwd()</code> Source code in <code>utils_reboot/plots.py</code> <pre><code>def get_contamination_comparison(model1:str,\n                            model2:str,\n                            dataset_name:str,\n                            path:str=os.getcwd()):\n\n    \"\"\"\n    Obtain the difference in precision between two models for different contamination values.\n\n    Args:\n        model1: The first model name.\n        model2: The second model name.\n        dataset_name: The dataset name.\n        path: Starting path to retrieve the path where the precisions of the two models are stored. Defaults to os.getcwd().\n    \"\"\"\n\n    path_model1=path+'/results/'+ dataset_name +'/experiments/contamination/'+model1\n    path_model2=path+'/results/'+ dataset_name +'/experiments/contamination/'+model2\n\n    precisions_model1=open_element(get_most_recent_file(path_model1),filetype='pickle')[0]\n    precisions_model2=open_element(get_most_recent_file(path_model2),filetype='pickle')[0]\n    precisions=precisions_model1-precisions_model2\n\n    return precisions\n</code></pre>"},{"location":"plots/#utils_reboot.plots.get_vals","title":"<code>get_vals(model, dataset_names, type='predict')</code>","text":"<p>Obtain statistics on the execution time of a model for different datasets. These values will be used in the plot_time_scaling method.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model name.</p> required <code>dataset_names</code> <code>List[str]</code> <p>The list of dataset names.</p> required <code>type</code> <code>str</code> <p>The type of execution time. Defaults to 'predict'.</p> <code>'predict'</code> <p>Returns:</p> Type Description <code>tuple[List, List, List]</code> <p>The median, 5th percentile and 95th percentile values of the execution time.</p> Source code in <code>utils_reboot/plots.py</code> <pre><code>def get_vals(model: str, \n            dataset_names: List[str],\n            type:str='predict') -&gt; tuple[List,List,List]:\n\n    \"\"\"\n    Obtain statistics on the execution time of a model for different datasets. These values will be used in the plot_time_scaling method.\n\n    Args:\n        model: The model name.\n        dataset_names: The list of dataset names.\n        type: The type of execution time. Defaults to 'predict'.\n\n    Returns:\n       The median, 5th percentile and 95th percentile values of the execution time.\n    \"\"\"\n\n    assert type in ['predict','fit','importances'], \"Type not valid\"\n\n    os.chdir('../utils_reboot')\n    with open(os.getcwd() + \"/time_scaling_test_dei_new.pickle\", \"rb\") as file:\n        dict_time = pickle.load(file)\n\n    val_times=[]\n    for d_name in dataset_names:\n        time=np.array(dict_time[type][model][d_name])\n        val_times.append(time)\n\n    median_val_times=[np.percentile(x,50) for x in val_times]\n    five_val_times=[np.percentile(x,5) for x in val_times]\n    ninefive_val_times=[np.percentile(x,95) for x in val_times]\n\n    return median_val_times,five_val_times,ninefive_val_times\n</code></pre>"},{"location":"plots/#utils_reboot.plots.importance_map","title":"<code>importance_map(dataset, model, resolution=30, path_plot=os.getcwd(), save_plot=True, show_plot=False, factor=3, feats_plot=(0, 1), col_names=None, isdiffi=False, scenario=2, interpretation='EXIFFI+')</code>","text":"<p>Produce the Local Feature Importance Scoremap.   </p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset</p> required <code>model</code> <code>Type[ExtendedIsolationForest]</code> <p>The AD model.</p> required <code>resolution</code> <code>Optional[int]</code> <p>The resolution of the plot. Defaults to 30.</p> <code>30</code> <code>path_plot</code> <code>Optional[str]</code> <p>The path where the plot will be saved. Defaults to os.getcwd().</p> <code>getcwd()</code> <code>save_plot</code> <code>Optional[bool]</code> <p>A boolean indicating whether the plot should be saved. Defaults to True.</p> <code>True</code> <code>show_plot</code> <code>Optional[bool]</code> <p>A boolean indicating whether the plot should be displayed. Defaults to False.</p> <code>False</code> <code>factor</code> <code>Optional[int]</code> <p>The factor by which the min and max values of the features are extended. Defaults to 3.</p> <code>3</code> <code>feats_plot</code> <code>Optional[tuple]</code> <p>The features to be plotted. Defaults to (0,1).</p> <code>(0, 1)</code> <code>col_names</code> <code>List[str]</code> <p>The names of the features. Defaults to None.</p> <code>None</code> <code>isdiffi</code> <code>Optional[bool]</code> <p>A boolean indicating whether the local-DIFFI method should be used to compute the importance values. Defaults to False.</p> <code>False</code> <code>scenario</code> <code>Optional[int]</code> <p>The scenario number. Defaults to 2.</p> <code>2</code> <code>interpretation</code> <code>Optional[str]</code> <p>Name of the interpretation model used. Defaults to \"EXIFFI+\".</p> <code>'EXIFFI+'</code> <p>Returns:</p> Type Description <code>None</code> <p>The function saves the plot in the specified path and displays it if the show_plot parameter is set to True.</p> Source code in <code>utils_reboot/plots.py</code> <pre><code>def importance_map(dataset: Type[Dataset],\n                   model: Type[ExtendedIsolationForest],\n                   resolution: Optional[int] = 30,\n                   path_plot: Optional[str] = os.getcwd(),\n                   save_plot: Optional[bool] = True,\n                   show_plot: Optional[bool] = False,\n                   factor: Optional[int] = 3, \n                   feats_plot: Optional[tuple] = (0,1),\n                   col_names: List[str] = None,\n                   isdiffi: Optional[bool] = False,\n                   scenario: Optional[int] = 2,\n                   interpretation: Optional[str] = \"EXIFFI+\"\n                   ) -&gt; None:\n        \"\"\"\n        Produce the Local Feature Importance Scoremap.   \n\n        Args:\n            dataset: Input dataset\n            model: The AD model.\n            resolution: The resolution of the plot. Defaults to 30.\n            path_plot: The path where the plot will be saved. Defaults to os.getcwd().\n            save_plot: A boolean indicating whether the plot should be saved. Defaults to True.\n            show_plot: A boolean indicating whether the plot should be displayed. Defaults to False.\n            factor: The factor by which the min and max values of the features are extended. Defaults to 3.\n            feats_plot: The features to be plotted. Defaults to (0,1).\n            col_names: The names of the features. Defaults to None.\n            isdiffi: A boolean indicating whether the local-DIFFI method should be used to compute the importance values. Defaults to False.\n            scenario: The scenario number. Defaults to 2.\n            interpretation: Name of the interpretation model used. Defaults to \"EXIFFI+\".\n\n        Returns:\n            The function saves the plot in the specified path and displays it if the show_plot parameter is set to True.\n        \"\"\"\n\n        mins = dataset.X_test.min(axis=0)[list(feats_plot)]\n        maxs = dataset.X_test.max(axis=0)[list(feats_plot)]  \n        mean = dataset.X_test.mean(axis = 0)\n        mins = list(mins-(maxs-mins)*factor/10)\n        maxs = list(maxs+(maxs-mins)*factor/10)\n        xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution), np.linspace(mins[1], maxs[1], resolution))\n        mean = np.repeat(np.expand_dims(mean,0),len(xx)**2,axis = 0)\n        mean[:,feats_plot[0]]=xx.reshape(len(xx)**2)\n        mean[:,feats_plot[1]]=yy.reshape(len(yy)**2)\n\n        importance_matrix = np.zeros_like(mean)\n        if isdiffi:\n                model.max_samples = len(dataset.X)\n                for i in range(importance_matrix.shape[0]):\n                        importance_matrix[i] = local_diffi(model, mean[i])[0]\n        else:\n            importance_matrix = model.local_importances(mean)\n\n        sign = np.sign(importance_matrix[:,feats_plot[0]]-importance_matrix[:,feats_plot[1]])\n        Score = sign*((sign&gt;0)*importance_matrix[:,feats_plot[0]]+(sign&lt;0)*importance_matrix[:,feats_plot[1]])\n        x = dataset.X_test[:,feats_plot[0]].squeeze()\n        y = dataset.X_test[:,feats_plot[1]].squeeze()\n\n        Score = Score.reshape(xx.shape)\n\n        # Create a new pyplot object if plt is not provided\n        fig, ax = plt.subplots()\n\n        cp = ax.pcolor(xx, yy, Score, cmap=cm.RdBu, shading='nearest', norm=colors.CenteredNorm())\n\n        ax.contour(xx, yy, (importance_matrix[:, feats_plot[0]] + importance_matrix[:, feats_plot[1]]).reshape(xx.shape), levels=7, cmap=cm.Greys, alpha=0.7)\n\n        try:\n            ax.scatter(x[dataset.y_test == 0], y[dataset.y_test == 0], s=40, c=\"tab:blue\", marker=\"o\", edgecolors=\"k\", label=\"inliers\")\n            ax.scatter(x[dataset.y_test == 1], y[dataset.y_test == 1], s=60, c=\"tab:orange\", marker=\"*\", edgecolors=\"k\", label=\"outliers\")\n        except IndexError:\n            print('Handling the IndexError Exception...')\n            ax.scatter(x[(dataset.y_test == 0)[:, 0]], y[(dataset.y_test == 0)[:, 0]], s=40, c=\"tab:blue\", marker=\"o\", edgecolors=\"k\", label=\"inliers\")\n            ax.scatter(x[(dataset.y_test == 1)[:, 0]], y[(dataset.y_test == 1)[:, 0]], s=60, c=\"tab:orange\", marker=\"*\", edgecolors=\"k\", label=\"outliers\")\n\n        if (isinstance(col_names, np.ndarray)) or (col_names is None):\n            ax.set_xlabel(f'Feature {feats_plot[0]}',fontsize=20)\n            ax.set_ylabel(f'Feature {feats_plot[1]}',fontsize=20)\n        elif col_names is not None:\n            ax.set_xlabel(col_names[feats_plot[0]],fontsize=20)\n            ax.set_ylabel(col_names[feats_plot[1]],fontsize=20)\n\n        ax.legend()\n\n\n        t = time.localtime()\n        current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n        if isdiffi:\n            filename = current_time+\"_importance_map_\"+dataset.name+\"_\"+model.name+\"_\"+interpretation+f\"_{str(scenario)}\"+f\"_feat_{feats_plot[0]}_{feats_plot[1]}\"+\".pdf\"\n        else:\n            filename = current_time+\"_importance_map_\"+dataset.name+\"_\"+model.name+\"_\"+interpretation+f\"_{str(scenario)}\"+f\"_feat_{feats_plot[0]}_{feats_plot[1]}\"+\".pdf\"\n\n        if show_plot:\n            plt.show()\n        if save_plot:\n            plt.savefig(path_plot + '/{}'.format(filename), bbox_inches='tight')\n</code></pre>"},{"location":"plots/#utils_reboot.plots.plot_ablation","title":"<code>plot_ablation(eta_list, avg_prec, EIF_value, dataset_name, plot_path=os.getcwd(), show_plot=False, save_plot=True, change_ylim=False)</code>","text":"<p>Obtain the plot of the Average precision values against different values of the era parameter.</p> <p>Parameters:</p> Name Type Description Default <code>eta_list</code> <code>List[float]</code> <p>The list of eta values.</p> required <code>avg_prec</code> <code>List[ndarray]</code> <p>The list of average precision values.</p> required <code>EIF_value</code> <code>float</code> <p>The average precision value of the EIF model.</p> required <code>dataset_name</code> <code>str</code> <p>The dataset name.</p> required <code>plot_path</code> <code>str</code> <p>The path where the plot will be saved. Defaults to os.getcwd().</p> <code>getcwd()</code> <code>show_plot</code> <code>bool</code> <p>A boolean indicating whether the plot should be displayed. Defaults to False.</p> <code>False</code> <code>save_plot</code> <code>bool</code> <p>A boolean indicating whether the plot should be saved. Defaults to True.</p> <code>True</code> <code>change_ylim</code> <code>bool</code> <p>A boolean indicating whether the y axis limits should be changed. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[figure, axes]</code> <p>The figure and axes objects used to create the plot.</p> Source code in <code>utils_reboot/plots.py</code> <pre><code>def plot_ablation(eta_list:List[float],\n                  avg_prec:List[np.ndarray],\n                  EIF_value:float,\n                  dataset_name:str,\n                  plot_path:str=os.getcwd(),\n                  show_plot:bool=False,\n                  save_plot:bool=True,\n                  change_ylim:bool=False) -&gt; tuple[plt.figure, plt.axes]:\n\n    \"\"\"\n    Obtain the plot of the Average precision values against different values of the era parameter.\n\n    Args:\n        eta_list: The list of eta values.\n        avg_prec: The list of average precision values.\n        EIF_value: The average precision value of the EIF model.\n        dataset_name: The dataset name.\n        plot_path: The path where the plot will be saved. Defaults to os.getcwd().\n        show_plot: A boolean indicating whether the plot should be displayed. Defaults to False.\n        save_plot: A boolean indicating whether the plot should be saved. Defaults to True.\n        change_ylim: A boolean indicating whether the y axis limits should be changed. Defaults to False.\n\n    Returns:\n        The figure and axes objects used to create the plot.\n    \"\"\"\n\n    fig, ax = plt.subplots()\n    plt.style.use('default')\n    plt.rcParams['axes.facecolor'] = '#F2F2F2'\n    plt.grid(alpha = 0.7)\n    colors = [\"tab:red\",\"tab:blue\",\"tab:orange\",\"tab:green\",\"tab:blue\"]\n\n\n    median_values=[np.mean(x) for x in avg_prec]\n    five_values=[np.percentile(x,5) for x in avg_prec]\n    ninefive_values=[np.percentile(x,95) for x in avg_prec]\n\n    ax.plot(eta_list,median_values,alpha=0.85,c=colors[0],marker=\"o\",label=\"EIF+\")\n    ax.plot(eta_list,[EIF_value]*len(eta_list),alpha=0.85,c=colors[1],label=\"EIF\")\n    ax.fill_between(eta_list,five_values,ninefive_values,alpha=0.1,color=colors[0])\n\n\n    ax.set_xlabel(\"Eta\",fontsize = 20)\n    ax.set_ylabel('Avg Prec',fontsize = 20)\n\n\n    ax.grid(visible=True, alpha=0.5, which='major', color='gray', linestyle='-')\n\n    if change_ylim:\n        ax.set_ylim([0,1.1])\n    else:\n        ax.set_ylim([0,1])\n\n    plt.legend()\n\n    t = time.localtime()\n    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n\n    if save_plot:\n        plt.savefig(f'{plot_path}/{current_time}_EIF+_ablation_{dataset_name}.pdf',bbox_inches='tight')\n\n    if show_plot:\n        plt.show()\n\n    return fig,ax\n</code></pre>"},{"location":"plots/#utils_reboot.plots.plot_feature_selection","title":"<code>plot_feature_selection(precision_file, plot_path, precision_file_random=None, color=0, model=None, eval_model='EIF+', interpretation=None, scenario=2, save_image=True, plot_image=False, box_loc=None, change_box_loc=0.9, rotation=False, change_ylim=False)</code>","text":"<p>Obtain the feature selection plot.</p> <p>Parameters:</p> Name Type Description Default <code>precision_file</code> <code>str</code> <p>The path to the file containing the precision values.</p> required <code>plot_path</code> <code>str</code> <p>The path where the plot will be saved.</p> required <code>precision_file_random</code> <code>Optional[str]</code> <p>The path to the file containing precision values computed with the random Feature Selection approach. Defaults to None.</p> <code>None</code> <code>color</code> <code>int</code> <p>The color of the plot. Defaults to 0.</p> <code>0</code> <code>model</code> <code>Optional[str]</code> <p>Name of the AD model. Defaults to None.</p> <code>None</code> <code>eval_model</code> <code>Optional[str]</code> <p>Name of the evaluation model. Defaults to 'EIF+'.</p> <code>'EIF+'</code> <code>interpretation</code> <code>Optional[str]</code> <p>Name of the interpretation model used. Defaults to None.</p> <code>None</code> <code>scenario</code> <code>Optional[int]</code> <p>The scenario number. Defaults to 2.</p> <code>2</code> <code>save_image</code> <code>bool</code> <p>A boolean indicating whether the plot should be saved. Defaults to True.</p> <code>True</code> <code>plot_image</code> <code>bool</code> <p>A boolean indicating whether the plot should be displayed. Defaults to False.</p> <code>False</code> <code>box_loc</code> <code>tuple</code> <p>The location of the text box containing the Area under the curve of Feature Selection value. Defaults to None.</p> <code>None</code> <code>change_box_loc</code> <code>float</code> <p>Change the y axis value of the text box location containing the Area under the curve of Feature Selection value. Defaults to 0.9.</p> <code>0.9</code> <code>rotation</code> <code>bool</code> <p>A boolean indicating whether the x ticks should be rotated by 45 degrees. Defaults to False.</p> <code>False</code> <code>change_ylim</code> <code>bool</code> <p>A boolean indicating whether the y axis limits should be changed (from 1 to 1.1). Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>The function saves the plot in the specified path and displays it if the plot_image parameter is set to True.</p> Source code in <code>utils_reboot/plots.py</code> <pre><code>def plot_feature_selection(\n        precision_file: str,\n        plot_path:str,\n        precision_file_random:Optional[str]=None,\n        color:int=0,\n        model:Optional[str]=None,\n        eval_model:Optional[str]='EIF+',\n        interpretation:Optional[str]=None,\n        scenario:Optional[int]=2,\n        save_image:bool=True,\n        plot_image:bool=False,\n        box_loc:tuple=None,\n        change_box_loc:float=0.9,\n        rotation:bool=False,\n        change_ylim:bool=False)-&gt; None:\n\n    \"\"\"\n    Obtain the feature selection plot.\n\n    Args:\n        precision_file: The path to the file containing the precision values.\n        plot_path: The path where the plot will be saved.\n        precision_file_random: The path to the file containing precision values computed with the random Feature Selection approach. Defaults to None.\n        color: The color of the plot. Defaults to 0.\n        model: Name of the AD model. Defaults to None.\n        eval_model: Name of the evaluation model. Defaults to 'EIF+'.\n        interpretation: Name of the interpretation model used. Defaults to None.\n        scenario: The scenario number. Defaults to 2.\n        save_image: A boolean indicating whether the plot should be saved. Defaults to True.\n        plot_image: A boolean indicating whether the plot should be displayed. Defaults to False.\n        box_loc: The location of the text box containing the Area under the curve of Feature Selection value. Defaults to None.\n        change_box_loc: Change the y axis value of the text box location containing the Area under the curve of Feature Selection value. Defaults to 0.9.\n        rotation: A boolean indicating whether the x ticks should be rotated by 45 degrees. Defaults to False.\n        change_ylim: A boolean indicating whether the y axis limits should be changed (from 1 to 1.1). Defaults to False.\n\n    Returns:\n        The function saves the plot in the specified path and displays it if the plot_image parameter is set to True.\n\n    \"\"\"\n\n    colors = [\"tab:red\",\"tab:gray\",\"tab:orange\",\"tab:green\",\"tab:blue\",\"tab:olive\",'tab:brown']\n    if model is None:\n        model = \"\"\n    #Precisions = namedtuple(\"Precisions\",[\"direct\",\"inverse\",\"dataset\",\"model\",\"value\"])\n\n    t = time.localtime()\n    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n    precision = open_element(precision_file)\n\n    #model = precision.model\n    aucfs = precision.aucfs\n\n    median_direct     = [np.percentile(x, 50) for x in precision.direct]\n    five_direct       = [np.percentile(x, 95) for x in precision.direct]\n    ninetyfive_direct = [np.percentile(x, 5) for x in precision.direct]\n    median_inverse    = [np.percentile(x, 50) for x in precision.inverse]\n    five_inverse       = [np.percentile(x, 95) for x in precision.inverse]\n    ninetyfive_inverse = [np.percentile(x, 5) for x in precision.inverse]\n    dim = len(median_direct)\n\n    plt.style.use('default')\n    plt.rcParams['axes.facecolor'] = '#F2F2F2'\n    plt.grid(alpha = 0.7)\n\n    #import ipdb; ipdb.set_trace()\n\n    if precision_file_random is not None:\n        precision_random=open_element(precision_file_random)\n        median_random = [np.percentile(x, 50) for x in precision_random.random]\n        plt.plot(median_random,label=\"random\",c=colors[3],alpha=0.5,marker=\"o\")\n\n    plt.plot(median_direct,label=\"direct\",c=colors[4],alpha=0.5,marker=\"o\")#markers[c])\n    plt.plot(median_inverse,label=\"inverse\",c=colors[color],alpha=0.5,marker=\"o\")\n\n    plt.xlabel(\"Number of Features\",fontsize = 20)\n    plt.ylabel(\"Average Precision\",fontsize = 20)\n    #plt.title(\"Feature selection \"+model, fontsize = 18)\n\n    if rotation:\n        plt.xticks(range(dim),range(dim,0,-1),rotation=45)\n    else:\n        plt.xticks(range(dim),range(dim,0,-1))    \n\n    if box_loc is None:\n       box_loc = (len(precision.direct)/2,change_box_loc)\n\n    text_box_content = r'${}'.format(\"AUC\") + r'_{FS}$' + \" = \" + str(np.round(aucfs,3))\n    plt.text(box_loc[0],box_loc[1], text_box_content, bbox=dict(facecolor='white', alpha=0.5, boxstyle=\"round\", pad=0.5), \n         verticalalignment='top', horizontalalignment='right')\n\n    if change_ylim:\n        plt.ylim(0,1.1)\n    else:\n        plt.ylim(0,1)\n\n    plt.fill_between(np.arange(dim),five_direct, ninetyfive_direct,alpha=0.1, color=\"k\")\n    plt.fill_between(np.arange(dim),five_inverse, ninetyfive_inverse,alpha=0.1, color=\"k\")\n    plt.fill_between(np.arange(dim),median_direct, median_inverse,alpha=0.7, color=colors[color])\n    plt.legend(bbox_to_anchor = (1.05,0.95),loc=\"upper left\")\n    plt.grid(visible=True, alpha=0.5, which='major', color='gray', linestyle='-')\n\n    if model=='EIF+' and interpretation=='EXIFFI+':\n        namefile = \"/\" + current_time + \"_\" + precision.dataset + \"_\" + eval_model + '_' + \"EXIFFI+\" + \"_feature_selection_\" + str(scenario) + \".pdf\"\n    elif model=='EIF' and interpretation=='EXIFFI':\n            namefile = \"/\" + current_time + \"_\" + precision.dataset + \"_\" + eval_model + '_' + 'EXIFFI' + \"_feature_selection_\" + str(scenario) + \".pdf\"\n    else:\n        namefile = \"/\" + current_time + \"_\" + precision.dataset + \"_\" + eval_model + '_' + model + \"_\" + interpretation + \"_feature_selection_\" + str(scenario) + \".pdf\"\n\n    if save_image:\n        plt.savefig(plot_path+namefile,bbox_inches = \"tight\")\n    if plot_image:\n        plt.show()\n</code></pre>"},{"location":"plots/#utils_reboot.plots.plot_precision_over_contamination","title":"<code>plot_precision_over_contamination(precisions, dataset_name, model_name, plot_path, contamination=np.linspace(0.0, 0.1, 10), save_image=True, plot_image=False, ylim=(0, 1))</code>","text":"<p>Obtain the precision over contamination plot.</p> <p>Parameters:</p> Name Type Description Default <code>precisions</code> <code>ndarray</code> <p>The precision values for different contamination values, obtained from the contamination_in_training_precision_evaluation method.</p> required <code>dataset_name</code> <code>str</code> <p>The dataset name.</p> required <code>model_name</code> <code>str</code> <p>The model name.</p> required <code>plot_path</code> <code>str</code> <p>The path where the plot will be saved.</p> required <code>contamination</code> <code>ndarray</code> <p>The contamination values. Defaults to np.linspace(0.0,0.1,10).</p> <code>linspace(0.0, 0.1, 10)</code> <code>save_image</code> <code>bool</code> <p>A boolean indicating whether the plot should be saved. Defaults to True.</p> <code>True</code> <code>plot_image</code> <code>bool</code> <p>A boolean indicating whether the plot should be displayed. Defaults to False.</p> <code>False</code> <code>ylim</code> <code>tuple</code> <p>The y axis limits. Defaults to (0,1).</p> <code>(0, 1)</code> <p>Returns:</p> Type Description <code>None</code> <p>The function saves the plot in the specified path and displays it if the plot_image parameter is set to True.</p> Source code in <code>utils_reboot/plots.py</code> <pre><code>def plot_precision_over_contamination(precisions:np.ndarray,\n                                      dataset_name:str,\n                                      model_name:str,\n                                      plot_path:str,\n                                      contamination:np.ndarray=np.linspace(0.0,0.1,10),\n                                      save_image:bool=True,\n                                      plot_image:bool=False,\n                                      ylim:tuple=(0,1)) -&gt; None:\n\n    \"\"\"\n    Obtain the precision over contamination plot.\n\n    Args:\n        precisions: The precision values for different contamination values, obtained from the contamination_in_training_precision_evaluation method.\n        dataset_name: The dataset name.\n        model_name: The model name.\n        plot_path: The path where the plot will be saved.\n        contamination: The contamination values. Defaults to np.linspace(0.0,0.1,10).\n        save_image: A boolean indicating whether the plot should be saved. Defaults to True.\n        plot_image: A boolean indicating whether the plot should be displayed. Defaults to False.\n        ylim: The y axis limits. Defaults to (0,1).\n\n    Returns:\n        The function saves the plot in the specified path and displays it if the plot_image parameter is set to True.\n\n    \"\"\"\n\n    t = time.localtime()\n    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n\n    plt.style.use('default')\n    plt.rcParams['axes.facecolor'] = '#F2F2F2'\n    plt.grid(alpha = 0.7)\n    plt.plot(contamination,precisions.mean(axis=1),marker=\"o\",c=\"tab:blue\",alpha=0.5,label=model_name)\n    plt.fill_between(contamination, [np.percentile(x, 10) for x in precisions], [np.percentile(x, 90) for x in precisions],alpha=0.1, color=\"tab:blue\")\n\n    plt.ylim(ylim)\n\n    plt.xlabel(\"Contamination\",fontsize = 20)\n    plt.ylabel(\"Average Precision\",fontsize = 20)\n\n    namefile = current_time + \"_\" + dataset_name + '_' + model_name + \"_precision_over_contamination.pdf\"\n\n    if save_image:\n        plt.savefig(plot_path + \"/\" + namefile, bbox_inches = \"tight\")\n\n    if plot_image:\n        plt.show()\n</code></pre>"},{"location":"plots/#utils_reboot.plots.plot_time_scaling","title":"<code>plot_time_scaling(model_names, dataset_names, data_path, type='predict', plot_type='samples', plot_path=os.getcwd(), show_plot=True, save_plot=True)</code>","text":"<p>Obtain the time scaling plot.</p> <p>Parameters:</p> Name Type Description Default <code>model_names</code> <code>List[str]</code> <p>The list of model names.</p> required <code>dataset_names</code> <code>List[str]</code> <p>The list of dataset names.</p> required <code>data_path</code> <code>str</code> <p>The path to the datasets.</p> required <code>type</code> <code>str</code> <p>The type of execution time, accepted values are: ['fit','predict','importances'] Defaults to 'predict'.</p> <code>'predict'</code> <code>plot_type</code> <code>str</code> <p>The type of plot, accepted values are ['samples','features']. Defaults to 'samples'.</p> <code>'samples'</code> <code>plot_path</code> <code>str</code> <p>The path where the plot will be saved. Defaults to os.getcwd().</p> <code>getcwd()</code> <code>show_plot</code> <code>bool</code> <p>A boolean indicating whether the plot should be displayed. Defaults to True.</p> <code>True</code> <code>save_plot</code> <code>bool</code> <p>A boolean indicating whether the plot should be saved. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[figure, axes]</code> <p>The figure and axes objects used to create the plot.</p> Source code in <code>utils_reboot/plots.py</code> <pre><code>def plot_time_scaling(model_names:List[str],\n                      dataset_names:List[str],\n                      data_path:str,\n                      type:str='predict',\n                      plot_type:str='samples',\n                      plot_path:str=os.getcwd(),\n                      show_plot:bool=True,\n                      save_plot:bool=True)-&gt; tuple[plt.figure, plt.axes]:\n\n    \"\"\"\n    Obtain the time scaling plot.\n\n    Args:\n        model_names: The list of model names.\n        dataset_names: The list of dataset names.\n        data_path: The path to the datasets.\n        type: The type of execution time, accepted values are: ['fit','predict','importances'] Defaults to 'predict'.\n        plot_type: The type of plot, accepted values are ['samples','features']. Defaults to 'samples'.\n        plot_path: The path where the plot will be saved. Defaults to os.getcwd().\n        show_plot: A boolean indicating whether the plot should be displayed. Defaults to True.\n        save_plot: A boolean indicating whether the plot should be saved. Defaults to True.\n\n    Returns:\n        The figure and axes objects used to create the plot.\n    \"\"\"\n\n    assert type in ['predict','fit','importances'], \"Type not valid. Accepted values: ['predict','fit','importances'] \"\n    assert plot_type in ['samples','features'], \"Plot Type not valid. Accepted values: ['samples','features']\"\n\n    datasets=[Dataset(name,path=data_path) for name in dataset_names]\n\n    if plot_type == \"samples\":\n        sample_sizes=[data.shape[0] for data in datasets]\n    elif plot_type == \"features\":\n        sample_sizes=[data.shape[1] for data in datasets]\n\n    fig, ax = plt.subplots()\n    plt.style.use('default')\n    plt.rcParams['axes.facecolor'] = '#F2F2F2'\n    plt.grid(alpha = 0.7)\n    colors = [\"tab:red\",\"tab:blue\",\"tab:orange\",\"tab:green\",\"tab:blue\"]\n\n    maxs=[]\n    mins=[]\n    for i,model in enumerate(model_names):\n        median_times,five_times,ninefive_times=get_vals(model,dataset_names,type=type)\n        maxs.append(np.max(median_times))\n        mins.append(np.min(median_times))\n\n        ax.plot(sample_sizes,median_times,alpha=0.85,c=colors[i],marker=\"o\",label=model)\n        ax.fill_between(sample_sizes,five_times,ninefive_times,alpha=0.1,color=colors[i])\n\n    if plot_type == \"samples\":\n        ax.set_yscale('log')\n        ax.set_xscale(\"log\")\n        ax.yaxis.set_major_locator(AutoLocator())\n        ax.yaxis.set_major_formatter(ScalarFormatter())\n        ax.minorticks_off()\n        ax.set_xticks(sample_sizes,sample_sizes,rotation=45,fontsize = 12)\n        ax.set_yticks([1,10,25,100,250],fontsize = 14)\n\n    ax.set_xlabel('Sample Size',fontsize = 20)\n    ax.set_ylabel(f'{type} Time (s)',fontsize = 20)\n    #plt.ylim(np.min(mins)-0.2*np.min(mins),np.max(maxs)+0.2*np.max(maxs))\n\n\n    ax.legend()\n    ax.grid(visible=True, alpha=0.5, which='major', color='gray', linestyle='-')\n\n    t = time.localtime()\n    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n\n    if save_plot:\n        plt.savefig(f'{plot_path}/{current_time}_time_scaling_plot_{plot_type}_{type}.pdf',bbox_inches='tight')\n\n    if show_plot:\n        plt.show()\n\n    return fig,ax\n</code></pre>"},{"location":"plots/#utils_reboot.plots.score_plot","title":"<code>score_plot(dataset, global_importances_file, plot_path=os.getcwd(), save_image=True, show_plot=True, model='EIF+', interpretation='EXIFFI', scenario=1)</code>","text":"<p>Obtain the Global Feature Importance Score Plot starting from the Global Feature Importance vector.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Type[Dataset]</code> <p>Input dataset</p> required <code>global_importances_file</code> <code>str</code> <p>The path to the file containing the global importances.</p> required <code>plot_path</code> <code>str</code> <p>The path where the plot will be saved. Defaults to os.getcwd().</p> <code>getcwd()</code> <code>save_image</code> <p>A boolean indicating whether the plot should be saved. Defaults to True.</p> <code>True</code> <code>show_plot</code> <p>A boolean indicating whether the plot should be displayed. Defaults to True.</p> <code>True</code> <code>model</code> <code>str</code> <p>The AD model on which the importances should be computed. Defaults to 'EIF+'.</p> <code>'EIF+'</code> <code>interpretation</code> <code>str</code> <p>The interpretation model used. Defaults to 'EXIFFI'.</p> <code>'EXIFFI'</code> <code>scenario</code> <p>The scenario number. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>tuple[axes, axes]</code> <p>The two axes objects used to create the plot.</p> Source code in <code>utils_reboot/plots.py</code> <pre><code>def score_plot(dataset: Type[Dataset], \n            global_importances_file: str,\n            plot_path: str = os.getcwd(), \n            save_image = True, \n            show_plot = True,\n            model:str='EIF+',\n            interpretation:str=\"EXIFFI\",\n            scenario=1) -&gt; tuple[plt.axes, plt.axes]:\n    \"\"\"\n    Obtain the Global Feature Importance Score Plot starting from the Global Feature Importance vector.\n\n    Args:\n        dataset: Input dataset\n        global_importances_file: The path to the file containing the global importances.\n        plot_path: The path where the plot will be saved. Defaults to os.getcwd().\n        save_image: A boolean indicating whether the plot should be saved. Defaults to True.\n        show_plot: A boolean indicating whether the plot should be displayed. Defaults to True.\n        model: The AD model on which the importances should be computed. Defaults to 'EIF+'.\n        interpretation: The interpretation model used. Defaults to 'EXIFFI'.\n        scenario: The scenario number. Defaults to 1.\n\n    Returns:\n        The two axes objects used to create the plot.\n\n    \"\"\"\n   # Compute the plt_data with the compute_plt_data function\n    col_names = dataset.feature_names\n    plt_data = compute_plt_data(global_importances_file)\n\n    t = time.localtime()\n    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n\n    if (model=='EIF+' and interpretation=='EXIFFI+') or (model=='EIF' and interpretation=='EXIFFI'):\n        name_file = f\"{current_time}_GFI_Score_plot_{dataset.name}_{interpretation}_{scenario}\"\n    else:\n        name_file = f\"{current_time}_GFI_Score_plot_{dataset.name}_{model}_{interpretation}_{scenario}\"\n\n    patterns=[None,'!','@','#','$','^','&amp;','*','\u00b0','(',')','-','_','+','=','[',']','{','}',\n    '|',';',':',',','.','&lt;','&gt;','/','?','`','~','\\\\','!!','@@','##','$$','^^','&amp;&amp;','**','\u00b0\u00b0','((']\n    imp_vals=plt_data['Importances']\n    feat_imp=pd.DataFrame({'Global Importance': np.round(imp_vals,3),\n                        'Feature': plt_data['feat_order'],\n                        'std': plt_data['std']\n                        })\n\n    if len(feat_imp)&gt;15:\n        feat_imp=feat_imp.iloc[-15:].reset_index(drop=True)\n\n    dim=feat_imp.shape[0]\n\n    number_colours = 20\n\n    plt.style.use('default')\n    plt.rcParams['axes.facecolor'] = '#F2F2F2'\n    plt.rcParams['axes.axisbelow'] = True\n    color = plt.cm.get_cmap('tab20',number_colours).colors\n    ax1=feat_imp.plot(y='Global Importance',x='Feature',kind=\"barh\",color=color[feat_imp['Feature']%number_colours],xerr='std',\n                    capsize=5, alpha=1,legend=False,\n                    hatch=[patterns[i//number_colours] for i in feat_imp['Feature']])\n    xlim=np.min(imp_vals)-0.05*np.min(imp_vals)\n\n    ax1.grid(alpha=0.7)\n    ax2 = ax1.twinx()\n    # Add labels on the right side of the bars\n    values=[]\n    for i, v in enumerate(feat_imp['Global Importance']):\n        values.append(str(v) + ' +- ' + str(np.round(feat_imp['std'][i],2)))\n\n    ax2.set_ylim(ax1.get_ylim())\n    ax2.set_yticks(range(dim))\n    ax2.set_yticklabels(values)\n    ax2.grid(alpha=0)\n    plt.axvline(x=0, color=\".5\")\n    ax1.set_xlabel('Importance Score',fontsize=20)\n    ax1.set_ylabel('Features',fontsize=20)\n    plt.xlim(xlim)\n    plt.subplots_adjust(left=0.3)\n\n    if col_names is not None:\n        ax1.set_yticks(range(dim))\n        idx=list(feat_imp['Feature'])\n        yticks=[col_names[i] for i in idx]\n        ax1.set_yticklabels(yticks)\n\n    if save_image:\n        plt.savefig(plot_path + f'/{name_file}.pdf', bbox_inches='tight')\n\n    if show_plot:\n        plt.show()\n\n    return ax1,ax2\n</code></pre>"},{"location":"tutorial/","title":"ExIFFI and EIF+ Tutorial Notebook","text":"<p>Import needed packages</p> In\u00a0[1]: Copied! <pre>import os \nimport sys\nsys.path.append('../')\nfrom utils_reboot.datasets import Dataset\nfrom utils_reboot.utils import *\nfrom utils_reboot.experiments import *\nfrom utils_reboot.plots import *\nfrom model_reboot import *\nimport numpy as np\n</pre> import os  import sys sys.path.append('../') from utils_reboot.datasets import Dataset from utils_reboot.utils import * from utils_reboot.experiments import * from utils_reboot.plots import * from model_reboot import * import numpy as np <pre>2024-05-10 09:37:01.993643: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n</pre> <p>Set up some useful paths</p> In\u00a0[2]: Copied! <pre>os.chdir('../')\ncwd=os.getcwd()\ndata_syn_path=cwd+'/data/syn/'\ndata_real_path=cwd+'/data/real/'\nexperiment_path=cwd+'/experiments/results'\n</pre> os.chdir('../') cwd=os.getcwd() data_syn_path=cwd+'/data/syn/' data_real_path=cwd+'/data/real/' experiment_path=cwd+'/experiments/results' <p>Import the dataset using the <code>Dataset</code> class from the <code>datasets</code> module. If the dataset has more than 7500 samples it will be downsampled to 7500 samples.</p> <p>For this example we will use the <code>wine</code> Real World Dataset. To change the dataset change the first argument of the <code>Dataset</code> class to the desired dataset name. The dataset names correspond to the names of the files contained in <code>data/real/</code> or <code>data/syn</code> folders.</p> In\u00a0[15]: Copied! <pre>dataset = Dataset('wine', path = data_real_path, feature_names_filepath='data/')\ndataset.drop_duplicates()\n\nif dataset.shape[0] &gt; 7500:\n    dataset.downsample(max_samples=7500)\n</pre> dataset = Dataset('wine', path = data_real_path, feature_names_filepath='data/') dataset.drop_duplicates()  if dataset.shape[0] &gt; 7500:     dataset.downsample(max_samples=7500) In\u00a0[21]: Copied! <pre>scenario=select_pre_process_scenario(dataset)\n</pre> scenario=select_pre_process_scenario(dataset) <pre>Dataset pre processed\n\nScenario: 2\n\nX_train shape: (119, 13)\nX_test shape: (129, 13)\n</pre> <p>For the sake of this example we will use the <code>EIF+</code> model with the default parameters. For all the details about the input parameters please refer to the <code>ExtendedIsolationForest</code> class contained in <code>model_reboot/EIF_reboot.py</code> or to the Models section in the documentation.</p> In\u00a0[5]: Copied! <pre>I=ExtendedIsolationForest(1)\n</pre> I=ExtendedIsolationForest(1) <p>Exploiting the <code>performance</code> function it is possible to obtain a Classification report for the input dataset and the <code>EIF+</code> model. The resulting values may be sligthly different from the ones reported on the paper because of the intrinsic stochasticity in the <code>EIF+</code> model.</p> In\u00a0[6]: Copied! <pre>I.fit(dataset.X_train)\nscore=I.predict(dataset.X_test)\ny_pred=I._predict(dataset.X_test,p=dataset.perc_outliers)\nperformance_metrics,_=performance(y_pred=y_pred,\n                                       y_true=dataset.y_test,\n                                       score=score,\n                                       I=I,\n                                       model_name=I.name,\n                                       dataset=dataset,\n                                       contamination=dataset.perc_outliers,\n                                       scenario=scenario,\n                                       save=False)\nperformance_metrics.T\n</pre> I.fit(dataset.X_train) score=I.predict(dataset.X_test) y_pred=I._predict(dataset.X_test,p=dataset.perc_outliers) performance_metrics,_=performance(y_pred=y_pred,                                        y_true=dataset.y_test,                                        score=score,                                        I=I,                                        model_name=I.name,                                        dataset=dataset,                                        contamination=dataset.perc_outliers,                                        scenario=scenario,                                        save=False) performance_metrics.T <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:03&lt;00:00,  2.87it/s]\n</pre> Out[6]: 2024-05-10 09:38:58.171460 Model EIF+ Dataset wine Contamination 0.077519 Train Size 0.8 Precision 0.8 Recall 0.8 f1 score 0.8 Accuracy 0.968992 Balanced Accuracy 0.891597 Average Precision 0.840966 ROC AUC Score 0.891597 In\u00a0[8]: Copied! <pre>interpretation=\"EXIFFI+\"\npath_gfi=os.path.join(experiment_path,\n                  dataset.name,\n                  'experiments',\n                  'global_importances',\n                  I.name,\n                  interpretation,\n                  f'scenario_{str(scenario)}'\n                  )\nif not os.path.exists(path_gfi):\n    os.makedirs(path_gfi)\n\nfull_importances,_ = experiment_global_importances(I, \n                                                   dataset, \n                                                   n_runs=40, \n                                                   p=0.1, \n                                                   interpretation=interpretation) \nsave_element(full_importances, path_gfi, filetype=\"npz\")\n</pre> interpretation=\"EXIFFI+\" path_gfi=os.path.join(experiment_path,                   dataset.name,                   'experiments',                   'global_importances',                   I.name,                   interpretation,                   f'scenario_{str(scenario)}'                   ) if not os.path.exists(path_gfi):     os.makedirs(path_gfi)  full_importances,_ = experiment_global_importances(I,                                                     dataset,                                                     n_runs=40,                                                     p=0.1,                                                     interpretation=interpretation)  save_element(full_importances, path_gfi, filetype=\"npz\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:14&lt;00:00,  2.77it/s]\n</pre> <p>The importance matrix generated in the previous cell is now used to produce the Bar Plot. If the argument <code>save_image</code> is set to <code>True</code> the plot is saved in the path: <code>ExIFFI/experiments/results/dataset_name/plots_new/imp_plots/</code></p> In\u00a0[16]: Copied! <pre>path_plots=os.path.join(experiment_path,dataset.name,'plots_new','imp_plots')\nif not os.path.exists(path_plots):\n    os.makedirs(path_plots)\n\nmost_recent_file = get_most_recent_file(path_gfi,filetype=\"npz\")\n_,_,_=bar_plot(dataset, \n         most_recent_file, \n         filetype=\"npz\", \n         plot_path=path_plots, \n         f=min(dataset.shape[1],6),\n         show_plot=True,\n         model=I, \n         interpretation=interpretation, \n         scenario=scenario,\n         save_image=False)\n</pre> path_plots=os.path.join(experiment_path,dataset.name,'plots_new','imp_plots') if not os.path.exists(path_plots):     os.makedirs(path_plots)  most_recent_file = get_most_recent_file(path_gfi,filetype=\"npz\") _,_,_=bar_plot(dataset,           most_recent_file,           filetype=\"npz\",           plot_path=path_plots,           f=min(dataset.shape[1],6),          show_plot=True,          model=I,           interpretation=interpretation,           scenario=scenario,          save_image=False)  <p>Use the Global Importances file most recently calculated to obtain the Score Plot. If the argument <code>save_image</code> is set to <code>True</code> the plot is saved in the path: <code>ExIFFI/experiments/results/dataset_name/plots_new/imp_plots/</code></p> In\u00a0[17]: Copied! <pre>_,_=score_plot(dataset,\n           most_recent_file,\n           plot_path=path_plots,\n           show_plot=True,\n           model=I,\n           interpretation=interpretation,\n           scenario=scenario,\n           save_image=False)\n</pre> _,_=score_plot(dataset,            most_recent_file,            plot_path=path_plots,            show_plot=True,            model=I,            interpretation=interpretation,            scenario=scenario,            save_image=False) In\u00a0[22]: Copied! <pre>path_plots_local=os.path.join(experiment_path,dataset.name,'plots_new','local_scoremaps')\nif not os.path.exists(path_plots_local):\n    os.makedirs(path_plots_local)\n    \nfeature1=\"Proline\"\nfeature2=\"Magnesium\"\nfeats_plot=get_feature_indexes(dataset,feature1,feature2)\nimportance_map(dataset=dataset,\n               model=I,\n               feats_plot=feats_plot,\n               path_plot=path_plots_local,\n               col_names=dataset.feature_names,\n               interpretation=interpretation,\n               scenario=scenario,\n               save_plot=False)\n</pre> path_plots_local=os.path.join(experiment_path,dataset.name,'plots_new','local_scoremaps') if not os.path.exists(path_plots_local):     os.makedirs(path_plots_local)      feature1=\"Proline\" feature2=\"Magnesium\" feats_plot=get_feature_indexes(dataset,feature1,feature2) importance_map(dataset=dataset,                model=I,                feats_plot=feats_plot,                path_plot=path_plots_local,                col_names=dataset.feature_names,                interpretation=interpretation,                scenario=scenario,                save_plot=False) <p>In order to obtain the Feature Selection plot we need to use the <code>.npz</code> file containing the Global Importances vector computed by <code>EXIFFI</code> to order the features in decreasing order of importance.</p> <p>In this case the <code>EIF+</code> model will be used to compute the Average Precisions (variable <code>I</code>) and the <code>EIF+</code> model will be the ones interpreted by <code>ExIFFI</code> (variable <code>model_interpretation</code>). It is possible to set <code>model_interpretation</code> also to <code>IF</code> or <code>EIF</code> to interpret also these models.</p> <p>The Average Precisions needed to create the plot will be saved in path:</p> <p><code>ExIFFI/experiments/results/dataset_name/experiments/feature_selection/model_name/model_interpretation_interpretation/scenario/</code></p> In\u00a0[23]: Copied! <pre>model_interpretation='EIF+'\npath_plots_fs=os.path.join(experiment_path,dataset.name,'plots_new','fs_plots')\nif not os.path.exists(path_plots_fs):\n    os.makedirs(path_plots_fs)\n\nmatrix = open_element(most_recent_file,filetype=\"npz\")\n# Order the features in decreasing order of importance\nfeat_order = np.argsort(matrix.mean(axis=0))\nPrecisions = namedtuple(\"Precisions\",[\"direct\",\"inverse\",\"dataset\",\"model\",\"value\"])\n\n# Compute the Average Precisions for the different sets of features\ndirect = feature_selection(I, dataset, feat_order, 10, inverse=False, random=False, scenario=scenario)\ninverse = feature_selection(I, dataset, feat_order, 10, inverse=True, random=False, scenario=scenario)\nvalue = abs(np.nansum(np.nanmean(direct,axis=1)-np.nanmean(inverse,axis=1)))\ndata = Precisions(direct, inverse, dataset.name, I.name, value)\npath_fs=os.path.join(experiment_path,\n                  dataset.name,\n                  'experiments',\n                  'feature_selection',\n                  I.name,\n                  f'{model_interpretation}_{interpretation}',\n                  f'scenario_{str(scenario)}'\n                  )\nsave_fs_prec(data, path_fs)\n</pre> model_interpretation='EIF+' path_plots_fs=os.path.join(experiment_path,dataset.name,'plots_new','fs_plots') if not os.path.exists(path_plots_fs):     os.makedirs(path_plots_fs)  matrix = open_element(most_recent_file,filetype=\"npz\") # Order the features in decreasing order of importance feat_order = np.argsort(matrix.mean(axis=0)) Precisions = namedtuple(\"Precisions\",[\"direct\",\"inverse\",\"dataset\",\"model\",\"value\"])  # Compute the Average Precisions for the different sets of features direct = feature_selection(I, dataset, feat_order, 10, inverse=False, random=False, scenario=scenario) inverse = feature_selection(I, dataset, feat_order, 10, inverse=True, random=False, scenario=scenario) value = abs(np.nansum(np.nanmean(direct,axis=1)-np.nanmean(inverse,axis=1))) data = Precisions(direct, inverse, dataset.name, I.name, value) path_fs=os.path.join(experiment_path,                   dataset.name,                   'experiments',                   'feature_selection',                   I.name,                   f'{model_interpretation}_{interpretation}',                   f'scenario_{str(scenario)}'                   ) save_fs_prec(data, path_fs)  <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:34&lt;00:00,  2.62s/it]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:33&lt;00:00,  2.58s/it]\n</pre> <p>Compute the Average Precision of a random Feature Selection approach to have a baseline</p> In\u00a0[24]: Copied! <pre>Precisions_random = namedtuple(\"Precisions_random\",[\"random\",\"dataset\",\"model\"])\nrandom = feature_selection(I, dataset, feat_order, 10, inverse=True, random=True, scenario=scenario)\ndata_random = Precisions_random(random, dataset.name, I.name)\npath_random=os.path.join(experiment_path,\n                  dataset.name,\n                  'experiments',\n                  'feature_selection',\n                  I.name,\n                  'random',\n                  f'scenario_{str(scenario)}'\n                  )\nsave_fs_prec_random(data_random, path_random)\n</pre> Precisions_random = namedtuple(\"Precisions_random\",[\"random\",\"dataset\",\"model\"]) random = feature_selection(I, dataset, feat_order, 10, inverse=True, random=True, scenario=scenario) data_random = Precisions_random(random, dataset.name, I.name) path_random=os.path.join(experiment_path,                   dataset.name,                   'experiments',                   'feature_selection',                   I.name,                   'random',                   f'scenario_{str(scenario)}'                   ) save_fs_prec_random(data_random, path_random) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:33&lt;00:00,  2.59s/it]\n</pre> <p>Use the Average Precisions computed in the two previous cells to produce the Feature Selection plot. If the argument <code>save_image</code> is set to <code>True</code> the plot is saved in the path: <code>ExIFFI/experiments/results/dataset_name/plots_new/fs_plots/</code></p> In\u00a0[28]: Copied! <pre>fs_prec = get_most_recent_file(path_fs)\nfs_prec_random = get_most_recent_file(path_random)\nplot_feature_selection(fs_prec,\n                        path_plots, \n                        fs_prec_random, \n                        model=model_interpretation, \n                        eval_model=I.name, \n                        interpretation=interpretation, \n                        scenario=scenario, \n                        plot_image=True,\n                        change_ylim=True,\n                        save_image=False)\n</pre> fs_prec = get_most_recent_file(path_fs) fs_prec_random = get_most_recent_file(path_random) plot_feature_selection(fs_prec,                         path_plots,                          fs_prec_random,                          model=model_interpretation,                          eval_model=I.name,                          interpretation=interpretation,                          scenario=scenario,                          plot_image=True,                         change_ylim=True,                         save_image=False)"},{"location":"tutorial/#exiffi-and-eif-tutorial-notebook","title":"<code>ExIFFI</code> and <code>EIF+</code> Tutorial Notebook\u00b6","text":"<p>This notebook is intended to provide a tutorial on the usage of the <code>EIF+</code> and <code>ExIFFI</code> algorithms introduced in the paper ExIFFI and EIF+: Interpretability and Enhanced Generalizability to Extend the Extended Isolation Forest.</p> <p>It is possible to recreate the conda environment with all the dependencies needed to run this notebook from the <code>exiffi_env.yml</code> file using the following command:</p> <pre>conda env create -f exiffi_env.yml\n</pre>"},{"location":"tutorial/#import-data","title":"Import Data\u00b6","text":""},{"location":"tutorial/#select-scenario-and-pre_process","title":"Select Scenario and pre_process\u00b6","text":"<ul> <li>Scenario 1 \u2192 Train and test on the entire dataset</li> <li>Scenario 2 \u2192 Train solely on the inliers and test on the entire dataset</li> </ul> <p>Suggestion: Pre process the dataset for Real Word datasets (contained in <code>/data/real</code>) and do not pre process Synthetic datasets (contained in <code>/data/syn</code>)</p>"},{"location":"tutorial/#define-eif-model","title":"Define <code>EIF+</code> model\u00b6","text":""},{"location":"tutorial/#performance-metrics-computation","title":"Performance Metrics Computation\u00b6","text":""},{"location":"tutorial/#adding-interpretability-with-exiffi","title":"Adding interpretability with <code>ExIFFI</code>\u00b6","text":"<p>At this point we can evaluate the importances of each feature in the detection of anomalies through the <code>ExIFFI</code> model.</p>"},{"location":"tutorial/#compute-global-importances","title":"Compute Global Importances\u00b6","text":"<p>Compute the Global Importances vector and save it into a <code>.npz</code> file in the path:</p> <p><code>ExIFFI/experiments/results/dataset_name/experiments/global_importances/model_name/interpretation_name/scenario/</code></p>"},{"location":"tutorial/#bar-plot","title":"Bar Plot\u00b6","text":""},{"location":"tutorial/#score-plot","title":"Score Plot\u00b6","text":""},{"location":"tutorial/#local-scoremaps","title":"Local Scoremaps\u00b6","text":"<p>Hint: Use the top 2 features in terms of Importance to obtain the Local Scoremaps. If the argument <code>save_image</code> is set to <code>True</code> the plot is saved in the path: <code>ExIFFI/experiments/results/dataset_name/plots_new/local_scoremaps/</code></p>"},{"location":"tutorial/#feature-selection-plot","title":"Feature Selection Plot\u00b6","text":"<p>Unsupervised Feature Selection is used as a proxy task for the evaluation of the efficacy of the <code>EXIFFI</code> interpretation algorithm in both a qualitative (Feature Selection Plot) and quantitative manner ($AUC_{FS}$ metric).</p>"},{"location":"utils/","title":"Utils","text":"<p>This section contains the documentation for the <code>utils</code> module. This module collects a series of utility functions that are used mainly for the experiments. </p>"},{"location":"utils/#utils_reboot.utils.AutoEncoder","title":"<code>AutoEncoder</code>","text":"<p>             Bases: <code>AutoEncoder</code></p> <p>Wrapper of <code>pyod.models.auto_encoder.AutoEncoder</code></p> Source code in <code>utils_reboot/utils.py</code> <pre><code>class AutoEncoder(oldAutoEncoder):\n\n    \"\"\"\n    Wrapper of `pyod.models.auto_encoder.AutoEncoder`\n    \"\"\"\n\n    def __init__(self, **kwargs):\n\n        \"\"\"\n        Constructor of the class `AutoEncoder` which uses the constructor of the parent class `AutoEncoder` from `pyod.models.auto_encoder` module.\n\n        Attributes:\n            name (str): Add the name attribute to the class.\n        \"\"\"\n\n        super().__init__(**kwargs)\n        self.name = \"AnomalyAutoencoder\"\n\n    def predict(self, X:np.array) -&gt; np.array:\n\n        \"\"\"\n        Overwrite the `predict` method of the parent class `AutoEncoder` from `pyod.models.auto_encoder` module to obtain the\n        Anomaly Scores instead of the class labels (i.e. inliers and outliers)\n\n        Args:\n            X: Input dataset\n\n        Returns:\n            Anomaly Scores\n        \"\"\"\n        score=self.decision_function(X)\n        return score\n\n    def _predict(self,\n                 X:np.array,\n                 p:float)-&gt; np.array:\n\n        \"\"\"\n        Method to predict the class labels based on the Anomaly Scores and the contamination factor `p`\n\n        Args:\n            X: Input dataset\n            p: Contamination factor\n\n        Returns:\n            Class labels (i.e. 0 for inliers and 1 for outliers)\n        \"\"\"\n\n        An_score = self.predict(X)\n        y_hat = An_score &gt; sorted(An_score,reverse=True)[int(p*len(An_score))]\n        return y_hat\n</code></pre>"},{"location":"utils/#utils_reboot.utils.AutoEncoder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Constructor of the class <code>AutoEncoder</code> which uses the constructor of the parent class <code>AutoEncoder</code> from <code>pyod.models.auto_encoder</code> module.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Add the name attribute to the class.</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def __init__(self, **kwargs):\n\n    \"\"\"\n    Constructor of the class `AutoEncoder` which uses the constructor of the parent class `AutoEncoder` from `pyod.models.auto_encoder` module.\n\n    Attributes:\n        name (str): Add the name attribute to the class.\n    \"\"\"\n\n    super().__init__(**kwargs)\n    self.name = \"AnomalyAutoencoder\"\n</code></pre>"},{"location":"utils/#utils_reboot.utils.AutoEncoder.predict","title":"<code>predict(X)</code>","text":"<p>Overwrite the <code>predict</code> method of the parent class <code>AutoEncoder</code> from <code>pyod.models.auto_encoder</code> module to obtain the Anomaly Scores instead of the class labels (i.e. inliers and outliers)</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>array</code> <p>Anomaly Scores</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def predict(self, X:np.array) -&gt; np.array:\n\n    \"\"\"\n    Overwrite the `predict` method of the parent class `AutoEncoder` from `pyod.models.auto_encoder` module to obtain the\n    Anomaly Scores instead of the class labels (i.e. inliers and outliers)\n\n    Args:\n        X: Input dataset\n\n    Returns:\n        Anomaly Scores\n    \"\"\"\n    score=self.decision_function(X)\n    return score\n</code></pre>"},{"location":"utils/#utils_reboot.utils.DIF","title":"<code>DIF</code>","text":"<p>             Bases: <code>DIF</code></p> <p>Wrapper of <code>pyod.models.dif.DIF</code></p> Source code in <code>utils_reboot/utils.py</code> <pre><code>class DIF(oldDIF):\n\n    \"\"\"\n    Wrapper of `pyod.models.dif.DIF`\n    \"\"\"\n\n    def __init__(self, **kwargs):\n\n        \"\"\"\n        Constructor of the class `DIF` which uses the constructor of the parent class `DIF` from `pyod.models.dif` module.\n\n        Attributes:\n            name (str): Add the name attribute to the class.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.name = \"DIF\"\n\n    def predict(self, X:np.array) -&gt; np.array:\n\n        \"\"\"\n        Overwrite the `predict` method of the parent class `DIF` from `pyod.models.dif` module to obtain the\n        Anomaly Scores instead of the class labels (i.e. inliers and outliers)\n\n        Args:\n            X: Input dataset\n\n        Returns:\n            Anomaly Scores \n\n        \"\"\"\n\n        score=self.decision_function(X)\n        return score\n\n    def _predict(self,\n                 X:np.array,\n                 p:float)-&gt;np.array:\n\n        \"\"\"\n        Method to predict the class labels based on the Anomaly Scores and the contamination factor `p`\n\n        Args:\n            X: Input dataset\n            p: Contamination factor\n\n        Returns:\n            Class labels (i.e. 0 for inliers and 1 for outliers)\n        \"\"\"\n\n        An_score = self.predict(X)\n        y_hat = An_score &gt; sorted(An_score,reverse=True)[int(p*len(An_score))]\n        return y_hat\n</code></pre>"},{"location":"utils/#utils_reboot.utils.DIF.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Constructor of the class <code>DIF</code> which uses the constructor of the parent class <code>DIF</code> from <code>pyod.models.dif</code> module.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Add the name attribute to the class.</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def __init__(self, **kwargs):\n\n    \"\"\"\n    Constructor of the class `DIF` which uses the constructor of the parent class `DIF` from `pyod.models.dif` module.\n\n    Attributes:\n        name (str): Add the name attribute to the class.\n    \"\"\"\n    super().__init__(**kwargs)\n    self.name = \"DIF\"\n</code></pre>"},{"location":"utils/#utils_reboot.utils.DIF.predict","title":"<code>predict(X)</code>","text":"<p>Overwrite the <code>predict</code> method of the parent class <code>DIF</code> from <code>pyod.models.dif</code> module to obtain the Anomaly Scores instead of the class labels (i.e. inliers and outliers)</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>array</code> <p>Anomaly Scores</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def predict(self, X:np.array) -&gt; np.array:\n\n    \"\"\"\n    Overwrite the `predict` method of the parent class `DIF` from `pyod.models.dif` module to obtain the\n    Anomaly Scores instead of the class labels (i.e. inliers and outliers)\n\n    Args:\n        X: Input dataset\n\n    Returns:\n        Anomaly Scores \n\n    \"\"\"\n\n    score=self.decision_function(X)\n    return score\n</code></pre>"},{"location":"utils/#utils_reboot.utils.sklearn_IsolationForest","title":"<code>sklearn_IsolationForest</code>","text":"<p>             Bases: <code>IsolationForest</code></p> <p>Wrapper of <code>sklearn.ensemble.IsolationForest</code></p> Source code in <code>utils_reboot/utils.py</code> <pre><code>class sklearn_IsolationForest(IsolationForest):\n\n    \"\"\"\n    Wrapper of `sklearn.ensemble.IsolationForest` \n    \"\"\"\n\n    def __init__(self, **kwargs):\n\n        \"\"\"\n        Constructor of the class `sklearn_IsolationForest` which uses the constructor of the parent class `IsolationForest` from `sklearn.ensemble` module.\n\n        Attributes:\n            name (str): Add the name attribute to the class.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.name = \"sklearn_IF\"\n\n    def predict(self, X:np.array) -&gt; np.array:\n\n        \"\"\"\n        Overwrite the `predict` method of the parent class `IsolationForest` from `sklearn.ensemble` module to obtain the \n        Anomaly Scores instead of the class labels (i.e. inliers and outliers)\n\n        Args:\n            X: Input dataset\n\n        Returns:\n            Anomaly Scores \n        \"\"\"\n\n        score=self.decision_function(X)\n        return -1*score+0.5\n</code></pre>"},{"location":"utils/#utils_reboot.utils.sklearn_IsolationForest.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Constructor of the class <code>sklearn_IsolationForest</code> which uses the constructor of the parent class <code>IsolationForest</code> from <code>sklearn.ensemble</code> module.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Add the name attribute to the class.</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def __init__(self, **kwargs):\n\n    \"\"\"\n    Constructor of the class `sklearn_IsolationForest` which uses the constructor of the parent class `IsolationForest` from `sklearn.ensemble` module.\n\n    Attributes:\n        name (str): Add the name attribute to the class.\n    \"\"\"\n    super().__init__(**kwargs)\n    self.name = \"sklearn_IF\"\n</code></pre>"},{"location":"utils/#utils_reboot.utils.sklearn_IsolationForest.predict","title":"<code>predict(X)</code>","text":"<p>Overwrite the <code>predict</code> method of the parent class <code>IsolationForest</code> from <code>sklearn.ensemble</code> module to obtain the  Anomaly Scores instead of the class labels (i.e. inliers and outliers)</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Input dataset</p> required <p>Returns:</p> Type Description <code>array</code> <p>Anomaly Scores</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def predict(self, X:np.array) -&gt; np.array:\n\n    \"\"\"\n    Overwrite the `predict` method of the parent class `IsolationForest` from `sklearn.ensemble` module to obtain the \n    Anomaly Scores instead of the class labels (i.e. inliers and outliers)\n\n    Args:\n        X: Input dataset\n\n    Returns:\n        Anomaly Scores \n    \"\"\"\n\n    score=self.decision_function(X)\n    return -1*score+0.5\n</code></pre>"},{"location":"utils/#utils_reboot.utils.get_feature_indexes","title":"<code>get_feature_indexes(dataset, f1, f2)</code>","text":"<p>Function to get the indexes of two features in the dataset given the feature names. </p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Type[Dataset]</code> <p>Dataset</p> required <code>f1</code> <code>Union[str, int]</code> <p>Name of the first feature</p> required <code>f2</code> <code>Union[str, int]</code> <p>Name of the second feature</p> required <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Indexes of the two features in the dataset</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def get_feature_indexes(dataset:Type[Dataset],\n                        f1:Union[str, int],\n                        f2:Union[str, int]) -&gt; tuple[int,int]:\n\n    \"\"\"\n    Function to get the indexes of two features in the dataset given the feature names. \n\n    Args:\n        dataset: Dataset\n        f1: Name of the first feature\n        f2: Name of the second feature\n\n    Returns:\n        Indexes of the two features in the dataset\n    \"\"\"\n\n    if isinstance(f1,int) and isinstance(f2,int):\n        return f1,f2\n\n    feature_names=dataset.feature_names\n\n    try:\n        idx1=feature_names.index(f1)\n    except:\n        print('Feature name not valid')\n    try: \n        idx2=feature_names.index(f2)\n    except:\n        print('Feature name not valid')\n\n    return idx1,idx2\n</code></pre>"},{"location":"utils/#utils_reboot.utils.get_most_recent_file","title":"<code>get_most_recent_file(directory_path, filetype='pickle')</code>","text":"<p>Function to get the most recent file (i.e. last modified file) in a directory path.</p> <p>Parameters:</p> Name Type Description Default <code>directory_path</code> <code>str</code> <p>Directory path where the files are stored</p> required <code>filetype</code> <code>str</code> <p>Type of the file (i.e. <code>npz</code> or <code>pickle</code>)</p> <code>'pickle'</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the most recent file in the directory path</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def get_most_recent_file(directory_path:str,\n                         filetype:str=\"pickle\")-&gt;str:\n\n    \"\"\"\n    Function to get the most recent file (i.e. last modified file) in a directory path.\n\n    Args:\n        directory_path: Directory path where the files are stored\n        filetype: Type of the file (i.e. `npz` or `pickle`)\n\n    Returns:\n        Path to the most recent file in the directory path\n\n    \"\"\"\n\n    assert filetype in [\"pickle\", \"npz\"], \"filetype must be either 'pickle' or 'npz'\"\n    date_format = \"%d-%m-%Y_%H-%M-%S\"\n    datetimes=[datetime.strptime(file[:19],date_format) for file in os.listdir(directory_path)]\n    sorted_files=sorted(datetimes,reverse=True)\n    most_recent_file=sorted_files[0].strftime(date_format)+f'_.{filetype}'\n    return os.path.join(directory_path,most_recent_file)\n</code></pre>"},{"location":"utils/#utils_reboot.utils.open_element","title":"<code>open_element(file_path, filetype='pickle')</code>","text":"<p>Function to open an element from a file (i.e. <code>npz</code> or <code>pickle</code> file) in the specified directory path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>filetype</code> <code>str</code> <p>Type of the file (i.e. <code>npz</code> or <code>pickle</code>)</p> <code>'pickle'</code> <p>Returns:</p> Type Description <code>Union[array, list, DataFrame, Type[Precisions], Type[NewPrecisions], Type[Precisions_random]]</code> <p>Element stored in the file</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def open_element(file_path:str,\n                 filetype:str=\"pickle\") -&gt; Union[np.array,list,pd.DataFrame,Type[Precisions],Type[NewPrecisions],Type[Precisions_random]]:\n\n    \"\"\"\n    Function to open an element from a file (i.e. `npz` or `pickle` file) in the specified directory path.\n\n    Args:\n        file_path: Path to the file\n        filetype: Type of the file (i.e. `npz` or `pickle`)\n\n    Returns:\n        Element stored in the file\n    \"\"\"\n\n    assert filetype in [\"pickle\", \"npz\"], \"filetype must be either 'pickle' or 'npz'\"\n    if filetype == \"pickle\":\n        with open(file_path, 'rb') as fl:\n            element = pickle.load(fl)\n    elif filetype == \"npz\":\n        element = np.load(file_path)['element']\n    return element\n</code></pre>"},{"location":"utils/#utils_reboot.utils.save_element","title":"<code>save_element(element, directory_path, filename='', filetype='pickle')</code>","text":"<p>Function to save an element produced by an experiment in a file (i.e. <code>npz</code> or <code>pickle</code> file) in the specified directory path.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>Union[array, list, DataFrame, Type[Precisions], Type[NewPrecisions], Type[Precisions_random]]</code> <p>Element to be saved</p> required <code>directory_path</code> <code>str</code> <p>Directory path where the file will be saved</p> required <code>filename</code> <code>str</code> <p>Name of the file</p> <code>''</code> <code>filetype</code> <code>str</code> <p>Type of the file (i.e. <code>npz</code> or <code>pickle</code>)</p> <code>'pickle'</code> <p>Returns:</p> Type Description <code>None</code> <p>The method saves element and does not return any value</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def save_element(element:Union[np.array,list,pd.DataFrame,Type[Precisions],Type[NewPrecisions],Type[Precisions_random]],\n                 directory_path:str,\n                 filename:str=\"\",\n                 filetype:str=\"pickle\") -&gt; None:\n\n    \"\"\"\n    Function to save an element produced by an experiment in a file (i.e. `npz` or `pickle` file) in the specified directory path.\n\n    Args:\n        element: Element to be saved\n        directory_path: Directory path where the file will be saved\n        filename: Name of the file\n        filetype: Type of the file (i.e. `npz` or `pickle`)\n\n    Returns:\n        The method saves element and does not return any value \n\n    \"\"\"\n\n    assert filetype in [\"pickle\", \"npz\"], \"filetype must be either 'pickle' or 'npz'\"\n    t = time.localtime()\n    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n    filename = current_time + '_' + filename\n    path = directory_path + '/' + filename\n    if filetype == \"pickle\":\n        with open(path+\".pickle\", 'wb') as fl:\n            pickle.dump(element, fl)\n    elif filetype == \"npz\":\n        np.savez(path, element=element)\n</code></pre>"},{"location":"utils/#utils_reboot.utils.save_fs_prec","title":"<code>save_fs_prec(precs, path)</code>","text":"<p>Function to save the feature selection precisions in a file (i.e. <code>pickle</code> file) in the specified directory path.</p> <p>Parameters:</p> Name Type Description Default <code>precs</code> <code>namedtuple</code> <p>Feature selection precisions</p> required <code>path</code> <code>str</code> <p>Directory path where the file will be saved</p> required <p>Returns:</p> Type Description <code>None</code> <p>The method saves the feature selection precisions and does not return any value</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def save_fs_prec(precs:namedtuple,\n                 path:str) -&gt; None:\n\n    \"\"\"\n    Function to save the feature selection precisions in a file (i.e. `pickle` file) in the specified directory path.\n\n    Args:\n        precs: Feature selection precisions\n        path: Directory path where the file will be saved\n\n    Returns:\n        The method saves the feature selection precisions and does not return any value\n\n    \"\"\"\n\n    #aucfs=sum(precs.inverse.mean(axis=1)-precs.direct.mean(axis=1))\n    aucfs=np.nansum(np.nanmean(precs.inverse,axis=1)-np.nanmean(precs.direct,axis=1))\n    new_precs = NewPrecisions(direct=precs.direct,\n                            inverse=precs.inverse,\n                            dataset=precs.dataset,\n                            model=precs.model,\n                            value=precs.value,\n                            aucfs=aucfs)\n    save_element(new_precs, path, filetype=\"pickle\")\n</code></pre>"},{"location":"utils/#utils_reboot.utils.save_fs_prec_random","title":"<code>save_fs_prec_random(precs, path)</code>","text":"<p>Function to save the feature selection precisions for random features in a file (i.e. <code>pickle</code> file) in the specified directory path.</p> <p>Parameters:</p> Name Type Description Default <code>precs</code> <code>namedtuple</code> <p>Feature selection precisions for random features</p> required <code>path</code> <code>str</code> <p>Directory path where the file will be saved</p> required <p>Returns:</p> Type Description <code>None</code> <p>The method saves the feature selection precisions for random features and does not return any value</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def save_fs_prec_random(precs:namedtuple,\n                        path:str) -&gt; None:\n\n    \"\"\"\n    Function to save the feature selection precisions for random features in a file (i.e. `pickle` file) in the specified directory path.\n\n    Args:\n        precs: Feature selection precisions for random features\n        path: Directory path where the file will be saved\n\n    Returns:\n        The method saves the feature selection precisions for random features and does not return any value\n    \"\"\"\n\n    new_precs = Precisions_random(random=precs.random,\n                            dataset=precs.dataset,\n                            model=precs.model)\n    save_element(new_precs, path, filetype=\"pickle\")\n</code></pre>"},{"location":"utils/#utils_reboot.utils.select_pre_process","title":"<code>select_pre_process()</code>","text":"<p>Function to select the pre-processing of the dataset asking the user to input the pre-processing number.</p> <p>This method was specifically designed to construct the <code>tutorial.ipynb</code> notebook for the documentation.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Boolean value to indicate whether the dataset should be pre-processed or not </p> <code>bool</code> <p>(i.e. 1 to pre-process the dataset and 2 otherwise)</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def select_pre_process() -&gt; bool:\n\n    \"\"\"\n    Function to select the pre-processing of the dataset asking the user to input the pre-processing number.\n\n    This method was specifically designed to construct the `tutorial.ipynb` notebook for the documentation.\n\n    Returns:\n        Boolean value to indicate whether the dataset should be pre-processed or not \n        (i.e. 1 to pre-process the dataset and 2 otherwise)\n    \"\"\"\n    pre_process=int(input(\"Press 1 to pre process the dataset, 2 otherwise: \"))\n    assert pre_process in [1,2], \"Input values not recognized: Accepted values: [1,2]\"\n    return pre_process==1\n</code></pre>"},{"location":"utils/#utils_reboot.utils.select_pre_process_scenario","title":"<code>select_pre_process_scenario(dataset)</code>","text":"<p>Combine the selection of the pre-processing of the dataset and the scenario for the experiment.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Type[Dataset]</code> <p>Dataset to be used in the experiment</p> required <p>Returns:</p> Type Description <code>int</code> <p>The selected scenario number (i.e. 1 for Scenario 1 and 2 for Scenario 2)</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def select_pre_process_scenario(dataset:Type[Dataset]) -&gt; int:\n\n    \"\"\"\n    Combine the selection of the pre-processing of the dataset and the scenario for the experiment.\n\n    Args:\n        dataset: Dataset to be used in the experiment\n\n    Returns:\n        The selected scenario number (i.e. 1 for Scenario 1 and 2 for Scenario 2)\n    \"\"\"\n    pre_process=select_pre_process()\n    scenario=select_scenario()\n\n    if scenario==2:\n        dataset.split_dataset(train_size=1-dataset.perc_outliers,contamination=0)\n\n    if pre_process==1:\n        dataset.pre_process()\n        print(\"Dataset pre processed\\n\")\n    elif scenario==2 and not pre_process==2:\n        print(\"Dataset not preprocessed\\n\")\n        dataset.initialize_test()\n    elif scenario==1 and not pre_process==2:\n        print(\"Dataset not preprocessed\\n\")\n        dataset.initialize_train_test()\n\n    print(f'Scenario: {scenario}\\n')\n\n    print(f'X_train shape: {dataset.X_train.shape}')\n    print(f'X_test shape: {dataset.X_test.shape}')\n\n    return scenario \n</code></pre>"},{"location":"utils/#utils_reboot.utils.select_scenario","title":"<code>select_scenario()</code>","text":"<p>Function to select the scenario for the experiment (i.e. Scenario 1 or Scenario 2) asking the user to input the scenario number.</p> <p>This method was specifically designed to construct the <code>tutorial.ipynb</code> notebook for the documentation.</p> <p>Returns:</p> Type Description <code>int</code> <p>The selected scenario number (i.e. 1 for Scenario 1 and 2 for Scenario 2)</p> Source code in <code>utils_reboot/utils.py</code> <pre><code>def select_scenario() -&gt; int:\n\n    \"\"\"\n    Function to select the scenario for the experiment (i.e. Scenario 1 or Scenario 2) asking the user to input the scenario number.\n\n    This method was specifically designed to construct the `tutorial.ipynb` notebook for the documentation.\n\n    Returns:\n        The selected scenario number (i.e. 1 for Scenario 1 and 2 for Scenario 2)\n    \"\"\"\n\n    scenario=int(input(\"Press 1 for scenario 1 and 2 for scenario 2: \"))\n    assert scenario in [1,2], \"Scenario not recognized: Accepted values: [1,2]\"\n    return scenario\n</code></pre>"}]}