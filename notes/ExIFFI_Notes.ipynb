{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExIFFI Paper Review\n",
    "Annotate here the main comments contained in the review of the [[DIFFI and EXIFFI - Interpretability on the Isolation Forest model|ExIFFI]] paper and write down the things to do to organize the re writing process of the paper. \n",
    "\n",
    "> [!warning] \n",
    "> Deadline for submitting the reviewed paper -> 31 March 2024  \n",
    "# Editor Comments\n",
    "\n",
    "1. Address concerns regarding the superiority of ExIFFI over distilling feature importance from traditional isolation-based anomaly detection methods like iForest and EIF. Provide a more detailed explanation of why the proposed method is advantageous.\n",
    "\n",
    "> [!todo] \n",
    "> Expand the explanation and intuition under the EIF+ model and why it is better than IF and EIF. \n",
    "\n",
    "2.  Expand the discussion of related work on interpretation methods for unsupervised models. Include recent studies. Additionally, conduct more ablation studies to analyze the impact of design choices in EIF+ and ExIFFI. Perform performance comparisons with state-of-the-art baselines published more recently to strengthen justification.\n",
    "\n",
    "> [!todo] \n",
    "> - Expand the related work section talking about interpretation methods used in unsupervised models (i.e. not only interpretation method in Anomaly Detection but also on other unsupervised learning tasks) → [[ExIFFI PAPER REVIEW#Papers for Related Work|papers to cite]]. \n",
    "> - Ablation study on EIF+ and ExIFFI → Try to see what happens removing some of the design choices we made in the model \n",
    "> - Comparison with state of the art baselines recently published -> We already have the comparison with DIFFI. Search other models to compare ExIFFI to → **Deep Isolation Forest (DIF).** \n",
    "\n",
    "3. Acknowledge concerns about the assumption that labeled anomalies truly deviate from the distribution in real datasets. Consider discussing the time complexity of EIF+ and its scalability to larger datasets. Introduce user studies to assess whether ExIFFI explanations align well with human interpretations, addressing concerns about evaluations limited to datasets without ground truth anomalies. \n",
    "\n",
    "> [!todo] \n",
    "> - Time analysis to see how ExIFFI scales (in terms of execution time) on larger datasets -> find these larger datasets. Here we can use the Parallelized version of ExIFFI I am working on with Francesco\n",
    "> - Introduce User Studies to see how ExIFFI aligns with human explanations -> so we need to find some datasets where there are ground truth anomalies \n",
    "\n",
    "> [!info] Definition of User Studies from Chat GPT\n",
    ">  When we talk about user studies to assess whether an interpretation algorithm aligns well with human explanations, we are referring to a process of evaluating how well the output of the algorithm can be understood and accepted by human users. Interpretation algorithms are often used in machine learning models to provide insights into why a particular decision or prediction was made. These algorithms generate explanations or visualizations that aim to make the model's decision-making process more transparent and interpretable to users.\n",
    ">  User studies in this context involve gathering feedback from human users to determine if the explanations generated by the algorithm are meaningful, accurate, and align with human understanding.\n",
    "\n",
    "For an example of a User Study see [here](http://199.247.16.97/) \n",
    "# Reviewer 1 Comments \n",
    "\n",
    "Recommendation: Major Revision\n",
    "\n",
    "I have the following concerns,  \n",
    "1. As iForest and EIF are not deep learning-based methods, it is possible to distill feature importance from iTrees by considering which features are used for partition. Could the authors please further explain the superiority of the proposed explanation method?  \n",
    "\n",
    "> [!todo] \n",
    "> Same as point 1 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]] \n",
    "\n",
    "2. In the introduction section, the authors are encouraged to further explain the basic insights of the proposed method. Only contributions are listed (contributions are not very specific as well, it is better to further explain why the proposed EIF+ is better), and the readers may also need to know how the proposed method achieves these merits. Please refer to some papers published on top-tier venues; the writing logic of the introduction part could be improved.  papers to cite\n",
    "\n",
    "> [!todo] \n",
    "> Essentially he/she is saying that the Introduction can be written better. It is suggesting again to explain further why EIF+ is better.  \n",
    "\n",
    "4. Some recent studies on isolation-based anomaly detection like [1] should be discussed → **Deep Isolation Forest (DIF)**\n",
    "# Reviewer 2 Comments\n",
    "\n",
    "Recommendation: Major Revision\n",
    "## Paper Strengths\n",
    "\n",
    "1. The paper tackles the important problem of providing explanations for unsupervised anomaly detection models. Interpretability is critical for gaining user trust and facilitating applications.  \n",
    "2. A new model-specific interpretation algorithm called ExIFFI is proposed to interpret predictions made by EIF. Feature importance scores provide useful insights into anomaly patterns.  \n",
    "3. Detailed analysis and visualizations like score maps aid understanding of ExIFFI results and how features influence anomalies.\n",
    "4. Code is openly available to facilitate reproducibility of the results.\n",
    "## Paper Weaknesses\n",
    "\n",
    "1. Limited discussion of related work on interpretation methods for unsupervised models.  \n",
    "\n",
    "> [!todo] \n",
    "> Same as point 2 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]] \n",
    "\n",
    "2. More ablation studies are needed to analyze the impact of different design choices in EIF+ and ExIFFI, such as variations to the normalization distributions and hyperparameter sensitivity analysis.\n",
    "\n",
    "> [!todo] \n",
    "> Like point 2 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]]. Here he/she also suggests on what to do the ablation studies:\n",
    "> - Variations to the normalization distributions:\n",
    "> \t- Use different distributions for the Normalization part (other than `StandardScaler`) ?\n",
    "> \t- Or use different distributions to generate the synthetic datasets?\n",
    "> \t- Or use different distributions to draw the normal vectors used to generate the hyperplanes?\n",
    "> - Hyperparameter sensitivity analysis: \n",
    "> \t- See how the model performance change with variations on the hyperparameter (i.e. number of trees, number of runs of `compute_imps`)\n",
    "\n",
    "3. Performance comparisons with state-of-the-art baselines published more recently are missing. It would help justify the usefulness of EIF+/ExIFFI if compared against more recent methods.  \n",
    "\n",
    "> [!todo] \n",
    "> Same as point 2 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]] \n",
    "\n",
    "4.  For real datasets, labeled anomalies may not truly deviate from the distribution as assumed by isolation forest models. This undermines the evaluation of interpretation results when training on entire data.\n",
    "\n",
    "> [!todo] \n",
    "> This is the problem we have found in the real world dataset used and that forced us to use the *Scenario II* training strategy. Here we should find datasets with ground truth anomalies to test the model and not Multi Class Classification datasets adapted to Anomaly Detection -> that is the hard part.  \n",
    "\n",
    "5. Lack of discussions on the time complexity of EIF+ and whether it can scale to industrial-sized datasets.\n",
    "\n",
    "> [!todo] \n",
    "> Same as point 3 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]]. Use Parallel ExIFFI and find larger datasets. \n",
    "\n",
    "6. Evaluations are limited to real-world datasets without ground truth anomalies. It is unclear whether ExIFFI explanations align well with human interpretations. User studies would provide a better evaluation of interpretability.\n",
    "\n",
    "> [!todo] \n",
    "> Same as the second part of point 3 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]]\n",
    "# Papers\n",
    "\n",
    "## Papers for Related Work\n",
    "\n",
    "- ***A Survey on Explainable Anomaly Detection*** → Here we can find some other interpretation algorithms in the field of anomaly detection to cite in the Related Work section. In this survey there is also DIFFI. \n",
    "- ***Why are you weird? Infusing Interpretability in Isolation Forest for Anomaly Detection*** → This is another interpretability method for the Isolation Forest model. It is surely a paper to cite and also look at the interpretation algorithm it uses in the Related Work section. It may also be a model to compare ExIFFI/DIFFI to. \n",
    "- ***Interpretable Anomaly Detection for Knowledge Discovery in Semiconductor Manufacturing*** → This is a paper by Susto and Mattia Carletti (the inventor of DIFFI). This is good for the Related Work section because it is an application of DIFFI in the industrial world. \n",
    "- ***A New Interpretable Unsupervised Anomaly Detection Method Based on Residual Explanation*** -> Interpretation method on Autoencoders for Anomaly Detection. Explanations are obtained from a deviation analysis of reconstructed input features. ---\n",
    "Created: 31 January 2024\n",
    "Class: Anomaly Detection\n",
    "Type: Notes\n",
    "---\n",
    "Annotate here the main comments contained in the review of the [[DIFFI and EXIFFI - Interpretability on the Isolation Forest model|ExIFFI]] paper and write down the things to do to organize the re writing process of the paper. \n",
    "\n",
    "> [!warning] \n",
    "> Deadline for submitting the reviewed paper -> 31 March 2024  \n",
    "# Editor Comments\n",
    "\n",
    "1. Address concerns regarding the superiority of ExIFFI over distilling feature importance from traditional isolation-based anomaly detection methods like iForest and EIF. Provide a more detailed explanation of why the proposed method is advantageous.\n",
    "\n",
    "> [!todo] \n",
    "> Expand the explanation and intuition under the EIF+ model and why it is better than IF and EIF. \n",
    "\n",
    "2.  Expand the discussion of related work on interpretation methods for unsupervised models. Include recent studies. Additionally, conduct more ablation studies to analyze the impact of design choices in EIF+ and ExIFFI. Perform performance comparisons with state-of-the-art baselines published more recently to strengthen justification.\n",
    "\n",
    "> [!todo] \n",
    "> - Expand the related work section talking about interpretation methods used in unsupervised models (i.e. not only interpretation method in Anomaly Detection but also on other unsupervised learning tasks) → [[ExIFFI PAPER REVIEW#Papers for Related Work|papers to cite]]. \n",
    "> - Ablation study on EIF+ and ExIFFI → Try to see what happens removing some of the design choices we made in the model \n",
    "> - Comparison with state of the art baselines recently published -> We already have the comparison with DIFFI. Search other models to compare ExIFFI to → **Deep Isolation Forest (DIF).** \n",
    "\n",
    "3. Acknowledge concerns about the assumption that labeled anomalies truly deviate from the distribution in real datasets. Consider discussing the time complexity of EIF+ and its scalability to larger datasets. Introduce user studies to assess whether ExIFFI explanations align well with human interpretations, addressing concerns about evaluations limited to datasets without ground truth anomalies. \n",
    "\n",
    "> [!todo] \n",
    "> - Time analysis to see how ExIFFI scales (in terms of execution time) on larger datasets -> find these larger datasets. Here we can use the Parallelized version of ExIFFI I am working on with Francesco\n",
    "> - Introduce User Studies to see how ExIFFI aligns with human explanations -> so we need to find some datasets where there are ground truth anomalies \n",
    "\n",
    "> [!info] Definition of User Studies from Chat GPT\n",
    ">  When we talk about user studies to assess whether an interpretation algorithm aligns well with human explanations, we are referring to a process of evaluating how well the output of the algorithm can be understood and accepted by human users. Interpretation algorithms are often used in machine learning models to provide insights into why a particular decision or prediction was made. These algorithms generate explanations or visualizations that aim to make the model's decision-making process more transparent and interpretable to users.\n",
    ">  User studies in this context involve gathering feedback from human users to determine if the explanations generated by the algorithm are meaningful, accurate, and align with human understanding.\n",
    "\n",
    "For an example of a User Study see [here](http://199.247.16.97/) \n",
    "# Reviewer 1 Comments \n",
    "\n",
    "Recommendation: Major Revision\n",
    "\n",
    "I have the following concerns,  \n",
    "1. As iForest and EIF are not deep learning-based methods, it is possible to distill feature importance from iTrees by considering which features are used for partition. Could the authors please further explain the superiority of the proposed explanation method?  \n",
    "\n",
    "> [!todo] \n",
    "> Same as point 1 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]] \n",
    "\n",
    "2. In the introduction section, the authors are encouraged to further explain the basic insights of the proposed method. Only contributions are listed (contributions are not very specific as well, it is better to further explain why the proposed EIF+ is better), and the readers may also need to know how the proposed method achieves these merits. Please refer to some papers published on top-tier venues; the writing logic of the introduction part could be improved.  papers to cite\n",
    "\n",
    "> [!todo] \n",
    "> Essentially he/she is saying that the Introduction can be written better. It is suggesting again to explain further why EIF+ is better.  \n",
    "\n",
    "4. Some recent studies on isolation-based anomaly detection like [1] should be discussed → **Deep Isolation Forest (DIF)**\n",
    "# Reviewer 2 Comments\n",
    "\n",
    "Recommendation: Major Revision\n",
    "## Paper Strengths\n",
    "\n",
    "1. The paper tackles the important problem of providing explanations for unsupervised anomaly detection models. Interpretability is critical for gaining user trust and facilitating applications.  \n",
    "2. A new model-specific interpretation algorithm called ExIFFI is proposed to interpret predictions made by EIF. Feature importance scores provide useful insights into anomaly patterns.  \n",
    "3. Detailed analysis and visualizations like score maps aid understanding of ExIFFI results and how features influence anomalies.\n",
    "4. Code is openly available to facilitate reproducibility of the results.\n",
    "## Paper Weaknesses\n",
    "\n",
    "1. Limited discussion of related work on interpretation methods for unsupervised models.  \n",
    "\n",
    "> [!todo] \n",
    "> Same as point 2 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]] \n",
    "\n",
    "2. More ablation studies are needed to analyze the impact of different design choices in EIF+ and ExIFFI, such as variations to the normalization distributions and hyperparameter sensitivity analysis.\n",
    "\n",
    "> [!todo] \n",
    "> Like point 2 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]]. Here he/she also suggests on what to do the ablation studies:\n",
    "> - Variations to the normalization distributions:\n",
    "> \t- Use different distributions for the Normalization part (other than `StandardScaler`) ?\n",
    "> \t- Or use different distributions to generate the synthetic datasets?\n",
    "> \t- Or use different distributions to draw the normal vectors used to generate the hyperplanes?\n",
    "> - Hyperparameter sensitivity analysis: \n",
    "> \t- See how the model performance change with variations on the hyperparameter (i.e. number of trees, number of runs of `compute_imps`)\n",
    "\n",
    "3. Performance comparisons with state-of-the-art baselines published more recently are missing. It would help justify the usefulness of EIF+/ExIFFI if compared against more recent methods.  \n",
    "\n",
    "> [!todo] \n",
    "> Same as point 2 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]] \n",
    "\n",
    "4.  For real datasets, labeled anomalies may not truly deviate from the distribution as assumed by isolation forest models. This undermines the evaluation of interpretation results when training on entire data.\n",
    "\n",
    "> [!todo] \n",
    "> This is the problem we have found in the real world dataset used and that forced us to use the *Scenario II* training strategy. Here we should find datasets with ground truth anomalies to test the model and not Multi Class Classification datasets adapted to Anomaly Detection -> that is the hard part.  \n",
    "\n",
    "5. Lack of discussions on the time complexity of EIF+ and whether it can scale to industrial-sized datasets.\n",
    "\n",
    "> [!todo] \n",
    "> Same as point 3 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]]. Use Parallel ExIFFI and find larger datasets. \n",
    "\n",
    "6. Evaluations are limited to real-world datasets without ground truth anomalies. It is unclear whether ExIFFI explanations align well with human interpretations. User studies would provide a better evaluation of interpretability.\n",
    "\n",
    "> [!todo] \n",
    "> Same as the second part of point 3 of [[ExIFFI PAPER REVIEW#Editor Comments|Editor Comments]]\n",
    "# Papers\n",
    "\n",
    "## Papers for Related Work\n",
    "\n",
    "- ***A Survey on Explainable Anomaly Detection*** → Here we can find some other interpretation algorithms in the field of anomaly detection to cite in the Related Work section. In this survey there is also DIFFI. \n",
    "- ***Why are you weird? Infusing Interpretability in Isolation Forest for Anomaly Detection*** → This is another interpretability method for the Isolation Forest model. It is surely a paper to cite and also look at the interpretation algorithm it uses in the Related Work section. It may also be a model to compare ExIFFI/DIFFI to. \n",
    "- ***Interpretable Anomaly Detection for Knowledge Discovery in Semiconductor Manufacturing*** → This is a paper by Susto and Mattia Carletti (the inventor of DIFFI). This is good for the Related Work section because it is an application of DIFFI in the industrial world. \n",
    "- ***A New Interpretable Unsupervised Anomaly Detection Method Based on Residual Explanation*** -> Interpretation method on Autoencoders for Anomaly Detection. Explanations are obtained from a deviation analysis of reconstructed input features. \n",
    "- ***DeepAID: Interpreting and Improving Deep Learning-based Anomaly Detection in Security Applications*** → from the abstract they talk about an interpretation method for Unsupervised DNN that will then be used in DL-based Anomaly Detection systems. \n",
    "- ***Multivariate Time Series Anomaly Detection and Interpretation using Hierarchical Inter-Metric and Temporal Embedding***→ This paper is also reported in *A Survey on Explainable Anomaly Detection*. Here we are talking about Anomaly Detection for Multi variate Time Series. This approach is based on hierarchical Variational Autoencoders (HVAE) and Markov Chain Monte Carlo (MCMC). Given an anomaly, they set up a MCMC-based method to find a set of the most anomalous metrics as explanations.\n",
    "- ***DAEMON: Unsupervised Anomaly Detection and Interpretation for Multivariate Time Series*** → This method still works on Multi Variate Time Series and it trains an Adversarial AutoEncoder (AAE) to learn the typical pattern of multivariate time series, and then use the reconstruction error to identify and explain anomalies.\n",
    "- ***Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction*** → Here we are in the security setting. They proposed the concept of *distribution decomposition rules* that decompose the complex distribution of normal data into multiple compositional distributions. To find these rules they defined an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. \n",
    "## More recent papers\n",
    "\n",
    "- ***A self-supervised anomaly detection algorithm with interpretability***\n",
    "- ***Enhancing anomaly detection accuracy and interpretability in low-quality and class imbalanced data: A comprehensive approach***\n",
    "- **An interpretable autoencoder for semi-supervised anomaly detection***\n",
    "\n",
    "> [!note] \n",
    "> There are a lot of interpretation algorithm on AE-based (AutoEncoder based) Anomaly Detection. In fact AE is the most used DL method for Anomaly Detection. Differently from Isolation Forest based methods (like ExIFFI) it requires much more data to be trained so we can use this to say that we are proposing an interpretation method for a kind of model that does not have it (expect for DIFFI). \n",
    "> Moreover we can use these citations to motivate the novelty of our approach that is based on the peculiar structure of the Isolation Forest model. \n",
    "## Important Papers \n",
    "\n",
    "- ***Deep Isolation Forest for Anomaly Detection*** (DIF)→ This is the paper suggested by the reviewers. We can use this model to compare its performances with the ExIFFI performances. This model may have better performances but, because it uses some NN to transform the inputs and put them into another representation, we this is probaax=sns.barplot(x='num_samples',y='real_time',data=df_100,width=0.5)\n",
    "\n",
    "> [!tip] \n",
    "> After having created an ensemble of representations using the randomly initialized DNN in the paper they adopt the simple axis-parallel cuts used in IF. But what if we try to extend this model using the cuts used in EIF or EIF+ ? May it work better or the newly created representations are already optimally changing the points distribution so that the simple IF cuts are already enough? \n",
    ">   \n",
    "\n",
    "- ***PIDForest: Anomaly Detection via Partial Identification*** (PID) → This one can ba another model to compare to EIF+. \n",
    "- ***Evaluation of post-hoc interpretability methods in time-series classification*** → This paper introduces some new metrics to evaluate interpretability models. The paper works on Time Series data and the interpretability methods evaluate the relevance of different time stamps -> we are working with tabular data and for use the time stamps will be the features. \n",
    "- ***On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study*** → This dataset contains a section that describes some datasets with semantic outliers -> this is what we need, some outliers with a semantic meaning so that we can see if the interpretation done by ExIFFI aligns with the domain knowledge. \n",
    "\n",
    "## Benchmark Datasets \n",
    "\n",
    "In the DIF paper very big datasets are used. This can also be helpful for the comparison of ExIFFI with DIF because we can just take the results reported in the DIF paper instead of re running the experiments (so we just have to run the ExIFFI experiments):\n",
    "\n",
    "- *Analysis,Backdoor,DoS* and *Exploits* -> taken from an intrusion detection benchmark UNSW_NB 15 -> their shape is more or less `(95.000,197)`. This datasets may be useful to see how ExIFFI behaves this very high number of features. \n",
    "\t- *Backdoor* is on ADBench Git repo → ok\n",
    "- *R8* → highly unbalanced text classification dataset → shape `(3974,9468)` \n",
    "- *Cover* → Ecology domain → ok\n",
    "- *Fraud* → Fraudulent Credit Card transactions → shape `(284.807,30)` → ok  \n",
    "- *Pageblock* → shape `(5393,11)`\n",
    "- *Thrombin* → ultrahigh-dimensional anomaly detection→ shape `(1909,139352)`\n",
    "\n",
    "Datasets from Table 2 of *On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study*: \n",
    "\n",
    "- *Arrhythmia* → shape `(450,259)` → ok \n",
    "- *HeartDisease* → shape `(270,120)`\n",
    "- *Hepatitis*  → shape `(80,13)` → ok \n",
    "- *InternetAds* → shape `(3264,1555)` → ok \n",
    "- *PageBlocks* → shape `(5473,10)` → ok,\n",
    "- *Parkinson* → shape `(195,22)`\n",
    "- *SpamBase* → shape `(4601,57)` → ok \n",
    "- *Stamps* → shape `(340,9)`\n",
    "- *Wilt* → shape `(4839,5)` → ok\n",
    "\n",
    "# Things TO DO\n",
    "\n",
    "- [x] [Possible solution to the Zoom Share Screen issue](https://technoracle.com/how-to-fix-zoom-screen-sharing-on-ubuntu-22-04-quickly/)\n",
    "\n",
    "- [ ] Try to organize better the GitHub repository so that also Alessio can work on that \n",
    "\n",
    "- [ ] Organize better the code to optimize it.\n",
    "\t- [x] Written `make_importance` function in C with `OpenMP` → up to 130 times faster  \n",
    "\t- [ ] Use a parallel code and compile in `numba`\n",
    "\t- [ ] Experiments with a similar structure to the CAPRI HPC jobs \n",
    "\t- [ ] Create a result table with all the time execution details to see how the model scales with the dataset size. Compare Isolation Forest with EIF and EIF+ and other AD models (e.g. a state of the art AD AutoEncoder and Deep Isolation Forest). Metrics to use for the comparison: AUC ROC Score, Average Precision, Precision, Recall, F1 Score, ... and the time values,`real_time`,and `user_time`)\n",
    "\t\n",
    "- [ ] Search a good dataset for discussing the results (think about what kind of experiments to do) with ground truth labels where there is some domain knowledge. We want anomalies to be truly isolated points and not just minority classes in a Multi Class Classification problem. → Some possible examples are [[ExIFFI PAPER REVIEW#Benchmark Datasets|here]]. \n",
    "\n",
    "- [ ] Ablation studies of EIF+\n",
    "\t- [ ] Different normalizing distributions (i.e. different scalers other than `StandardScaler` → `MinMaxScaler`,)\n",
    "\t- [ ] Different number of Isolation Trees \n",
    "\t- [ ] Different distribution for selecting the intercept point $p$ from which the partition hyperplane has to pass \n",
    "\t- [ ] Try to use median instead of mean to select the intercept point (i.e. $N(median(X),\\eta \\ std(X)$)\n",
    "\t- [ ] Divide in train and test and change the percentage of anomalies in the training set \n",
    "\n",
    "- [ ] Ablation studies ExIFFI \n",
    "\t- [ ] What happens to explainability as the contamination factor increases ? \n",
    "\t- [ ] Different number of Isolation Trees \n",
    "\t- [ ] Include or exclude the `depth_based` parameter \n",
    "\t- [ ] How interpretation changes giving in input only inliers or datasets with also outliers \n",
    "\t- [ ] Try to use other percentages (other than 10%) to split the dataset in inliers and outliers when we compute the Global Importance \n",
    "\n",
    "- [ ] Deep Isolation Forest and compare it to ExIFFI -> say at the end that the problem with Deep Isolation Forest is that is very difficult to apply interpretability to it. \n",
    "\t- [ ] Focus more on comparing the feature importance obtained with ExIFFI with the one obtained with Random Forest (train the random forest model with the anomaly scores obtained from the Anomaly Detection models).\n",
    "\n",
    "- [ ] Search for papers on Feature Importance in Decision Trees/Random Forest and see what kind of experiments they did \n",
    "\n",
    "- [ ] Interpretable models evaluation metrics from *Evaluation of post-hoc interpretability methods in time-series classification*\n",
    "\t- [ ] Use TIC Index from the paper *Evaluation of post-hoc interpretability methods in time-series classification* \n",
    "\t- [ ] Use the metrics $AUC\\tilde{S}_{top}$ and $F1\\tilde{S}$ to evaluate the feature importance\n",
    "\n",
    "- [ ] Enlarge the Related Work section \n",
    "\t- [ ] See some possible paper to cite [[ExIFFI PAPER REVIEW#Papers for Related Work|here]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "te Carlo (MCMC). Given an anomaly, they set up a MCMC-based method to find a set of the most anomalous metrics as explanations.\n",
    "- ***DAEMON: Unsupervised Anomaly Detection and Interpretation for Multivariate Time Series*** → This method still works on Multi Variate Time Series and it trains an Adversarial AutoEncoder (AAE) to learn the typical pattern of multivariate time series, and then use the reconstruction error to identify and explain anomalies.\n",
    "- ***Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction*** → Here we are in the security setting. They proposed the concept of *distribution decomposition rules* that decompose the complex distribution of normal data into multiple compositional distributions. To find these rules they defined an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. \n",
    "## More recent papers\n",
    "\n",
    "- ***A self-supervised anomaly detection algorithm with interpretability***\n",
    "- ***Enhancing anomaly detection accuracy and interpretability in low-quality and class imbalanced data: A comprehensive approach***\n",
    "- **An interpretable autoencoder for semi-supervised anomaly detection***\n",
    "\n",
    "> [!note] \n",
    "> There are a lot of interpretation algorithm on AE-based (AutoEncoder based) Anomaly Detection. In fact AE is the most used DL method for Anomaly Detection. Differently from Isolation Forest based methods (like ExIFFI) it requires much more data to be trained so we can use this to say that we are proposing an interpretation method for a kind of model that does not have it (expect for DIFFI). \n",
    "> Moreover we can use these citations to motivate the novelty of our approach that is based on the peculiar structure of the Isolation Forest model. \n",
    "## Important Papers \n",
    "\n",
    "- ***Deep Isolation Forest for Anomaly Detection*** (DIF)→ This is the paper suggested by the reviewers. We can use this model to compare its performances with the ExIFFI performances. This model may have better performances but, because it uses some NN to transform the inputs and put them into another representation, we this is probaax=sns.barplot(x='num_samples',y='real_time',data=df_100,width=0.5)\n",
    "\n",
    "> [!tip] \n",
    "> After having created an ensemble of representations using the randomly initialized DNN in the paper they adopt the simple axis-parallel cuts used in IF. But what if we try to extend this model using the cuts used in EIF or EIF+ ? May it work better or the newly created representations are already optimally changing the points distribution so that the simple IF cuts are already enough? \n",
    ">   \n",
    "\n",
    "- ***PIDForest: Anomaly Detection via Partial Identification*** (PID) → This one can ba another model to compare to EIF+. \n",
    "- ***Evaluation of post-hoc interpretability methods in time-series classification*** → This paper introduces some new metrics to evaluate interpretability models. The paper works on Time Series data and the interpretability methods evaluate the relevance of different time stamps -> we are working with tabular data and for use the time stamps will be the features. \n",
    "- ***On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study*** → This dataset contains a section that describes some datasets with semantic outliers -> this is what we need, some outliers with a semantic meaning so that we can see if the interpretation done by ExIFFI aligns with the domain knowledge. \n",
    "\n",
    "## Benchmark Datasets \n",
    "\n",
    "In the DIF paper very big datasets are used. This can also be helpful for the comparison of ExIFFI with DIF because we can just take the results reported in the DIF paper instead of re running the experiments (so we just have to run the ExIFFI experiments):\n",
    "\n",
    "- *Analysis,Backdoor,DoS* and *Exploits* -> taken from an intrusion detection benchmark UNSW_NB 15 -> their shape is more or less `(95.000,197)`. This datasets may be useful to see how ExIFFI behaves this very high number of features. \n",
    "\t- *Backdoor* is on ADBench Git repo → ok\n",
    "- *R8* → highly unbalanced text classification dataset → shape `(3974,9468)` \n",
    "- *Cover* → Ecology domain → ok\n",
    "- *Fraud* → Fraudulent Credit Card transactions → shape `(284.807,30)` → ok  \n",
    "- *Pageblock* → shape `(5393,11)`\n",
    "- *Thrombin* → ultrahigh-dimensional anomaly detection→ shape `(1909,139352)`\n",
    "\n",
    "Datasets from Table 2 of *On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study*: \n",
    "\n",
    "- *Arrhythmia* → shape `(450,259)` → ok \n",
    "- *HeartDisease* → shape `(270,120)`\n",
    "- *Hepatitis*  → shape `(80,13)` → ok \n",
    "- *InternetAds* → shape `(3264,1555)` → ok \n",
    "- *PageBlocks* → shape `(5473,10)` → ok,\n",
    "- *Parkinson* → shape `(195,22)`\n",
    "- *SpamBase* → shape `(4601,57)` → ok \n",
    "- *Stamps* → shape `(340,9)`\n",
    "- *Wilt* → shape `(4839,5)` → ok\n",
    "\n",
    "# Things TO DO\n",
    "\n",
    "- [x] [Possible solution to the Zoom Share Screen issue](https://technoracle.com/how-to-fix-zoom-screen-sharing-on-ubuntu-22-04-quickly/)\n",
    "\n",
    "- [ ] Try to organize better the GitHub repository so that also Alessio can work on that \n",
    "\n",
    "- [ ] Organize better the code to optimize it.\n",
    "\t- [x] Written `make_importance` function in C with `OpenMP` → up to 130 times faster  \n",
    "\t- [ ] Use a parallel code and compile in `numba`\n",
    "\t- [ ] Experiments with a similar structure to the CAPRI HPC jobs \n",
    "\t- [ ] Create a result table with all the time execution details to see how the model scales with the dataset size. Compare Isolation Forest with EIF and EIF+ and other AD models (e.g. a state of the art AD AutoEncoder and Deep Isolation Forest). Metrics to use for the comparison: AUC ROC Score, Average Precision, Precision, Recall, F1 Score, ... and the time values,`real_time`,and `user_time`)\n",
    "\t\n",
    "- [ ] Search a good dataset for discussing the results (think about what kind of experiments to do) with ground truth labels where there is some domain knowledge. We want anomalies to be truly isolated points and not just minority classes in a Multi Class Classification problem. → Some possible examples are [[ExIFFI PAPER REVIEW#Benchmark Datasets|here]]. \n",
    "\n",
    "- [ ] Ablation studies of EIF+\n",
    "\t- [ ] Different normalizing distributions (i.e. different scalers other than `StandardScaler` → `MinMaxScaler`,)\n",
    "\t- [ ] Different number of Isolation Trees \n",
    "\t- [ ] Different distribution for selecting the intercept point $p$ from which the partition hyperplane has to pass \n",
    "\t- [ ] Try to use median instead of mean to select the intercept point (i.e. $N(median(X),\\eta \\ std(X)$)\n",
    "\t- [ ] Divide in train and test and change the percentage of anomalies in the training set \n",
    "\n",
    "- [ ] Ablation studies ExIFFI \n",
    "\t- [ ] What happens to explainability as the contamination factor increases ? \n",
    "\t- [ ] Different number of Isolation Trees \n",
    "\t- [ ] Include or exclude the `depth_based` parameter \n",
    "\t- [ ] How interpretation changes giving in input only inliers or datasets with also outliers \n",
    "\t- [ ] Try to use other percentages (other than 10%) to split the dataset in inliers and outliers when we compute the Global Importance \n",
    "\n",
    "- [ ] Deep Isolation Forest and compare it to ExIFFI -> say at the end that the problem with Deep Isolation Forest is that is very difficult to apply interpretability to it. \n",
    "\t- [ ] Focus more on comparing the feature importance obtained with ExIFFI with the one obtained with Random Forest (train the random forest model with the anomaly scores obtained from the Anomaly Detection models).\n",
    "\n",
    "- [ ] Search for papers on Feature Importance in Decision Trees/Random Forest and see what kind of experiments they did \n",
    "\n",
    "- [ ] Interpretable models evaluation metrics from *Evaluation of post-hoc interpretability methods in time-series classification*\n",
    "\t- [ ] Use TIC Index from the paper *Evaluation of post-hoc interpretability methods in time-series classification* \n",
    "\t- [ ] Use the metrics $AUC\\tilde{S}_{top}$ and $F1\\tilde{S}$ to evaluate the feature importance\n",
    "\n",
    "- [ ] Enlarge the Related Work section \n",
    "\t- [ ] See some possible paper to cite [[ExIFFI PAPER REVIEW#Papers for Related Work|here]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
