{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORMANCE METRICS \n",
    "\n",
    "Compute the performance metrics of the EIF and EIF+ models (for the moment let's consider just these two). \n",
    "\n",
    "Performance Metrics computed: \n",
    "\n",
    "1. The typical classification metrics that we can obtain with sklearn.metrics.classification_report\n",
    "\n",
    "2. The Average Precision -> this is obtained with sklearn.metrics.average_precision_score but we can still use the mean value obtained in the Average_Precision.ipynb notebook (the ones used to create the Violin Plot)\n",
    "\n",
    "3. The ROC AUC Score -> obtainable with the sklearn.metrics.auc_roc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 16:10:17.392151: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import sklearn\n",
    "sys.path.append('../experiments')\n",
    "from append_dir import append_dirname\n",
    "append_dirname(\"ExIFFI\")\n",
    "sys.path.append('../src')\n",
    "from src.utils import *\n",
    "from src.performance_report_functions import *\n",
    "#from utils.feature_selection import *\n",
    "from plot import *\n",
    "from simulation_setup import *\n",
    "from models import *\n",
    "from models.forests import *\n",
    "from pyod.models.dif import DIF\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from sklearn.metrics import classification_report,average_precision_score,roc_auc_score\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os\n",
    "import pickle \n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.getcwd()\n",
    "path = os.path.dirname(path)\n",
    "path_real = os.path.join(path, \"data\", \"real\")\n",
    "path_syn = os.path.join(path, \"data\", \"syn\")\n",
    "mat_files_real = glob(os.path.join(path_real, \"*.mat\"))\n",
    "mat_file_names_real = {os.path.basename(x).split(\".\")[0]: x for x in mat_files_real}\n",
    "mat_files_syn = glob(os.path.join(path_syn, \"*.pkl\"))\n",
    "mat_file_names_syn = {os.path.basename(x).split(\".\")[0]: x for x in mat_files_syn}\n",
    "csv_files_real = glob(os.path.join(path_real, \"*.csv\"))\n",
    "csv_file_names_real = {os.path.basename(x).split(\".\")[0]: x for x in csv_files_real}\n",
    "dataset_names = list(mat_file_names_real.keys()) + list(mat_file_names_syn) + list(csv_file_names_real.keys())\n",
    "mat_file_names_real.update(mat_file_names_syn)\n",
    "mat_file_names_real.update(csv_file_names_real)\n",
    "dataset_paths = mat_file_names_real.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wine dataset from /home/davidefrizzo/Desktop/PHD/ExIFFI/data/real/wine.mat\n",
      "wine \n",
      "\n",
      "[number of samples = 129]\n",
      "[percentage outliers = 0.07751937984496124]\n",
      "[number features = 13]\n",
      "[number outliers = 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidefrizzo/Desktop/PHD/ExIFFI/models/forests.py:18: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'C', False, aligned=True))\n",
      "  d = np.dot(x,normals[node_id])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shuttle dataset from /home/davidefrizzo/Desktop/PHD/ExIFFI/data/real/shuttle.mat\n",
      "shuttle \n",
      "\n",
      "[number of samples = 49097]\n",
      "[percentage outliers = 0.0715114976475141]\n",
      "[number features = 9]\n",
      "[number outliers = 3511]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wine</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.774790</td>\n",
       "      <td>0.331008</td>\n",
       "      <td>0.774790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>0.702383</td>\n",
       "      <td>0.982056</td>\n",
       "      <td>0.819002</td>\n",
       "      <td>0.968959</td>\n",
       "      <td>0.975004</td>\n",
       "      <td>0.691063</td>\n",
       "      <td>0.975004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Precision    Recall  f1 score  Accuracy  Balanced Accuracy  \\\n",
       "0     wine   0.500000  0.600000  0.545455  0.922481           0.774790   \n",
       "1  shuttle   0.702383  0.982056  0.819002  0.968959           0.975004   \n",
       "\n",
       "   Average Precision  ROC AUC Score  \n",
       "0           0.331008       0.774790  \n",
       "1           0.691063       0.975004  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets=['wine','shuttle']\n",
    "path_list=[dataset_paths[name] for name in datasets]\n",
    "model=IsolationForest()\n",
    "df_perf=collect_performance_df(datasets,path_list,model=model)\n",
    "df_perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wine</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.77479</td>\n",
       "      <td>0.331008</td>\n",
       "      <td>0.77479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>0.702791</td>\n",
       "      <td>0.982626</td>\n",
       "      <td>0.819477</td>\n",
       "      <td>0.969041</td>\n",
       "      <td>0.97531</td>\n",
       "      <td>0.691823</td>\n",
       "      <td>0.97531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Precision    Recall  f1 score  Accuracy  Balanced Accuracy  \\\n",
       "0     wine   0.500000  0.600000  0.545455  0.922481            0.77479   \n",
       "1  shuttle   0.702791  0.982626  0.819477  0.969041            0.97531   \n",
       "\n",
       "   Average Precision  ROC AUC Score  \n",
       "0           0.331008        0.77479  \n",
       "1           0.691823        0.97531  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_pickle(os.path.join(os.getcwd(),'../','results','perf_results','12-02-2024_16-25-16_test_performance_wine_shuttle.pkl'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davidefrizzo/Desktop/PHD/ExIFFI/data/syn'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../data/syn')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(os.getcwd()+'/ball_6_dim.pkl', \"rb\")\n",
    "loaded_dictionary = pickle.load(file_to_read)\n",
    "X_train=loaded_dictionary['X_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(os.path.join(os.getcwd(),'anomalies.pkl'), \"rb\")\n",
    "loaded_dictionary = pickle.load(file_to_read)\n",
    "X_xaxis,X_yaxis,X_bisect,X_bisect_3d,X_bisect_6d=loaded_dictionary['X_xaxis'],loaded_dictionary['X_yaxis'],loaded_dictionary['X_bisec'],loaded_dictionary['X_bisec_3d'],loaded_dictionary['X_bisec_6d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `performance` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davidefrizzo/Desktop/PHD/ExIFFI/data/real'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../real')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wine dataset from /home/davidefrizzo/Desktop/PHD/ExIFFI/data/real/wine.mat\n",
      "wine \n",
      "\n",
      "[number of samples = 129]\n",
      "[percentage outliers = 0.07751937984496124]\n",
      "[number features = 13]\n",
      "[number outliers = 10]\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,X,y=load_preprocess('StandardScaler','wine',os.path.join(os.getcwd(),'wine.mat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidefrizzo/Desktop/PHD/ExIFFI/models/forests.py:18: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'C', False, aligned=True))\n",
      "  d = np.dot(x,normals[node_id])\n"
     ]
    }
   ],
   "source": [
    "model=IsolationForest(n_estimators=100)\n",
    "model.fit(X_train)\n",
    "X_test=np.r_[X_train,X_xaxis]\n",
    "_,X_test,_,y=pre_process('StandardScaler',X_train,X_test)\n",
    "d,y_pred=performance(X_test,y,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `get_performance_dict` method\n",
    "\n",
    "It works both with PyOD model and with models from `forests.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ],\n",
       "       [0.52380952, 1.        , 0.6875    , 0.52380952, 0.5       ,\n",
       "        0.52380952, 0.5       ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=IsolationForest(n_estimators=100)\n",
    "model.fit(X_train)\n",
    "X_test=np.r_[X_train,X_xaxis]\n",
    "_,X_test,_,y=pre_process('StandardScaler',X_train,X_test)\n",
    "mat=get_performance_dict('Xxaxis',X_train,X_test,y)\n",
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Report Table Computation Function\n",
    "\n",
    "The following functions can be found in the Python Script called performance_report_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_predict(score,p):\n",
    "    y=score>np.sort(score)[::-1][int(p*len(score))]\n",
    "    return y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_if(y,score):\n",
    "    p=sum(y)/len(y)\n",
    "    y_pred=if_predict(score,p)\n",
    "    d={}\n",
    "    d['Precision']=sklearn.metrics.precision_score(y,y_pred) \n",
    "    d['Recall']=sklearn.metrics.recall_score(y,y_pred) \n",
    "    d['f1 score']=sklearn.metrics.f1_score(y,y_pred) \n",
    "    d['Accuracy']=sklearn.metrics.accuracy_score(y,y_pred) \n",
    "    d['Balanced Accuracy']=sklearn.metrics.balanced_accuracy_score(y,y_pred) \n",
    "    d['Average Precision']=sklearn.metrics.average_precision_score(y,y_pred) \n",
    "    d['ROC AUC Score']=sklearn.metrics.roc_auc_score(y,y_pred) \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_eif(y,score,X_test,model):\n",
    "    p=sum(y)/len(y)\n",
    "    y_pred=model._predict(X_test,p).astype(int)\n",
    "    d={}\n",
    "    d['Precision']=sklearn.metrics.precision_score(y,y_pred) \n",
    "    d['Recall']=sklearn.metrics.recall_score(y,y_pred)\n",
    "    d['f1 score']=sklearn.metrics.f1_score(y,y_pred)\n",
    "    d['Accuracy']=sklearn.metrics.accuracy_score(y,y_pred)\n",
    "    d['Balanced Accuracy']=sklearn.metrics.balanced_accuracy_score(y,y_pred)\n",
    "    d['Average Precision']=sklearn.metrics.average_precision_score(y,score)\n",
    "    d['ROC AUC Score']=sklearn.metrics.roc_auc_score(y,score)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(X_train,X_test,y):\n",
    "    \n",
    "    EIF=ExtendedIsolationForest(n_estimators=300,plus=0)\n",
    "    EIF.fit(X_train)\n",
    "\n",
    "    EIF_plus=ExtendedIsolationForest(n_estimators=300,plus=1)\n",
    "    EIF_plus.fit(X_train)\n",
    "\n",
    "    IF=IsolationForest(n_estimators=300,max_samples=min(len(X_train),256))\n",
    "    IF.fit(X_train)\n",
    "\n",
    "    score_if=-1*IF.score_samples(X_test)+0.5\n",
    "    score_eif=EIF.predict(X_test)\n",
    "    score_eif_plus=EIF_plus.predict(X_test)\n",
    "\n",
    "    metrics_if=performance_if(y,score_if)\n",
    "    metrics_eif=performance_eif(y,score_eif,X_test,EIF)\n",
    "    metrics_eif_plus=performance_eif(y,score_eif_plus,X_test,EIF_plus)\n",
    "\n",
    "    return metrics_if,metrics_eif,metrics_eif_plus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_performance(metrics_dict,name,X_train,X_test,y):\n",
    "    metrics_dict[name]={}\n",
    "    metrics_dict[name][\"IF\"]={}\n",
    "    metrics_dict[name][\"EIF\"]={}\n",
    "    metrics_dict[name][\"EIF_plus\"]={}\n",
    "    metric_names=['Precision', 'Recall', 'f1 score', 'Accuracy', 'Balanced Accuracy', 'Average Precision', 'ROC AUC Score']\n",
    "\n",
    "    for metric_name in metric_names:\n",
    "        metrics_dict[name]['IF'][metric_name]=[]\n",
    "        metrics_dict[name]['EIF'][metric_name]=[]\n",
    "        metrics_dict[name]['EIF_plus'][metric_name]=[]\n",
    "\n",
    "\n",
    "    for i in tqdm(range(10)):\n",
    "        metrics_if,metrics_eif,metrics_eif_plus=evaluate_performance(X_train,X_test,y)\n",
    "\n",
    "        for metric_name in metric_names:\n",
    "            metrics_dict[name]['IF'][metric_name].append(metrics_if[metric_name])\n",
    "            metrics_dict[name]['EIF'][metric_name].append(metrics_eif[metric_name])\n",
    "            metrics_dict[name]['EIF_plus'][metric_name].append(metrics_eif_plus[metric_name])\n",
    "\n",
    "    for metric_name in metric_names:\n",
    "        metrics_dict[name]['IF'][metric_name+'_avg']=np.mean(np.array(metrics_dict[name]['IF'][metric_name]))\n",
    "        metrics_dict[name]['EIF'][metric_name+'_avg']=np.mean(np.array(metrics_dict[name]['EIF'][metric_name]))\n",
    "        metrics_dict[name]['EIF_plus'][metric_name+'_avg']=np.mean(np.array(metrics_dict[name]['EIF_plus'][metric_name]))\n",
    "     \n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOMATIC PERFORMANCE REPORT COMPUTATION FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_report(name,metrics_dict,metrics_dict_split):\n",
    "    \n",
    "    os.chdir('c:\\\\Users\\\\lemeda98\\\\Desktop\\\\PHD Information Engineering\\\\ExIFFI\\\\ExIFFI\\\\data')\n",
    "    if name=='diabetes' or name=='moodify':\n",
    "        X,y=csv_dataset(name,os.getcwd()+'\\\\')\n",
    "    else:\n",
    "        X,y=dataset(name,os.getcwd()+'\\\\')\n",
    "\n",
    "    X,y=downsample(X,y)\n",
    "    X_train,X_test=partition_data(X,y)\n",
    "    scaler=StandardScaler()\n",
    "    X_train=scaler.fit_transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    y_train=np.zeros(X_train.shape[0])\n",
    "    y_test=np.ones(X_test.shape[0])\n",
    "    y=np.concatenate([y_train,y_test])\n",
    "    X_test=np.r_[X_train,X_test]\n",
    "    scaler2=StandardScaler()\n",
    "    X=scaler2.fit_transform(X)\n",
    "\n",
    "    #Compute Performance Report Table without split\n",
    "    metrics_dict=collect_performance(metrics_dict,name,X,X,y)\n",
    "\n",
    "    #Compute Performance Report Table with split\n",
    "    metrics_dict_split=collect_performance(metrics_dict_split,name,X_train,X_test,y)\n",
    "\n",
    "    print('--------------------------------------------------------')\n",
    "    print(name)\n",
    "    print()\n",
    "    print('f1 score and average precision no train test split ')\n",
    "    print(f'IF -> f1 score: {metrics_dict[name][\"IF\"][\"f1 score\"]}\\naverage precision: {metrics_dict[name][\"IF\"][\"Average Precision\"]}')\n",
    "    print(f'EIF -> f1 score: {metrics_dict[name][\"EIF\"][\"f1 score\"]}\\naverage precision: {metrics_dict[name][\"EIF\"][\"Average Precision\"]}')\n",
    "    print(f'EIF_plus -> f1 score: {metrics_dict[name][\"EIF_plus\"][\"f1 score\"]}\\naverage precision: {metrics_dict[name][\"EIF_plus\"][\"Average Precision\"]}')\n",
    "    print(' ')\n",
    "    print('f1 score and average precision with train test split ')\n",
    "    print(f'IF -> f1 score: {metrics_dict_split[name][\"IF\"][\"f1 score\"]}\\naverage precision: {metrics_dict_split[name][\"IF\"][\"Average Precision\"]}')\n",
    "    print(f'EIF -> f1 score: {metrics_dict_split[name][\"EIF\"][\"f1 score\"]}\\naverage precision: {metrics_dict_split[name][\"EIF\"][\"Average Precision\"]}')\n",
    "    print(f'EIF_plus -> f1 score: {metrics_dict_split[name][\"EIF_plus\"][\"f1 score\"]}\\naverage precision: {metrics_dict_split[name][\"EIF_plus\"][\"Average Precision\"]}')\n",
    "    print('-----------------------------------------------------------')\n",
    "\n",
    "    return metrics_dict,metrics_dict_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_report_synt(name,X_train,X_test,metrics_dict,metrics_dict_split):\n",
    "    \n",
    "    X=np.r_[X_train,X_test]\n",
    "    scaler=StandardScaler()\n",
    "    X_train=scaler.fit_transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    y_train=np.zeros(X_train.shape[0])\n",
    "    y_test=np.ones(X_test.shape[0])\n",
    "    y=np.concatenate([y_train,y_test])\n",
    "    X_test=np.r_[X_train,X_test]\n",
    "    scaler2=StandardScaler()\n",
    "    X=scaler2.fit_transform(X)\n",
    "\n",
    "    #Compute Performance Report Table without split\n",
    "    metrics_dict=collect_performance(metrics_dict,name,X,X,y)\n",
    "\n",
    "    #Compute Performance Report Table with split\n",
    "    metrics_dict_split=collect_performance(metrics_dict_split,name,X_train,X_test,y)\n",
    "\n",
    "    print('--------------------------------------------------------')\n",
    "    print(name)\n",
    "    print()\n",
    "    print('f1 score and average precision no train test split ')\n",
    "    print(f'IF -> f1 score: {metrics_dict[name][\"IF\"][\"f1 score_avg\"]}\\naverage precision: {metrics_dict[name][\"IF\"][\"Average Precision_avg\"]}')\n",
    "    print(f'EIF -> f1 score: {metrics_dict[name][\"EIF\"][\"f1 score_avg\"]}\\naverage precision: {metrics_dict[name][\"EIF\"][\"Average Precision_avg\"]}')\n",
    "    print(f'EIF_plus -> f1 score: {metrics_dict[name][\"EIF_plus\"][\"f1 score_avg\"]}\\naverage precision: {metrics_dict[name][\"EIF_plus\"][\"Average Precision_avg\"]}')\n",
    "    print(' ')\n",
    "    print('f1 score and average precision with train test split ')\n",
    "    print(f'IF -> f1 score: {metrics_dict_split[name][\"IF\"][\"f1 score_avg\"]}\\naverage precision: {metrics_dict_split[name][\"IF\"][\"Average Precision_avg\"]}')\n",
    "    print(f'EIF -> f1 score: {metrics_dict_split[name][\"EIF\"][\"f1 score_avg\"]}\\naverage precision: {metrics_dict_split[name][\"EIF\"][\"Average Precision_avg\"]}')\n",
    "    print(f'EIF_plus -> f1 score: {metrics_dict_split[name][\"EIF_plus\"][\"f1 score_avg\"]}\\naverage precision: {metrics_dict_split[name][\"EIF_plus\"][\"Average Precision_avg\"]}')\n",
    "    print('-----------------------------------------------------------')\n",
    "\n",
    "    return metrics_dict,metrics_dict_split\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict={}\n",
    "metrics_dict_split={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re load the X_train dataset for each different synthetic dataset to avoid having it scaled multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(os.getcwd()+'\\\\ball_6_dim.pkl', \"rb\")\n",
    "loaded_dictionary = pickle.load(file_to_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict,metrics_dict_split=performance_report_synt('Xaxis',X_train,X_xaxis,metrics_dict,metrics_dict_split)\n",
    "X_train=loaded_dictionary['X_train']\n",
    "metrics_dict,metrics_dict_split=performance_report_synt('Yaxis',X_train,X_yaxis,metrics_dict,metrics_dict_split)\n",
    "X_train=loaded_dictionary['X_train']\n",
    "metrics_dict,metrics_dict_split=performance_report_synt('Bisect',X_train,X_bisect,metrics_dict,metrics_dict_split)\n",
    "X_train=loaded_dictionary['X_train']\n",
    "metrics_dict,metrics_dict_split=performance_report_synt('Bisect_3d',X_train,X_bisect_3d,metrics_dict,metrics_dict_split)\n",
    "X_train=loaded_dictionary['X_train']\n",
    "metrics_dict,metrics_dict_split=performance_report_synt('Bisect_6d',X_train,X_bisect_6d,metrics_dict,metrics_dict_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real World Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names=['wine','annthyroid','breastw','shuttle','pima','cardio','glass',\n",
    "             'ionosphere','pendigits','diabetes','moodify']\n",
    "for name in dataset_names:\n",
    "    metrics_dict,metrics_dict_split=performance_report(name,metrics_dict,metrics_dict_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save in pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\lemeda98\\\\Desktop\\\\PHD Information Engineering\\\\ExIFFI\\\\ExIFFI\\\\results\\\\davide\\\\Performance Report'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('c:\\\\Users\\\\lemeda98\\\\Desktop\\\\PHD Information Engineering\\\\ExIFFI\\\\ExIFFI\\\\results\\\\davide\\\\Performance Report')\n",
    "path=os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path + '\\\\Performance_Report_final_synt.pkl'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(metrics_dict_split,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('c:\\\\Users\\\\lemeda98\\\\Desktop\\\\PHD Information Engineering\\\\ExIFFI\\\\ExIFFI')\n",
    "path = os.getcwd() + '\\\\results\\\\davide\\\\Performance Report\\\\Performance_Report_final_synt.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    Performance_report_synt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(dataset_paths['pima'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   age    bmi  HbA1c_level  blood_glucose_level  Target\n",
       "0           0  80.0  25.19          6.6                  140       0\n",
       "1           1  54.0  27.32          6.6                   80       0\n",
       "2           2  28.0  27.32          5.7                  158       0\n",
       "3           3  36.0  23.45          5.0                  155       0\n",
       "4           4  76.0  20.14          4.8                  155       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(dataset_paths['diabetes'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>duration (ms)</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>spec_rate</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-8.815</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.520</td>\n",
       "      <td>128.050</td>\n",
       "      <td>3.446154e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>194641.0</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-6.848</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.250</td>\n",
       "      <td>122.985</td>\n",
       "      <td>1.464234e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>217573.0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>-8.029</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.247</td>\n",
       "      <td>170.044</td>\n",
       "      <td>4.007850e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>443478.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-4.571</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.199</td>\n",
       "      <td>92.011</td>\n",
       "      <td>7.959809e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>225862.0</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-5.863</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.163</td>\n",
       "      <td>115.917</td>\n",
       "      <td>4.693131e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  duration (ms)  danceability  energy  loudness  speechiness  \\\n",
       "0           0       195000.0         0.611   0.614    -8.815       0.0672   \n",
       "1           1       194641.0         0.638   0.781    -6.848       0.0285   \n",
       "2           2       217573.0         0.560   0.810    -8.029       0.0872   \n",
       "3           3       443478.0         0.525   0.699    -4.571       0.0353   \n",
       "4           4       225862.0         0.367   0.771    -5.863       0.1060   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo     spec_rate  \\\n",
       "0        0.0169          0.000794    0.7530    0.520  128.050  3.446154e-07   \n",
       "1        0.0118          0.009530    0.3490    0.250  122.985  1.464234e-07   \n",
       "2        0.0071          0.000008    0.2410    0.247  170.044  4.007850e-07   \n",
       "3        0.0178          0.000088    0.0888    0.199   92.011  7.959809e-08   \n",
       "4        0.3650          0.000001    0.0965    0.163  115.917  4.693131e-07   \n",
       "\n",
       "   Target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(dataset_paths['moodify'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
